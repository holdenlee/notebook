<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

  <meta name="description" content="Holden Lee's Research Notebook">
  <meta name="author" content="Holden Lee">
    
  <title>Adversarial examples in neural networks</title>

  <!-- Bootstrap core CSS -->
  <link href="../../../../bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
  <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

  <!-- Custom styles for this template -->
  <link href="../../../../css/blog.css" rel="stylesheet">
  <link href="../../../../css/default.css" rel="stylesheet">

  <!-- Extension : Footnotes -->
  <link href="../../../../footnotes/css/footnotes.css" rel="stylesheet">

  <!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->
  

  <!-- Extension : Collapsible lists @ http://code.stephenmorley.org/javascript/collapsible-lists/-->
  <link href="../../../../collapsible_lists/css/collapsible.css" rel="stylesheet">
  <script type="text/javascript" src="../../../../collapsible_lists/js/CollapsibleLists.js"></script>

</head>

<body>

<!-- Navigation bar. navbar-inverse is black, navbar-default is white.-->
<!-- To make a button active (pressed), use <li class="active"> -->
<div id="header">
  <nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../../">Notebook</a>
      </div>
      <div id="navbar" class="collapse navbar-collapse">
        <ul class="nav navbar-nav">
          <li><a href="../../../../">Home</a></li>
          <li><a href="../../../../sitemap.html">Sitemap</a></li>
<!-- TODO: Distinguish between PAPERS, RESEARCH QUESTIONS, BOOKS -->
<!-- TODO: make this part a for loop over main pages -->
        </ul>
      </div><!--/.nav-collapse -->
    </div>
  </nav>
</div>
<!-- Content -->
<!--div id="content">
  <h1>Mental Wilderness</h1>-->



<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Adversarial examples in neural networks</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-21 
          , Modified: 2017-02-21 
	</p>
      
       <p>Tags: <a href="../../../../tags/neural%20nets.html">neural nets</a>, <a href="../../../../tags/uncertainty.html">uncertainty</a>, <a href="../../../../tags/aaml.html">aaml</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#introduction">Introduction</a><ul>
 <li><a href="#statement">Statement</a></li>
 <li><a href="#literature">Literature</a></li>
 <li><a href="#experiments">Experiments</a></li>
 <li><a href="#theory">Theory</a></li>
 </ul></li>
 <li><a href="#lcls17-delving-into-transferable-adversarial-examples">[LCLS17] Delving into Transferable Adversarial Examples</a><ul>
 <li><a href="#experiments-1">Experiments</a></li>
 <li><a href="#ensemble-based-approaches">Ensemble-based approaches</a></li>
 <li><a href="#geometry">Geometry</a></li>
 </ul></li>
 <li><a href="#questions">Questions</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="introduction">Introduction</h2>
<h3 id="statement">Statement</h3>
<p>Neural networks can be easily fooled—ex. an adversary adding a small amount of noise can change the classification from “dog” to “cat” with high confidence. It can be fooled even by a weak adversary with just black-box access!</p>
<p>Related to making NN’s resistant: Have NN’s give a confidence bound.</p>
<p>Ideas:</p>
<ul>
<li>Use uncertainty quantification from statistics: Fisher information. See personal communication with Jacob.</li>
<li>Use an ensemble of neural nets. Train an ensemble in parallel, vs. train together against a discriminator.</li>
<li>Sleeping in NN</li>
<li>Use some kind of calibration</li>
<li>Active learning</li>
<li>Make Lipschitz/other regularization. Give noisy example with the kind of noise you want to be resistant against.</li>
<li>Boosting</li>
</ul>
<h3 id="literature">Literature</h3>
<ul>
<li>[SZSB14] Intriguing properties of neural networks <a href="https://arxiv.org/pdf/1312.6199.pdf?not-changed">paper</a></li>
<li>Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014.</li>
<li></li>
<li></li>
<li>[LCLS17] Delving into Transferable Adversarial Examples and Black-box Attacks</li>
</ul>
<h3 id="experiments">Experiments</h3>
<ul>
<li>Reproduce adversarial examples result on a simple dataset, e.g. MNIST.</li>
<li>Try training an ensemble of NN in parallel and compare to predictions of a single one.</li>
</ul>
<h3 id="theory">Theory</h3>
<ul>
<li>Think in terms of learning theory, VC dimension…</li>
</ul>
<h2 id="lcls17-delving-into-transferable-adversarial-examples">[LCLS17] Delving into Transferable Adversarial Examples</h2>
<ol type="1">
<li>Model, training data, training process, test label set unknown to attacker.</li>
<li>Large dataset (ImageNet)</li>
<li>Do not construct substitute model</li>
</ol>
<p>What is the difference between targeted and non-targeted transferability?</p>
<ol type="1">
<li>Non-targeted: <span class="math inline">\(x^*\approx x\)</span>, <span class="math inline">\(f_\te(x^*)\ne f_\te(x) = y\)</span>. (Constrain <span class="math inline">\(d(x,x^*)\le B\)</span>.)</li>
<li>Targeted: <span class="math inline">\(x^*\approx x\)</span>, <span class="math inline">\(f_\te(x^*)=y^*\)</span>.</li>
</ol>
<p>3 approaches: Suppose <span class="math inline">\(f = \max_i J_\te(x)_i\)</span>, where <span class="math inline">\(J_\te(x)\)</span> is vector of probabilities.</p>
<ol type="1">
<li>Optimization <span class="math inline">\(\amin_{x^*} \la d(x,x^*) - \ell(\one_y, J_\te(x^*))\)</span>. Ex. <span class="math inline">\(\ell(u,v) = \ln (1-u\cdot v)\)</span>.</li>
<li>Fast gradient <span class="math inline">\(x^* \leftarrow \text{clamp}(x+B\sign (\nb_x \ell(\one_y, J_\te(x))))\)</span>.</li>
<li>Fast gradient sign <span class="math inline">\(x^* \leftarrow \text{clamp}\pa{x+B\nv{\nb_x\ell(\one_y, J_\te(x))}}\)</span>.</li>
</ol>
<p>Approaches for targeted: Replace constraint with <span class="math inline">\(f_\te(x^*)=y^*\)</span></p>
<ol type="1">
<li>Optimization <span class="math inline">\(\amin_{x^*} \la d(x,x^*) \redd{+} \redd{\ell'(\one_{y^*}}, J_\te(x^*))\)</span>. Ex. <span class="math inline">\(\ell'(u,v) = \redd{-\sum_i u_i \lg v_i}\)</span>.</li>
<li>Fast gradient <span class="math inline">\(x^* \leftarrow \text{clamp}(x\redd{-}B\sign (\nb_x \redd{\ell'(\one_{y^*}}, J_\te(x))))\)</span>.</li>
<li>Fast gradient sign <span class="math inline">\(x^* \leftarrow \text{clamp}\pa{x\redd{-}B\nv{\nb_x\redd{\ell'(\one_y}, J_\te(x))}}\)</span>.</li>
</ol>
<h3 id="experiments-1">Experiments</h3>
<p>Choose 100 images (ILSVRC2012 dataset) which can be correctly classified by all 5 models.</p>
<p>Non-target transferability: accuracy = percentage of adversarial examples for one model correctly classified for the other. (For NN to be good, want this to be high)</p>
<p>Targeted transferability: matching rate = percentage of adversarial examples classified as target label by other model. (Want this to be low)</p>
<p>Root mean square deviation <span class="math inline">\(d(x^*,x) = \sfc{\sum_i (x_i^*-x_i^2)}{N}\)</span>.</p>
<p>Q: isn’t the optimizer using gradient information? (We can estimate it by sampling though!)</p>
<p>Use small learning rate to generate images with RMSD&lt;2. Actually can set <span class="math inline">\(\la=0\)</span>.</p>
<p>(Accuracy is low. But what is the confidence?)</p>
<ul>
<li>Optimization can mislead the models.</li>
<li>FG cannot fully mislead the models. A potential reason is that, FG can be viewed as approximating the optimization, but is tailored for speed over accuracy.</li>
</ul>
<p>Find the minimal transferable RMSD by linear search.</p>
<p>Note FGS minimizes distortion’s <span class="math inline">\(L_\iy\)</span> norm while FG minimizes <span class="math inline">\(L_2\)</span> norm.</p>
<p>Target labels do not transfer. Fast gradient-based approaches don’t do well because they only search in 1-D subspace.</p>
<h3 id="ensemble-based-approaches">Ensemble-based approaches</h3>
<p>These do better! If an adversarial image remains adversarial for multiple models, it is more likely to transfer to other models. <span class="math display">\[
\amin_{x^*} -\ln \pa{\pa{\sumo ik \al_i J_i(x^*)}\cdot \one_{y^*}} + \la d(x,x^*)
\]</span> For each of the five models, we treat it as the black-box model to attack, and generate adversarial images for the ensemble of the rest four, which is considered as white-box. This attack does well!</p>
<p>Non-targeted adversarial images have almost perfect transferability!</p>
<p>Fast gradient doesn’t work with ensemble.</p>
<h3 id="geometry">Geometry</h3>
<ul>
<li>The gradient directions of different models in our evaluation are almost orthogonal to each other. - this makes sense</li>
<li>Choose 2 orthogonal directions, one being a gradient direction. There are up to 21 different regions
<ul>
<li>Boundaries align well.</li>
<li>Boundary diameter along gradient direction smaller. (Even in the direction of increasing the prediction probability!)</li>
</ul></li>
</ul>
<h2 id="questions">Questions</h2>
<ul>
<li>Can you use adversarial examples to improve training?</li>
<li>What if you try denoising first?</li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class="st_facebook_large" displayText="Facebook"></span>
    <span class="st_twitter_large" displayText="Tweet"></span>
    <span class="st_googleplus_large" displayText="Google +"></span>
    <span class="st_reddit_large" displayText="Reddit"></span>
    <span class="st__large" displayText></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>


<!-- Footer -->
<div id="footer">
  <div class="container">
    Built with
    <a href="http://jaspervdj.be/hakyll">Hakyll</a> 
    using 
    <a href="http://www.getbootstrap.com">Bootstrap</a>, 
    <a href="http://www.disqus.com">Disqus</a>,
    <a href="http://ignorethecode.net/blog/2010/04/20/footnotes/">Footnotes.js</a>,
    <a href="http://highlightjs.org/">Highlight.js</a>, 
    <a href="http://www.mathjax.org">MathJax</a>, 
    and <a href="http://www.sharethis.com">ShareThis</a>.
  </div>
</div>
</body>

</html>

<!-- SCRIPTS -->
<!-- jQuery-->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>

<script src="../../../../bootstrap/js/bootstrap.min.js"></script>

<!-- Extension : Highlight.js @ https://highlightjs.org/ -->
<!-- Syntax highlighting tomorrow-night-bright, agate-->
<link rel="stylesheet" href="../../../../highlight/css/tomorrow-night-bright.css">
<script src="../../../../highlight/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<!-- Extension : MathJax @ https://docs.mathjax.org/en/v2.5-latest/tex.html -->
<!-- MathJax/config/local/local.js contains macros. Need to provide entire URL-->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML,http://holdenlee.github.io/notebook/MathJax/config/local/local"></script>

<!-- Extension : Footnotes @ http://ignorethecode.net/blog/2010/04/20/footnotes/ -->
<script src="../../../../footnotes/js/footnotes.js"></script>

<!-- Extension : Disqus @ http://disqus.com -->
<!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->

<script src="../../../../disqus/js/disqus.js"></script>



<!-- Extension : Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-73261814-1', 'auto');
  ga('send', 'pageview');

</script>

