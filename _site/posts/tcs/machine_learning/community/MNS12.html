<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

  <meta name="description" content="Holden Lee's Research Notebook">
  <meta name="author" content="Holden Lee">
    
  <title>[MNS12]</title>

  <!-- Bootstrap core CSS -->
  <link href="../../../../bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
  <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

  <!-- Custom styles for this template -->
  <link href="../../../../css/blog.css" rel="stylesheet">
  <link href="../../../../css/default.css" rel="stylesheet">

  <!-- Extension : Footnotes -->
  <link href="../../../../footnotes/css/footnotes.css" rel="stylesheet">

  <!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->
  

</head>

<body>

<!-- Navigation bar. navbar-inverse is black, navbar-default is white.-->
<!-- To make a button active (pressed), use <li class="active"> -->
<div id="header">
  <nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../../">Notebook</a>
      </div>
      <div id="navbar" class="collapse navbar-collapse">
        <ul class="nav navbar-nav">
          <li><a href="../../../../">Home</a></li>
          <li><a href="../../../../sitemap.html">Sitemap</a></li>
<!-- TODO: Distinguish between PAPERS, RESEARCH QUESTIONS, BOOKS -->
<!-- TODO: make this part a for loop over main pages -->
        </ul>
      </div><!--/.nav-collapse -->
    </div>
  </nav>
</div>
<!-- Content -->
<!--div id="content">
  <h1>Mental Wilderness</h1>-->



<div class="container">
  <div id="content">
    <div class="page header">
      <h1>[MNS12]</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-02-28 
          , Modified: 2016-02-28 
	</p>
      
       <p>Tags: <a href="../../../../tags/abbe.html">abbe</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#summary">Summary</a></li>
 <li><a href="#proofs">Proofs</a><ul>
 <li><a href="#estimation">Estimation</a></li>
 <li><a href="#non-recovery">Non-recovery</a></li>
 <li><a href="#non-estimation">Non-estimation</a></li>
 </ul></li>
 <li><a href="#questions">Questions</a><ul>
 <li><a href="#minor">Minor</a></li>
 </ul></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="summary">Summary</h2>
<p>Mossel, Elchanan, Joe Neeman, and Allan Sly. “Stochastic block models and reconstruction.” arXiv preprint arXiv:1202.1499 (2012).</p>
<p>Model: Given a stochastic block model <span class="math inline">\(G(n, \fc an, \fc bn)\)</span>, recover the communities and estimate <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>.</p>
<p>They prove 3/4 of the problem. The conjectured threshold is <span class="math inline">\((a-b)^2&gt;2(a+b)\)</span>.</p>
<ol type="1">
<li>When $(a-b)^2&gt;2(a+b),
<ol type="1">
<li>Recovery: can we recover the communities efficiently? (Still open.)</li>
<li>Estimate <span class="math inline">\(a,b\)</span> (w.h.p. get <span class="math inline">\(a(1+o(1))\)</span> as <span class="math inline">\(n\to \iy\)</span>). (Theorem 2.5)</li>
</ol></li>
<li>When <span class="math inline">\((a-b)^2\le 2(a+b)\)</span>,
<ol type="1">
<li>Non-recovery: we can recover communities exactly (with probability <span class="math inline">\(1-o(1)\)</span>). (Theorem 2.1)</li>
<li>Non-estimation: we cannot estimate <span class="math inline">\(a,b\)</span>. (Theorem 2.4)</li>
</ol></li>
</ol>
<p>Note that recovery seems stronger than estimation (is this true formally?).</p>
<p>Details of the theorems: Let <span class="math inline">\(\Pj_n=\cal G(n,\fc an, \fc bn)\)</span>, <span class="math inline">\(\Pj_n' = \cal G(n,\fc{a+b}{2n})\)</span>.</p>
<ul>
<li>2.1: Show something stronger: for fixed vertices, <span class="math inline">\(\Pj_n(\si_u=+|G,\si_v=+)\to \rc2\)</span> a.a.s. This means no algorithm can tell whether 2 vertices have the same label.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></li>
<li>2.4: Show that <span class="math inline">\(\Pj_n,\Pj_n'\)</span> are mutually continuous.
<ul>
<li>Mutually contiguous means that <span class="math inline">\(\Pj_n(A_n)\to 0\iff \Pj_n'(A_n)\to 0\)</span>. This is weaker than being statistically indistinguishable.</li>
<li>Mutual continiguity is a transitive relation, so it’s indistinguishable from all <span class="math inline">\(\cal G(n,\fc{a'+b'}{2n})\)</span> also satisfying the same inequality, with the same sum.</li>
</ul></li>
<li>2.5: There are consistent estimators for <span class="math inline">\(a,b\)</span> depending on the number of <span class="math inline">\(k_n\)</span>-cycles (<span class="math inline">\(k_n=\fl{\ln^{\rc 4}n}\)</span>).
<ul>
<li><span class="math inline">\(\Pj_n,\Pj_n'\)</span> are asymptotically orthogonal, i.e., there is <span class="math inline">\(A_n\)</span>, <span class="math inline">\(\Pj_n(A_n)\to 1, \Pj_n'(A_n)\to 0\)</span>.</li>
</ul></li>
</ul>
<h2 id="proofs">Proofs</h2>
<h3 id="estimation">Estimation</h3>
<p>Idea: The number of cycles for <span class="math inline">\(\Pj_n,\Pj_n'\)</span> follow a Poisson distribution. They are spaced farther apart than their standard deviation exactly when <span class="math inline">\((a-b)^2&gt;2(a+b)\)</span>.</p>
<ol type="1">
<li>Calculation of number of <span class="math inline">\(k\)</span>-cycles: <span class="math display">\[ X_{k,n}\xra{d} \Pois\pa{\rc{k2^{k+1}}((a+b)^k + (a-b)^k)}.\]</span> (For the Erdos-Renyi random graph <span class="math inline">\(a'=b'=\fc{a+b}{2}\)</span>, there is no 2nd term.) To calculate this,
<ol type="1">
<li>Expected value: Use linearity of <span class="math inline">\(\E\)</span> over all <span class="math inline">\(\binom nk\)</span> cycles. The probability of the cycle depends on the number of sign changes. Get <span class="math inline">\(n^{-k}2^{-k+1}\sum_{m\text{ even}} \binom km a^{k-m}b^m\)</span>.</li>
<li>Higher moments: We’re counting number of <span class="math inline">\(m\)</span>-cycles. It suffices to show the expected number of non-vertex disjoint <span class="math inline">\(m\)</span>-types converges to 0.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> Then it’s Poisson.</li>
</ol></li>
<li>Parameters. <span class="math inline">\(a+b\)</span> can be estimated from average degree. Estimate <span class="math inline">\(a-b\)</span> using the estimate for <span class="math inline">\(a+b\)</span> and <span class="math inline">\(X_{k_n}\)</span>.</li>
<li>Algorithm. This is Proposition 3.2 which I don’t understand!<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a></li>
</ol>
<h3 id="non-recovery">Non-recovery</h3>
<p>First consider a problem on trees.</p>
<p>Model: A Galton-Watson tree has <span class="math inline">\(\Pois(d)\)</span> offspring. An offspring is flipped with probability <span class="math inline">\(\ep\)</span>. Can you deduce the sign of the root from the sign of the depth-<span class="math inline">\(R\)</span> signs?</p>
<p>Answer: There is threshold.</p>
<p>Idea of non-recovery: On neighborhoods, the distribution of signs is close to that of the model. The posterior distribution of the signs given the graph is approximately a Markov.</p>
<ol type="1">
<li><strong>Theorem 4.1</strong>: <span class="math inline">\(d(1-2\ep)^2\le 1 \iff \lim_{R\to \iy} \Pj(\tau_p=+|\tau_{\pl T_R})=\rc2\)</span> a.s.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></li>
<li><strong>Pr. 4.2</strong>: The distribution of a small neighborhood of a given vertex is statistically close the the distribution for the tree model. Take the radius to be <span class="math inline">\(\rc{C} \log_{\fc{a+b}2} n\)</span>, so that the expected number of nodes is <span class="math inline">\(O(n^{\rc C})\)</span>. Think of this as a coupling argument. Do an inductive argument on the depth, the distance between distributions grows a little each time. Bound the probability of the bad event of having too many children—if this doesn’t happen, there are still approximately <span class="math inline">\(\fc n2\)</span> <span class="math inline">\(+\)</span>’s and <span class="math inline">\(-\)</span>’s left, and the appromate number of children that switch/don’t switch will be close to <span class="math inline">\(\fc a2, \fc b2\)</span>. (See lemmas 4.3-6.)</li>
<li>Consider <span class="math inline">\(\Pj(\si|G)\)</span>. This is not a Markov field because the probability (multiplying factor) of non-edge is different for if the vertices are same/different. But the ratio is <span class="math inline">\(\fc{1-\fc an}{1-\fc bn}\approx 1\)</span>, so it shouldn’t have much effect. We show we still have approximate independence in the sense of <strong>Lemma 4.7</strong>: <span class="math inline">\(\Pj(\si_A|\si_{B\cup C,G} = (1+o(1))\Pj(\si_A|\si_B,G)\)</span> for a.a.e. <span class="math inline">\(G,\si\)</span>,<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> when <span class="math inline">\(A,B,C\)</span> is a partition with <span class="math inline">\(|A\cup B|=o(\sqrt n)\)</span>. (This condition is necessary to make sure we’re not multiplying too many <span class="math inline">\((1-\fc an)\)</span> and <span class="math inline">\((1-\fc bn)\)</span>’s.) Take <span class="math inline">\(A\)</span> to be <span class="math inline">\(B_{R-1}(v)\)</span>, <span class="math inline">\(B\)</span> to be <span class="math inline">\(\pl G_R\)</span>, and <span class="math inline">\(C\)</span> to be the rest. This gives that <span class="math inline">\(\si_v,\si_\rh\)</span> are conditionally independent given the boundary.</li>
<li>Use 1 with <span class="math inline">\(\ep = \fc{b}{a+b}, d=\fc{a+b}{2}\)</span> (proportion of edges corresponding to flipping). The variance approaches the variance without conditioning on <span class="math inline">\(\si_v\)</span>. The variance without conditioning <span class="math inline">\(\Var(\si_\rh|G_,\si_v)\)</span> is close to tht for the tree model, which is 1 (the nonrecovery regime) when <span class="math inline">\(d(1-2\ep)^2\le 1\)</span>, which is exactly the condition. From the variance going to 1, the expectation goes to 0;probability goes to <span class="math inline">\(\rc2\)</span>.</li>
</ol>
<h3 id="non-estimation">Non-estimation</h3>
<p>(Unfinished)</p>
<p>Define <span class="math inline">\(\Pj_n(\si|G)\)</span> to be the same as <span class="math inline">\(\Pj_n'(\si|G)\)</span>. The joint distribution is not the same because the marginal distribution over the graphs is different.</p>
<p>Use a criteria for contiguity, <strong>Theorem 5.1</strong><a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a>. See this as a black box. Calculate moments, etc. of <span class="math inline">\(Y_n=\fc{\Pj_n}{\Pj_n'}\)</span>. Using independence of edges given <span class="math inline">\(\si\)</span>, you can decompose this as a product nicely.</p>
<h2 id="questions">Questions</h2>
<h3 id="minor">Minor</h3>
<ul>
<li>What is a.a.s.?</li>
</ul>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Note that the “a.s.” is with respect to <span class="math inline">\((\si,G)\)</span>. Two neighboring vertices will have a lot of information on each other, but two vertices will be neighboring with low probability with respect to the distribution over <span class="math inline">\(G\)</span>.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>? (How? Reference given is Bollobas, Ch. 4. Need <span class="math inline">\(k=O(\ln^{\rc 4}n)\)</span>.)<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>?<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>It would be good to understand this proof for <span class="math inline">\(d\)</span>-ary trees (without the GW complication).<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>I don’t understand what it means by random partition.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>I don’t understand the motivation/theory behind this. Reference is [35], Wormald, Models of random regular graphs.<a href="#fnref6">↩</a></p></li>
</ol>
</section>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class="st_facebook_large" displayText="Facebook"></span>
    <span class="st_twitter_large" displayText="Tweet"></span>
    <span class="st_googleplus_large" displayText="Google +"></span>
    <span class="st_reddit_large" displayText="Reddit"></span>
    <span class="st__large" displayText></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>


<!-- Footer -->
<div id="footer">
  <div class="container">
    Built with
    <a href="http://jaspervdj.be/hakyll">Hakyll</a> 
    using 
    <a href="http://www.getbootstrap.com">Bootstrap</a>, 
    <a href="http://www.disqus.com">Disqus</a>,
    <a href="http://ignorethecode.net/blog/2010/04/20/footnotes/">Footnotes.js</a>,
    <a href="http://highlightjs.org/">Highlight.js</a>, 
    <a href="http://www.mathjax.org">MathJax</a>, 
    and <a href="http://www.sharethis.com">ShareThis</a>.
  </div>
</div>
</body>

</html>

<!-- SCRIPTS -->
<!-- jQuery-->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>

<script src="../../../../bootstrap/js/bootstrap.min.js"></script>

<!-- Extension : Highlight.js @ https://highlightjs.org/ -->
<!-- Syntax highlighting tomorrow-night-bright, agate-->
<link rel="stylesheet" href="../../../../highlight/css/tomorrow-night-bright.css">
<script src="../../../../highlight/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<!-- Extension : MathJax @ https://docs.mathjax.org/en/v2.5-latest/tex.html -->
<!-- MathJax/config/local/local.js contains macros. Need to provide entire URL-->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML,http://holdenlee.github.io/notebook/MathJax/config/local/local"></script>

<!-- Extension : Footnotes @ http://ignorethecode.net/blog/2010/04/20/footnotes/ -->
<script src="../../../../footnotes/js/footnotes.js"></script>

<!-- Extension : Disqus @ http://disqus.com -->
<!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->

<script src="../../../../disqus/js/disqus.js"></script>



<!-- Extension : Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-73261814-1', 'auto');
  ga('send', 'pageview');

</script>

