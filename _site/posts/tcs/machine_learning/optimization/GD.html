<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

  <meta name="description" content="Holden Lee's Research Notebook">
  <meta name="author" content="Holden Lee">
    
  <title>Gradient descent</title>

  <!-- Bootstrap core CSS -->
  <link href="../../../../bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
  <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

  <!-- Custom styles for this template -->
  <link href="../../../../css/blog.css" rel="stylesheet">
  <link href="../../../../css/default.css" rel="stylesheet">

  <!-- Extension : Footnotes -->
  <link href="../../../../footnotes/css/footnotes.css" rel="stylesheet">

  <!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->
  

</head>

<body>

<!-- Navigation bar. navbar-inverse is black, navbar-default is white.-->
<!-- To make a button active (pressed), use <li class="active"> -->
<div id="header">
  <nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../../">Notebook</a>
      </div>
      <div id="navbar" class="collapse navbar-collapse">
        <ul class="nav navbar-nav">
          <li><a href="../../../../">Home</a></li>
          <li><a href="../../../../sitemap.html">Sitemap</a></li>
<!-- TODO: Distinguish between PAPERS, RESEARCH QUESTIONS, BOOKS -->
<!-- TODO: make this part a for loop over main pages -->
        </ul>
      </div><!--/.nav-collapse -->
    </div>
  </nav>
</div>
<!-- Content -->
<!--div id="content">
  <h1>Mental Wilderness</h1>-->



<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Gradient descent</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-03-04 
          , Modified: 2016-03-04 
	</p>
      
       <p>Tags: <a href="../../../../tags/gradient.html">gradient</a></p> 
    </div>
    
  </div>
  <!--/div-->

  

  <div class="blog-main">
    <p>(See 10/15 notebook for detailed notes.)</p>
<p>See also <a href="AO15.html">AO15</a> and <a href="mirror-descend.html">mirror descent</a>.</p>
<h2 id="summary">Summary</h2>
<table style="width:25%;">
<colgroup>
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Algorithm</th>
<th style="text-align: left;">General</th>
<th style="text-align: left;"><span class="math inline">\(\al\)</span>-strongly convex</th>
<th style="text-align: left;"><span class="math inline">\(\be\)</span>-smooth</th>
<th style="text-align: left;"><span class="math inline">\(\ga\)</span>-convex</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Gradient descent</td>
<td style="text-align: left;"><span class="math inline">\(\rc{\sqrt{T}}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\rc{\al T}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\fc{\be}T\)</span></td>
<td style="text-align: left;"><span class="math inline">\(e^{-\ga T}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Accelerated gradient descent</td>
<td style="text-align: left;"><span class="math inline">\(\fc{d}{T}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\rc{\al T^2}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\fc{\be}{T^2}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(e^{-\sqrt{\ga} T}\)</span></td>
</tr>
</tbody>
</table>
<p>“<span class="math inline">\(\ga\)</span>-convex” is also called “condition number <span class="math inline">\(\ka\)</span>” (<span class="math inline">\(\ka= \ga\)</span>).</p>
<h3 id="gradient-descent-main-points">Gradient descent main points</h3>
<ul>
<li>What is the general framework?
<ol type="1">
<li>Pick a descent direction <span class="math inline">\(\De x\)</span>.</li>
<li>Choose a step size <span class="math inline">\(\tau&gt;0\)</span>: <span class="math display">\[x^{(t+1)} \leftarrow x+\tau \De x.\]</span>
<ul>
<li>Backtracking OR</li>
<li>Exact line search OR</li>
<li>Fixed multiplier</li>
</ul></li>
<li>Continue until stop criterion.</li>
</ol></li>
<li>What is vanilla (one shot) gradient descent?
<ul>
<li>Gradient descent lemma: Suppose <span class="math inline">\(f\)</span> is convex and <span class="math inline">\(L\)</span>-smooth, <span class="math inline">\(\ve{\nb f(x)-\nb f(y)}\le L\ve{x-y}\)</span>.
\begin{align}
 x':&amp;=x-\rc L \nb f(x)\\
 \implies f(x')&amp;\le f(x) - \rc{2L}\ve{\nb f(x)}^2.
 \end{align}</li>
<li>There’s no guarantee for linear convergence unless we assume <span class="math inline">\(f\)</span> is <span class="math inline">\(l\)</span>-strongly convex, <span class="math inline">\(\ve{\nb f(x)-\nb f(y)}\le l\ve{x-y}\)</span>. Let <span class="math inline">\(\ka=\fc{L}{l}, t = \fc{2}{L+l}\)</span>.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> Then linear convergence holds:
\begin{align}
 \ve{x_{k+1}-x^*} \le \pf{\ka-1}{\ka+1} \ve{x_k-x^*}
 \end{align}</li>
<li>This requires knowing the condition number. If we don’t know the condition number, use something like backtracking to get similar convergence guarantees.</li>
</ul></li>
<li>What is gradient descent with backtracking?
<ul>
<li>Parameters <span class="math inline">\(\al\in (0,0.5)\)</span>, step size, <span class="math inline">\(\be\in (0,1)\)</span> scaling factor.</li>
<li>Choose <span class="math inline">\(\De x=\nb f(x)\)</span>.</li>
<li>Choose <span class="math inline">\(\tau\)</span> by backtracking: Set <span class="math inline">\(t=1\)</span>. While <span class="math inline">\(f(x+t\De x)&gt;f(x)+\al \nb f^T\De x\)</span>, <span class="math display">\[\De x\leftarrow \al \De x.\]</span></li>
<li>Lemma: suppose <span class="math inline">\(mI \preceq \nb^2 f \preceq MI\)</span>. Then <span class="math display">\[\fc{f(x_t)-f(p^*)}{f(x_{t-1})-f(p^*)}\le 1-\min\bc{\fc{2\al \be m}{M}, 2m\al}.\]</span></li>
</ul></li>
<li></li>
</ul>
<h2 id="proofs">Proofs</h2>
<p><strong>Gradient descent lemma:</strong> Let <span class="math inline">\(D=\nb f(x)\)</span>. Move to origin. Upper bound is <span class="math display">\[f(x) \le \fc{L}2 x^2 + Dx.\]</span> The minimum is at <span class="math inline">\(-\fc{D}{L}\)</span> and is <span class="math inline">\(\fc{-b^2}{4a} = -\fc{D^2}{2L}.\)</span></p>
<p>For strongly convex: Choose <span class="math inline">\(s\)</span> to maximize the minimum progress in terms of <span class="math inline">\(x\)</span>. <span class="math display">\[\fc{s-\rc{l}}{\rc{l}} = \fc{\rc L-s}{\rc L} \implies s = \fc{2}{L+l}.\]</span></p>
<p><strong>Backtracking analysis:</strong></p>
<ul>
<li>Translate to <span class="math inline">\((0,0)\)</span> and look at 1-D slice. Then <span class="math inline">\(f\le b x + \rc2 M x^2\)</span>, <span class="math inline">\(b = \ve{\nb f(x)}\)</span>. The quadratic equals $bx $ at <span class="math inline">\(x=\fc{2b(1-\al)}{M}\)</span>.</li>
<li>One of the following holds.
\begin{align}
f(x+t_0\De x) &amp;&gt; f(x) + \al \nb f^T \De x\\
t &amp;= \fc{2\nb f^T\De x (1-\al)\be}{M} \ge \fc{\nb f^T \De x \be}{M}
\end{align}
where the last inequality follows from <span class="math inline">\(\al&lt;0.5\)</span>.</li>
<li>What’s the right measure of progress?
<ul>
<li>It shouldn’t be the absolute progress; it should depend on what the minimum actually is. Closer to <span class="math inline">\(x^*\)</span>, we make a smaller step size but <em>more progress proportionally</em>. The right measure is <span class="math inline">\(\fc{f(x_{n+1}) - f(x^*)}{f(x_n)-f(x^*)}\)</span>.</li>
<li>Abstractly, given a quadratic upper and lower bound for <span class="math inline">\(f\)</span>, make progress towards minimum.</li>
<li>Consider the 1-D case at <span class="math inline">\((0,0)\)</span>. We have <span class="math inline">\(\wt f(t) \in - d^2 t + \rc 2 (m,M) d^2 t^2.\)</span>
<ul>
<li>The minimum possible is <span class="math inline">\(-\rc 2 \fc{d^2}{M}\)</span>.</li>
<li>1st case: <span class="math inline">\(\wt f(1) &gt; - \al d^2 t_0\)</span>.
<ul>
<li>Progress <span class="math inline">\(2m\al\)</span>.</li>
</ul></li>
<li>2nd case: <span class="math inline">\(\wt f(t) &gt; - \fc{2\al \be (1-\al)d^2}{M}\)</span>
<ul>
<li>Progress <span class="math inline">\(\fc{2\al \be m}{M}\)</span>.</li>
</ul></li>
<li>Convergence <span class="math inline">\(\fc{f(x_t) - f(x^*)}{f(x_{t-1}) - f(x^*)} \le 1-\min\pa{\fc{2\al \be (1-\al)d^2}{M}, 2m\al}\)</span>.</li>
</ul></li>
</ul></li>
</ul>
<h2 id="different-settings">Different settings</h2>
<ul>
<li>General (can replace gradient by subgradient): Suppose <span class="math inline">\(\ve{\nb f(x)}_2\le M\)</span> and <span class="math inline">\(\ve{x_1-x^*}_2\le R\)</span>.
\begin{align}
\rc 2\ve{x_{k+1}-x^*}_2^2
&amp; = \rc2 \ve{x_k-\al_k g_k -x^*}_2^2 \\
&amp;= \rc 2\ve{x_k-x^*}_2^2 - \al_k \an{g_k,x_k-x^*} + \fc{\al_k^2}{2}\ve{g_k}^2\\
&amp;\le \rc 2\ve{x_k-x^*}_2^2 - \al_k [f(x_k) - f(x^*)]+ \fc{\al_k^2}{2}\ve{g_k}^2&amp; (f(x^*) \ge f(x_k) + \an{g_k,x^*-x_k}).
\end{align}
<p>Rearranging, <span class="math display">\[
\al_k [f(x_k) - f(x^*)] \le \rc2 \ve{x_k-x^*}^2 \le 
\rc2 \ve{x_k-x^*}-\rc2 \ve{x_{k+1}-x^*}^2 + \fc{\al_k^2}{2}\ve{g_k}_*^2.
\]</span> Summing and telescoping, (n.b. we don’t divide through by <span class="math inline">\(\al_k\)</span> before summing) <span class="math display">\[
\sumo kK  \al_k [f(x_k)-f^*] \le \rc2\ve{x_1-x^*}_2^2 + \sumo kK \fc{\al_k^2}2 \ve{g_k}_2^2.
\]</span> Letting <span class="math inline">\(\ol x_K = \rc K \sumo kK x_k\)</span>, (for simplicity of notation, set <span class="math inline">\(\rc{2\al_0}=0\)</span>) <span class="math display">\[
f(\ol x_K) - f(x^*) \le \rc K\pa{
\sum_k \pa{\sumo kK\rc{2\al_k}-\rc{2\al_{k-1}}\ve{x_k-x^*}} - \rc{2\al_K} \ve{x_{K+1}-x^*}^2+ \sumo kK \fc{\al_k}2\ve{g_k}^2}
\le \rc{2\al K}R + \rc{2K}\al M^2.
\]</span> Choose <span class="math inline">\(\al=\fc{\sqrt R}{M}\)</span> to get this is <span class="math inline">\(\le \boxed{\fc{M\sqrt{R}}K}\)</span>. <!--
	Letting $\ol x_K = \sumo kK \al_k x_k/\sumo kK \al_k$, 
	$$
	f(\ol x_K) - f(x^*) \le \fc{R^2+ \rc2 \sumo kK \al_k^2 M^2}{\sumo kK \al_k}.
	$$
	(By convexity, $f(\ol x_K)\le \sumo kK \al_kf(x_k)/\sumo kK \al_k$.)

	Choose $\al=\fc{R}{M\sqrt K}$ to get 
	$$
	f(\ol x_K) - f(x^*) \le \fc{RM}{\sqrt K}.
	$$
	Note if $\sum_k \al_k=\iy$ but $\al_k\to 0$, we get convergence.

	This is slow. If we want $f(x_k) - f(x^*)\le \ep$, we need $O\prc{\ep^2}$ steps.
    I'm very confused here. Isn't the above setting the $M$-smooth case, in which case you get $\rc{T}$ convergence? --> Note this is also a regret bound, and it gives a bound on <span class="math inline">\(\ol x_K\)</span> not <span class="math inline">\(x_K\)</span>. For the bound on <span class="math inline">\(x_K\)</span> see <a href="AO15.html">AO15</a>. Note that proof starts with <span class="math inline">\(f(x_k)-f(x^*)\)</span> rather than <span class="math inline">\(\ve{x_k-x^*}\)</span>, and telescopes on <span class="math inline">\(\rc{D_k}\)</span> instead of <span class="math inline">\(\ve{x_k-x^*}\)</span>.</p>
Alternate proof off by factor of <span class="math inline">\(\log T\)</span>: reduce to <span class="math inline">\(\ga\)</span>-convex by adding <span class="math inline">\(\fc{\al}2\ve{x-x_1}^2\)</span>.</li>
<li><span class="math inline">\(\al\)</span>-sc: Proof off by factor of <span class="math inline">\(\log T\)</span>: average <span class="math inline">\(f*\mu(\pl \bS_\de)\)</span> is <span class="math inline">\(\fc{dG}{\de}\)</span> smooth; optimize parameters.</li>
<li><p>General case: Consider <span class="math inline">\(g(x)=f(x) + \fc{\al}2\ve{x-x_1}^2\)</span>. Use the <span class="math inline">\(\al\)</span>-sc case to get error <span class="math inline">\(\fc{\al}2R^2 + \rc{\al T}\)</span>. Take <span class="math inline">\(\al = \sfc{1}{TR}\)</span> to get <span class="math inline">\(\sfc{R}{\sqrt T}\)</span>.</p></li>
</ul>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Think of this as the harmonic average of how much to move to get to the minima of the upper and lower-bounding quadratics.<a href="#fnref1">↩</a></p></li>
</ol>
</section>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class="st_facebook_large" displayText="Facebook"></span>
    <span class="st_twitter_large" displayText="Tweet"></span>
    <span class="st_googleplus_large" displayText="Google +"></span>
    <span class="st_reddit_large" displayText="Reddit"></span>
    <span class="st__large" displayText></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>


<!-- Footer -->
<div id="footer">
  <div class="container">
    Built with
    <a href="http://jaspervdj.be/hakyll">Hakyll</a> 
    using 
    <a href="http://www.getbootstrap.com">Bootstrap</a>, 
    <a href="http://www.disqus.com">Disqus</a>,
    <a href="http://ignorethecode.net/blog/2010/04/20/footnotes/">Footnotes.js</a>,
    <a href="http://highlightjs.org/">Highlight.js</a>, 
    <a href="http://www.mathjax.org">MathJax</a>, 
    and <a href="http://www.sharethis.com">ShareThis</a>.
  </div>
</div>
</body>

</html>

<!-- SCRIPTS -->
<!-- jQuery-->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>

<script src="../../../../bootstrap/js/bootstrap.min.js"></script>

<!-- Extension : Highlight.js @ https://highlightjs.org/ -->
<!-- Syntax highlighting tomorrow-night-bright, agate-->
<link rel="stylesheet" href="../../../../highlight/css/tomorrow-night-bright.css">
<script src="../../../../highlight/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<!-- Extension : MathJax @ https://docs.mathjax.org/en/v2.5-latest/tex.html -->
<!-- MathJax/config/local/local.js contains macros. Need to provide entire URL-->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML,http://holdenlee.github.io/notebook/MathJax/config/local/local"></script>

<!-- Extension : Footnotes @ http://ignorethecode.net/blog/2010/04/20/footnotes/ -->
<script src="../../../../footnotes/js/footnotes.js"></script>

<!-- Extension : Disqus @ http://disqus.com -->
<!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->

<script src="../../../../disqus/js/disqus.js"></script>



<!-- Extension : Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-73261814-1', 'auto');
  ga('send', 'pageview');

</script>

