<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

  <meta name="description" content="Holden Lee's Research Notebook">
  <meta name="author" content="Holden Lee">
    
  <title>(HMR16) Gradient descent learns linear dynamical systems</title>

  <!-- Bootstrap core CSS -->
  <link href="../../../../bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
  <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

  <!-- Custom styles for this template -->
  <link href="../../../../css/blog.css" rel="stylesheet">
  <link href="../../../../css/default.css" rel="stylesheet">

  <!-- Extension : Footnotes -->
  <link href="../../../../footnotes/css/footnotes.css" rel="stylesheet">

  <!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->
  

  <!-- Extension : Collapsible lists @ http://code.stephenmorley.org/javascript/collapsible-lists/-->
  <link href="../../../../collapsible_lists/css/collapsible.css" rel="stylesheet">
  <script type="text/javascript" src="../../../../collapsible_lists/js/CollapsibleLists.js"></script>

</head>

<body>

<!-- Navigation bar. navbar-inverse is black, navbar-default is white.-->
<!-- To make a button active (pressed), use <li class="active"> -->
<div id="header">
  <nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../../">Notebook</a>
      </div>
      <div id="navbar" class="collapse navbar-collapse">
        <ul class="nav navbar-nav">
          <li><a href="../../../../">Home</a></li>
          <li><a href="../../../../sitemap.html">Sitemap</a></li>
<!-- TODO: Distinguish between PAPERS, RESEARCH QUESTIONS, BOOKS -->
<!-- TODO: make this part a for loop over main pages -->
        </ul>
      </div><!--/.nav-collapse -->
    </div>
  </nav>
</div>
<!-- Content -->
<!--div id="content">
  <h1>Mental Wilderness</h1>-->



<div class="container">
  <div id="content">
    <div class="page header">
      <h1>(HMR16) Gradient descent learns linear dynamical systems</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-12-27 
          , Modified: 2016-12-27 
	</p>
      
       <p>Tags: <a href="../../../../tags/dynamical%20systems.html">dynamical systems</a>, <a href="../../../../tags/quasi-convexity.html">quasi-convexity</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#optimization-background">Optimization background</a></li>
 <li><a href="#control-theory-background">Control theory background</a></li>
 <li><a href="#conditions">Conditions</a></li>
 <li><a href="#proof">Proof</a><ul>
 <li><a href="#showing-quasi-convexity">Showing quasi-convexity</a></li>
 <li><a href="#unbiased-estimator">Unbiased estimator</a></li>
 <li><a href="#bounded-variance">Bounded variance</a></li>
 <li><a href="#extensions">Extensions</a></li>
 </ul></li>
 </ul> </div>

  <div class="blog-main">
    <p>Main theorem:</p>
<ol type="1">
<li>(5.1) Suppose <span class="math inline">\(\Te\)</span> is <span class="math inline">\(\al\)</span>-acquiescent and <span class="math inline">\(\ve{C}\le 1\)</span>. With <span class="math inline">\(N\)</span> samples of length <span class="math inline">\(T\ge \Om\pa{n+\rc{1-\al}}\)</span>, SGD with projection set <span class="math inline">\(B_\al\)</span> returns <span class="math inline">\(\wh \Te = (\wh A, \wh B, \wh C, \wh D)\)</span> with population risk <span class="math display">\[
f(\wh \Te) - f(\Te) \le O\pa{\fc{n^2}N + \sfc{n^5 + \si^2 n^3}{TN}}\poly\pa{\rc{1-\al}, \rc{\tau_0}, \rc{\tau_1}, \tau_2, R=\ve{a}}.
\]</span></li>
<li>(5.2) For long sequences, dividing into samples of length <span class="math inline">\(\be n\)</span> for large enough constant <span class="math inline">\(\be\)</span> gives (suppressing the polynomial dependence on the other parameters) <span class="math display">\[
f(\wh \Te) - f(\Te) \le f(\Te) + O\pa{\sfc{n^5 + \si^2 n^3}{TN}}.
\]</span></li>
<li>(6.2) Suppose <span class="math inline">\(\Te\)</span> has transfer function <span class="math inline">\(G(z) = \fc{s(z)}{p(z)}\)</span> with characteristic function <span class="math inline">\(p(z)\)</span> that is <span class="math inline">\(\al\)</span>-acquiescent by extension of degree <span class="math inline">\(d\)</span>, <span class="math inline">\(\ve{G}_{H_2}\le1\)</span>. Projected SGD with <span class="math inline">\(m=n+d\)</span> states returns <span class="math inline">\(\wh \Te\)</span> with risk <span class="math display">\[
f(\wh \Te) - f(\Te) \le f(\Te) + O\pa{\sfc{m^5 + \si^2 m^3}{TK}}.
\]</span></li>
</ol>
<p>Note:</p>
<ol type="1">
<li>Any poly of degree <span class="math inline">\(n\)</span> with distinct roots inside circle of radius <span class="math inline">\(\al\)</span> is <span class="math inline">\(\al\)</span>-acquiescent by extension of degree <span class="math inline">\(d = O(\max\{(1-\al)^{-1} \ln (\sqrt n \Ga\ve{p}_{H_2}), 0\})\)</span>.</li>
<li>If <span class="math inline">\(p\)</span> has random conjugate pairs of roots inside a circle of radius <span class="math inline">\(\al\)</span>, whp <span class="math inline">\(\Ga(p)\le \exp(\wt O(\sqrt n))\)</span> and <span class="math inline">\(\ve{p}_{H_2}\le \exp(\wt O(\sqrt n))\)</span>, so <span class="math inline">\(p\)</span> is <span class="math inline">\(\al\)</span>-acquiescent by extension of degree <span class="math inline">\(\wt O((1-\al)^{-1}n)\)</span>.</li>
</ol>
<h2 id="optimization-background">Optimization background</h2>
<p>A function <span class="math inline">\(f\)</span> is <span class="math inline">\(\tau\)</span>-weakly-quasi-convex (<span class="math inline">\(\tau\)</span>-WQC) over <span class="math inline">\(B\)</span> with respect to a global minimum <span class="math inline">\(\te^*\)</span> if there is a positive <span class="math inline">\(\tau&gt;0\)</span> such that for all <span class="math inline">\(\te\in B\)</span>, <span class="math display">\[
\nb f(\te)^T(\te-\te^*) \ge \tau (f(\te) - f(\te^*)).
\]</span> <span class="math inline">\(f\)</span> is <span class="math inline">\(\Ga\)</span>-weakly smooth if <span class="math display">\[
\ve{\nb f(\te)}^2 \le \Ga(f(\te)-f(\te^*)).
\]</span></p>
<p>Note a convex function satisfies <span class="math display">\[
f(\te^*) - f(\te) \ge \nb f(\te)^T (\te^*-\te)
\]</span> so is 1-WQC. If <span class="math inline">\(f''\ge a\)</span> everywhere, then <span class="math inline">\(f(\te)-f(\te^*) \ge \ve{\nb f(\te)}^2\)</span> so <span class="math inline">\(f\)</span> is <span class="math inline">\(4a\)</span>-weakly smooth.</p>
<p>For stochastic gradient descent, weak QC and S are enough for convergence guarantees.</p>
<p><strong>Theorem</strong>. Suppose <span class="math inline">\(f\)</span> is <span class="math inline">\(\tau\)</span>-WQC and <span class="math inline">\(\Ga\)</span>-WS and <span class="math inline">\(r\)</span> is an unbiased estimator for <span class="math inline">\(\nb f(\te)\)</span> with variance <span class="math inline">\(V\)</span>, <span class="math inline">\(\te^*\in B\)</span>, <span class="math inline">\(\ve{\te_0-\te^*}\le R\)</span>. Then projected SGD with a suitable learning rate returns <span class="math inline">\(\te_K\)</span> with error <span class="math display">\[
\E f(\te_K)-f(\te^*) \le O\pa{
\max\bc{\fc{\Ga R^2}{\tau^2 K}, \fc{R\sqrt V}{\tau \sqrt K}}
}.
\]</span> (Dependence on <span class="math inline">\(K\)</span> is most important here. Check this.) (Variance makes the convergence <span class="math inline">\(\rc{\sqrt K}\)</span> rather than <span class="math inline">\(\rc K\)</span>.)</p>
<h2 id="control-theory-background">Control theory background</h2>
Consider dynamical systems in the form
<span class="math display">\[\begin{align}
h_{t+1} &amp;= A h_t + B x_t\\
y_t &amp;= C h_t + D x_t + \xi_t\\
\xi_t &amp; \sim N(0,\si^2).
\end{align}\]</span>
<p>(This is a SISO - single-input single-output system.) The population risk is <span class="math display">\[
f(\wh \Te) = \EE_{\{x_t\}, \{\xi_t\}} \ba{
\rc T \sumo tT \ve{\wh y_t - y_t}^2
}
\]</span> where <span class="math inline">\(\wh y_t\)</span> is generated from the estimated parameters without noise. Evert SISO of order <span class="math inline">\(n\)</span> can be put into <strong>controllable canonical form</strong> <span class="math display">\[
A = \matt{\vec 0}{I_{n-1}}{-a_n}{-a_{n-1:1}}, \quad B = \colthree{0}{\vdots}{1} = e_n.
\]</span> Write <span class="math inline">\(A=CC(a)\)</span>, where <span class="math inline">\(a=-[a_n,\ldots, a_1]\)</span>.</p>
<p>A SISO is <strong>controllable</strong> iff <span class="math inline">\([B|AB|\cdots|A^{n-1}B]\)</span> has rank <span class="math inline">\(n\)</span>. (See <a href="../reinforcement_learning/control_theory.html#controllability">Control theory/2 Controllability</a>.)</p>
<p>Let <span class="math display">\[
p_a(z) = z^n + a_1z^{n-1}+\cdots + a_n = \det (zI-A)
\]</span> be the characteristic polynomial of <span class="math inline">\(A\)</span>.</p>
The <strong>transfer function</strong> of the linear system is
<span class="math display">\[\begin{align}
G(z) &amp;= C(zI - A)^{-1}B=:\fc{s(z)}{p(z)}\\
&amp; = \sumo t{\iy} z^{-t} \ub{CA^{t-1}B}{r_{t-1}}\\
&amp; = \fc{c_1+\cdots + c_n z^{n-1}}{z^n + a_1z^{n-1}+\cdots + a_n}
\end{align}\]</span>
<p>where <span class="math inline">\(p\)</span> is monic. (We have <span class="math inline">\(M^{-1} = \fc{\text{cofactor}(M)}{\det(M)}\)</span>.)</p>
<p>(Why is the transfer function useful?)</p>
<p>Define the <strong>idealized risk</strong> as <span class="math display">\[
g(\wh A, \wh C) = \sumz k{\iy} (\wh C\wh A^k B - CA^k B)^2.
\]</span> In the Fourier domain, <span class="math display">\[
g(\wh A, \wh C) = \int_0^{2\pi} |\wh G (e^{i\te}) - G(e^{i\te})|^2\,d\te
\]</span> (The hat on the parameters means “estimate”, the hat on <span class="math inline">\(G\)</span> means “Fourier transform”.)</p>
<em>Explanation</em>. By unfolding the recurrences, then taking the average,
<span class="math display">\[\begin{align}
\E [\ve{\wh y_t - y_t}^2] &amp; = \ve{\wh D - D}^2 + \sumo k{t-1} \ve{\wh C \wh A^{t-k-1} \wh B - CA^{t-k-1} B}^2 + \E[\ve{\xi_t}^2]\\
f(\wh \Te) &amp; = \ve{\wh D - D}^2 + \sumo k{t-1} \pa{1-\fc kT}\ve{\wh C \wh A^{k-1} B - CA^{k-1} B}^2 + \si^2.
\end{align}\]</span>
The idealized risk takes <span class="math inline">\(T\to \iy\)</span>, and ignores the first term. Now by Parseval’s Theorem,
<span class="math display">\[\begin{align}
G(z) &amp;= \sumo t{\iy} CA^{t-1} Bz^{-t}\\
\wh G(z) &amp;= \sumo t{\iy} \wh C \wh A^{t-1} B z^{-t}\\
\int_0^{2\pi} |\wh G(e^{i\te}) - G(e^{i\te})|^2 &amp; = \sumo t{\iy} \ve{CA^{t-1}B - \wh C \wh A^{t-1} B}^2.
\end{align}\]</span>
<p>(This can give some motivation for definition of <span class="math inline">\(G\)</span>. Simply put <span class="math inline">\(CA^kB\)</span> as coefficients of power series; we get <span class="math inline">\(G\)</span>. This also motivates looking at the Fourier series.)</p>
<p>(Why is it useful to pass to the Fourier domain?)</p>
<h2 id="conditions">Conditions</h2>
<ul>
<li>Fix <span class="math inline">\(\tau_0,\tau_1,\tau_2\)</span>. Consider the trapezoidal region on the real axis, <span class="math display">\[ C = \set{z}{\Re z \ge (1+\tau_0)|\Im z|} \cap \set{z}{\tau_1&lt;\Re z &lt;\tau_2}.\]</span>.</li>
<li><span class="math inline">\(p\)</span> is <span class="math inline">\(\al\)</span>-acquiescent if <span class="math inline">\(\set{\fc{p(z)}{z^n}}{|z|=\al}\subeq C\)</span>. A linear system with transfer function <span class="math inline">\(\fc sp\)</span> is <span class="math inline">\(\al\)</span>-acquiescent if <span class="math inline">\(p\)</span> is.</li>
<li><span class="math inline">\(p\)</span> is <span class="math inline">\(\al\)</span>-acquiescent by extension of degree <span class="math inline">\(d\)</span> if there is monic <span class="math inline">\(u\)</span> of degree <span class="math inline">\(d\)</span> such that <span class="math inline">\(pu\)</span> is <span class="math inline">\(\al\)</span>-acquiescent.</li>
<li>Let <span class="math inline">\(B_\al=\set{a\in \R^n}{\set{\fc{p_a(z)}{z^n}}{|z|=\al}\subeq C}\)</span>.
<ul>
<li>If <span class="math inline">\(a\in B_\al\)</span>, then <span class="math inline">\(A\)</span> has spectral radius <span class="math inline">\(\rh(A)&lt;\al\)</span>.</li>
<li><em>Proof</em>. <span class="math inline">\(C\)</span> does not intersect the negative real axis, so by Rouche’s Theorem <span class="math inline">\(z^n, p_a\)</span> have the same number of roots. Thus <span class="math inline">\(g\)</span> has all roots inside <span class="math inline">\(|z|=\al\)</span>. (NOTE: this only requires <span class="math inline">\(\fc{p_n}{z^n}\nin\R\)</span>. Where do we use <span class="math inline">\(\subeq C\)</span>? In the no blow-up property.)</li>
<li><span class="math inline">\(0&lt;\al&lt;\be\implies B_\al\sub B_\be\)</span>. <em>Proof</em>. Maximum modulo principle. If <span class="math inline">\(q(z)\subeq C\)</span> for <span class="math inline">\(|z|=\rc \al\)</span>, then <span class="math inline">\(q(z)\subeq C\)</span> for <span class="math inline">\(|z|=\rc \be\)</span>.</li>
</ul></li>
<li>No blow-up:
<span class="math display">\[\begin{align}
 \sumz k{\iy} \ve{\al^{-k} A^k B}^2 &amp;\le 2\pi n\al^{-2n}/\tau_1^2\\
 \ve{A^k B}^2&amp;\le \min\{2\pi n/\tau_1^2, 2\pi n\al^{2k-2n}/\tau_1^2\}.
 \end{align}\]</span>
<ul>
<li>Load these as coefficients into a Fourier series and use Parseval. Get <span class="math inline">\(\int_0^{2\pi} |(I-\al^{-1}e^{i\la}A)^{-1}B|^2\,d\la\)</span> which depends on the value of <span class="math inline">\(p_a\)</span> at <span class="math inline">\(|z|=\al\)</span>. (Use forms of <span class="math inline">\(A,B\)</span>.) (NOTE: this only requires <span class="math inline">\(\fc{p_n}{z^n}\nin \{|z|\le \tau_1\}\)</span>.</li>
</ul></li>
<li>Define <span class="math inline">\(H_2\)</span> norm by <span class="math inline">\(\ve{G}_{H_2}^2 = \rc{2\pi}\int_0^{2\pi} |G(e^{i\te})|^2\,d\te\)</span>.</li>
<li>Let <span class="math inline">\(\Ga(h) = \sum_{j\in [n]}\af{\la_j^n}{\prod_{i\ne j}(\la_i-\la_j)}\)</span>. (TODO, Q: how related to Lagrange, Chebyshev interpolation?)</li>
</ul>
<p><strong>Rouche’s Theorem</strong>. <a href="https://en.wikipedia.org/wiki/Rouch%C3%A9's_theorem">wikipedia</a></p>
<ol type="1">
<li>If <span class="math inline">\(f,g\)</span> are holomorphic in closed <span class="math inline">\(K\)</span>, <span class="math inline">\(|g|&lt;|f|\)</span> on <span class="math inline">\(\pl K\)</span>, then <span class="math inline">\(f\)</span>, <span class="math inline">\(f+g\)</span> have the same number of zeros inside <span class="math inline">\(K\)</span>.</li>
<li>(Symmetric form) … <span class="math inline">\(|f-g|&lt;|f|+|g|\)</span> on <span class="math inline">\(\pl K\)</span> then <span class="math inline">\(f,g\)</span> have the same number of zeros.</li>
</ol>
<h2 id="proof">Proof</h2>
<h3 id="showing-quasi-convexity">Showing quasi-convexity</h3>
<ul>
<li><span class="math inline">\(g(\wh A, \wh C)\)</span> is <span class="math inline">\(\tau\)</span>-WQC over <span class="math display">\[N_\tau(a) = \set{\wh a\in \R^n}{\forall |z|=1, \Re\pa{p_a}{p_{\wh a}}\ge \fc\tau2}.\]</span>
<ul>
<li><em>Proof</em>. Calculate <span class="math inline">\(h_{\wh s},h_{\wh p}\)</span>. Then compute <span class="math display">\[ \an{h_{\wh a}, \wh a - a} + \an{h_{\wh C}, \wh C-C} = 2\Re \pa{p}{\wh p} |\wh G - G|^2.\]</span> Use the Fourier expression for <span class="math inline">\(g\)</span>.</li>
</ul></li>
<li><span class="math inline">\(g\)</span> is <span class="math inline">\(\Om\pf{\tau_0\tau_1}{\tau_2}\)</span>-WQC in <span class="math inline">\(B_\al \ot \R^n\)</span> and <span class="math inline">\(O\pf{n^2}{\tau_1^4}\)</span>-WS.
<ul>
<li><em>Proof</em>. For <span class="math inline">\(\wh a, a\in B_\al\)</span>, show that <span class="math inline">\(\wh a\in N_\tau(a)\)</span>. Restricting <span class="math inline">\(C\)</span> to be a sector means the angle between any 2 points in <span class="math inline">\(C\)</span> is at most <span class="math inline">\(\pi - \Om(\tau_0)\)</span> and the magnitude is at least <span class="math inline">\(\Om\pf{\tau_1}{\tau_2}\)</span>.</li>
<li>Smoothness (3.4). Use chain rule with <span class="math inline">\(p\)</span> and CS.</li>
</ul></li>
</ul>
<h3 id="unbiased-estimator">Unbiased estimator</h3>
<p>Let <span class="math inline">\(T_1=\fc T4\)</span>. Using loss function <span class="math display">\[
\ell((x,y),\wh\Te) = \rc{T-T_1} \sum_{t&gt;T_1} \ve{\wt y_t - y_t}^2,
\]</span> gradients wrt <span class="math inline">\(\wh a, \wh C, \wh D\)</span> are almost (exponentially) unbiased.</p>
<h3 id="bounded-variance">Bounded variance</h3>
<p>Omitted.</p>
<h3 id="extensions">Extensions</h3>
<p>Ex. when we can’t hope to properly recover: <span class="math inline">\(G(z) = G_1(z) \fc{z^n-r_1^n}{z^n-r_2^n}\)</span> where <span class="math inline">\(r_1\approx r_2\approx 1\)</span>. They are exponentially close but the characteristic polys are very different.</p>
<p>Approximation: Prove that the inverse of a poly can be easily approximated (cf. proof for conjugate gradients, Chebyshev approx).</p>
<p>Using the approximation result, get <span class="math inline">\(\ab{\fc{pu}{z^{n+d}} - 1} &lt;0.5\)</span>, so <span class="math inline">\(\fc{pu}{z^{n+d}}\in C\)</span> for appropriate <span class="math inline">\(\tau_i\)</span>.</p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class="st_facebook_large" displayText="Facebook"></span>
    <span class="st_twitter_large" displayText="Tweet"></span>
    <span class="st_googleplus_large" displayText="Google +"></span>
    <span class="st_reddit_large" displayText="Reddit"></span>
    <span class="st__large" displayText></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>


<!-- Footer -->
<div id="footer">
  <div class="container">
    Built with
    <a href="http://jaspervdj.be/hakyll">Hakyll</a> 
    using 
    <a href="http://www.getbootstrap.com">Bootstrap</a>, 
    <a href="http://www.disqus.com">Disqus</a>,
    <a href="http://ignorethecode.net/blog/2010/04/20/footnotes/">Footnotes.js</a>,
    <a href="http://highlightjs.org/">Highlight.js</a>, 
    <a href="http://www.mathjax.org">MathJax</a>, 
    and <a href="http://www.sharethis.com">ShareThis</a>.
  </div>
</div>
</body>

</html>

<!-- SCRIPTS -->
<!-- jQuery-->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>

<script src="../../../../bootstrap/js/bootstrap.min.js"></script>

<!-- Extension : Highlight.js @ https://highlightjs.org/ -->
<!-- Syntax highlighting tomorrow-night-bright, agate-->
<link rel="stylesheet" href="../../../../highlight/css/tomorrow-night-bright.css">
<script src="../../../../highlight/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<!-- Extension : MathJax @ https://docs.mathjax.org/en/v2.5-latest/tex.html -->
<!-- MathJax/config/local/local.js contains macros. Need to provide entire URL-->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML,http://holdenlee.github.io/notebook/MathJax/config/local/local"></script>

<!-- Extension : Footnotes @ http://ignorethecode.net/blog/2010/04/20/footnotes/ -->
<script src="../../../../footnotes/js/footnotes.js"></script>

<!-- Extension : Disqus @ http://disqus.com -->
<!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->

<script src="../../../../disqus/js/disqus.js"></script>



<!-- Extension : Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-73261814-1', 'auto');
  ga('send', 'pageview');

</script>

