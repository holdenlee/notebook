<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

  <meta name="description" content="Holden Lee's Research Notebook">
  <meta name="author" content="Holden Lee">
    
  <title>Weekly summary 2016-10-22</title>

  <!-- Bootstrap core CSS -->
  <link href="../../bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
  <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

  <!-- Custom styles for this template -->
  <link href="../../css/blog.css" rel="stylesheet">
  <link href="../../css/default.css" rel="stylesheet">

  <!-- Extension : Footnotes -->
  <link href="../../footnotes/css/footnotes.css" rel="stylesheet">

  <!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->
  

  <!-- Extension : Collapsible lists @ http://code.stephenmorley.org/javascript/collapsible-lists/-->
  <link href="../../collapsible_lists/css/collapsible.css" rel="stylesheet">
  <script type="text/javascript" src="../../collapsible_lists/js/CollapsibleLists.js"></script>

</head>

<body>

<!-- Navigation bar. navbar-inverse is black, navbar-default is white.-->
<!-- To make a button active (pressed), use <li class="active"> -->
<div id="header">
  <nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../">Notebook</a>
      </div>
      <div id="navbar" class="collapse navbar-collapse">
        <ul class="nav navbar-nav">
          <li><a href="../../">Home</a></li>
          <li><a href="../../sitemap.html">Sitemap</a></li>
<!-- TODO: Distinguish between PAPERS, RESEARCH QUESTIONS, BOOKS -->
<!-- TODO: make this part a for loop over main pages -->
        </ul>
      </div><!--/.nav-collapse -->
    </div>
  </nav>
</div>
<!-- Content -->
<!--div id="content">
  <h1>Mental Wilderness</h1>-->



<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Weekly summary 2016-10-22</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-10-19 
          , Modified: 2016-10-19 
	</p>
      
       <p>Tags: <a href="../../tags/none.html">none</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#threads">Threads</a></li>
 <li><a href="#other-papers">Other papers</a></li>
 <li><a href="#talk-with-arora-1019-wed">Talk with Arora 10/19 (Wed)</a></li>
 <li><a href="#wonderings">Wonderings</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="threads">Threads</h2>
<ul>
<li>PMI - get some results!</li>
<li>SoS - chapters 2 and 3</li>
<li>DL: do experiments suggested in <a href="../../posts/tcs/machine_learning/matrices/DL_generalization.html">DL generalization</a> (Mon, Tue)
<ul>
<li>(*) NN learns DL. (Mon, Tue) - Wrote up progress so far, where I am stuck.</li>
</ul></li>
<li>Papers
<ul>
<li>[HM16] on unsupervised learning (went through 1st half, Tue)</li>
<li>[HMR16] on dynamical system learning (read <a href="http://www.offconvex.org/2016/10/13/gradient-descent-learns-dynamical-systems/">blog post</a> Tue)</li>
</ul></li>
<li>Come up with a class of MDPs on exponential space that is interesting and tractable. <a href="../../posts/tcs/machine_learning/reinforcement_learning/exponential.html">Thoughts</a>
<ul>
<li>Understand provable guarantees on MDP’s first</li>
</ul></li>
<li>Alexa <a href="https://docs.google.com/document/d/1OtvefjviKSSWH2gzOtYo8T_DVEwPEsI2n0kdrC8WlZI/edit">references</a></li>
</ul>
<p>Analyze Arora and Ge’s NMF algorithm in the presence of noise. Exactly how much noise can it tolerate?</p>
<h2 id="other-papers">Other papers</h2>
<ul>
<li>TODO Read this paper: [CFP16] Assessing significance in a Markov chain without mixing</li>
</ul>
<h2 id="talk-with-arora-1019-wed">Talk with Arora 10/19 (Wed)</h2>
<p>Dynamical systems + MDP!</p>
<h2 id="wonderings">Wonderings</h2>
<ul>
<li>Can we generalize the random walk of the context vectors? There’s no reason to think that context vectors just drift on the sphere. (p. 139)
<ul>
<li>Make it a RBM. Say with bounded degree. (There are ways to learn - see the factored MDP paper. We don’t care about MDP here, so it’s easier.)</li>
<li>For example, one node (dimension) could simply control output of common words.</li>
<li>Given the observations, whose probs are <span class="math inline">\(\propto e^{w^TAc}\)</span>, learn the RBM. (Note we can replace <span class="math inline">\(w\)</span> by <span class="math inline">\(A^Tw\)</span>… but if <span class="math inline">\(c\)</span> is in larger space, then it’s not obvious how to learn the <span class="math inline">\(A\)</span>! Can we modify the word embeddings to deal with this? Beware of difficulties… HMMs usually assume full column-rank observations, violated here. Look at the proper hard instance for HMM. - the version I saw with noisy parity wasn’t quite a HMM)</li>
<li>Prereq: given <span class="math inline">\((x,h)\)</span> how to learn RBM or Bayes net? (When <span class="math inline">\(W\)</span>’s entries are small enough, can do via MCMC estimation of partition function and optimization of log-likelihood. Otherwise, is hard worst-case.)
<ul>
<li>I’m confused! There seems to be a line of work on factorial MDP’s. However, where are the basic results about learnability of Bayes nets? Learning the model for FMDP’s is strictly harder—why so much work on this (with too much assumptions, or weak results) without results on learning Bayes nets?</li>
<li>Bresler.</li>
</ul></li>
<li>cf. work on continuous HMM’s. Work on factored HMMs? Any bounds when hidden state has larger dimension? Also, adapt HMM learning to vector observations. (Is the natural generalization a factored prob model rather than a dynamical system? Note probabilistic linear dynamical system IS straightforward generalization of HMM, but the factored prob model is not. Weird generalization though, because only having states <span class="math inline">\(\{e_1,\ldots, e_n\}\)</span> seems decoupled - can couple together any way you want.) <span class="citation" data-cites="Andrej">@Andrej</span> on this.
<ul>
<li>When state has larger dimension, need overcomplete tensor factorization.</li>
</ul></li>
<li>Start with: given an HMM with both transitions and observations being RBMs (say of degree at most 2), observations don’t “lose info” (analogue of full column rank), infer RBM. (Z is over words that exist). Breaks symmetries - the various dimensions are important now? <!-- sparse vectors are meaningful --></li>
</ul></li>
<li>Dictionary learning experiment
<ul>
<li>The kernel DL I want is different from in the literature. There they want <span class="math inline">\(\Phi(Y) \approx \Phi(A)X\)</span>, here we want <span class="math inline">\(\Phi(Y) \approx \Phi(AX)\)</span>. I.e. we want to maximize <span class="math inline">\(K(Y,AX)\)</span> where <span class="math inline">\(X\)</span> is restricted to be sparse. Usual algorithms break down here, but can still consider <span class="math inline">\(K(Y,AX) + \ve{X}_1\)</span>. (137)</li>
<li>Use kernel in <a href="../../posts/tcs/machine_learning/neural_nets/PMDH16.html">PMDH16</a>.</li>
</ul></li>
<li>RL questions (135)
<ul>
<li>Given a (continuous) space of policies, converge to a local min in the space of policies.</li>
<li>Find some measure of complexity of a class of policies. Branching is important. (Getting limited info from other policies…) Get a bound independent of number of states, involving this complexity.
<ul>
<li>Example to keep in mind: <span class="math inline">\(2^n\)</span> strategies all branching off into different rewards at end of their paths.</li>
<li>Alternatively, complexity of class of models of environment.</li>
</ul></li>
<li>What is the VC dimension bound for contextual (expert) bandits? Also look at the contextual MDP paper, cf. EXP4.</li>
<li>[ALA16] open question</li>
<li>Scraps
<ul>
<li>Right <span class="math inline">\(\la\)</span>, how do well without learning model?</li>
<li>SoS, minimax, etc.</li>
<li>EXP3:Scrible:EXP4::UCB1:?:? (LinUCB? RUCB?)</li>
</ul></li>
<li>Increasing <span class="math inline">\(\ga\)</span> towards 1 (simulated annealing, temperature schedule…)</li>
</ul></li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class="st_facebook_large" displayText="Facebook"></span>
    <span class="st_twitter_large" displayText="Tweet"></span>
    <span class="st_googleplus_large" displayText="Google +"></span>
    <span class="st_reddit_large" displayText="Reddit"></span>
    <span class="st__large" displayText></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>


<!-- Footer -->
<div id="footer">
  <div class="container">
    Built with
    <a href="http://jaspervdj.be/hakyll">Hakyll</a> 
    using 
    <a href="http://www.getbootstrap.com">Bootstrap</a>, 
    <a href="http://www.disqus.com">Disqus</a>,
    <a href="http://ignorethecode.net/blog/2010/04/20/footnotes/">Footnotes.js</a>,
    <a href="http://highlightjs.org/">Highlight.js</a>, 
    <a href="http://www.mathjax.org">MathJax</a>, 
    and <a href="http://www.sharethis.com">ShareThis</a>.
  </div>
</div>
</body>

</html>

<!-- SCRIPTS -->
<!-- jQuery-->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>

<script src="../../bootstrap/js/bootstrap.min.js"></script>

<!-- Extension : Highlight.js @ https://highlightjs.org/ -->
<!-- Syntax highlighting tomorrow-night-bright, agate-->
<link rel="stylesheet" href="../../highlight/css/tomorrow-night-bright.css">
<script src="../../highlight/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<!-- Extension : MathJax @ https://docs.mathjax.org/en/v2.5-latest/tex.html -->
<!-- MathJax/config/local/local.js contains macros. Need to provide entire URL-->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML,http://holdenlee.github.io/notebook/MathJax/config/local/local"></script>

<!-- Extension : Footnotes @ http://ignorethecode.net/blog/2010/04/20/footnotes/ -->
<script src="../../footnotes/js/footnotes.js"></script>

<!-- Extension : Disqus @ http://disqus.com -->
<!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->

<script src="../../disqus/js/disqus.js"></script>



<!-- Extension : Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-73261814-1', 'auto');
  ga('send', 'pageview');

</script>

