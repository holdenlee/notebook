<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

  <meta name="description" content="Holden Lee's Research Notebook">
  <meta name="author" content="Holden Lee">
    
  <title>Weekly summary 2018-11-10</title>

  <!-- Bootstrap core CSS -->
  <link href="../../bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
  <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

  <!-- Custom styles for this template -->
  <link href="../../css/blog.css" rel="stylesheet">
  <link href="../../css/default.css" rel="stylesheet">

  <!-- Extension : Footnotes -->
  <link href="../../footnotes/css/footnotes.css" rel="stylesheet">

  <!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->
  

  <!-- Extension : Collapsible lists @ http://code.stephenmorley.org/javascript/collapsible-lists/-->
  <link href="../../collapsible_lists/css/collapsible.css" rel="stylesheet">
  <script type="text/javascript" src="../../collapsible_lists/js/CollapsibleLists.js"></script>

</head>

<body>

<!-- Navigation bar. navbar-inverse is black, navbar-default is white.-->
<!-- To make a button active (pressed), use <li class="active"> -->
<div id="header">
  <nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../">Notebook</a>
      </div>
      <div id="navbar" class="collapse navbar-collapse">
        <ul class="nav navbar-nav">
          <li><a href="../../">Home</a></li>
          <li><a href="../../sitemap.html">Sitemap</a></li>
<!-- TODO: Distinguish between PAPERS, RESEARCH QUESTIONS, BOOKS -->
<!-- TODO: make this part a for loop over main pages -->
        </ul>
      </div><!--/.nav-collapse -->
    </div>
  </nav>
</div>
<!-- Content -->
<!--div id="content">
  <h1>Mental Wilderness</h1>-->



<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Weekly summary 2018-11-10</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2018-11-07 
          , Modified: 2018-11-07 
	</p>
      
       <p>Tags: <a href="../../tags/none.html">none</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#projects">Projects</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="projects">Projects</h2>
<ul>
<li>Multimodal sampling
<ul>
<li>Show mixing for Dirichlet process sampling. (This is a basic distribution and Markov chain, which is often combined with other things, e.g. in Dirichlet process mixture models.)</li>
<li>Show that Gibbs sampling (keep track of cluster membership, sample from mean, and then re-cluster) with merge/split succeeds for mixture of Gaussians.
<ul>
<li>Big problem: how to do merge/split step.
<ul>
<li>In general this is NP-hard. (2-means is NP-hard.)</li>
<li>Use a good enough proposal distribution, like 1 step of Gibbs in each coordinate.</li>
</ul></li>
<li>First do the well-separated case. Instead of canonical paths, use a “Lyapunov function” argument to show that it’s on average getting closer to the right clustering.</li>
<li>Note I keep track of the cluster assignments, not the means. The cluster assignments can “integrate out” the mixing coefficients, not so with the means (?). (My original idea was to do Gibbs with each mean, hoping it’s a tractable multimodal distribution (mixture of gaussians)</li>
</ul></li>
<li>Tensor decomposition
<ul>
<li>Overcomplete tensor decomposition (noiseless), [GM16]</li>
<li><span class="math inline">\(\la u^{\ot 3} + \rc{\sqrt n}W\)</span>, [ADGM16]</li>
<li>Simply flattening out doesn’t seem to work, because it doesn’t increase the “attraction region.”</li>
<li>Can try convolving with gaussian on the sphere to flatten local minima (but will this increase attraction region? do we need that?)</li>
<li>Check previous notebook first (around 2017/9)</li>
</ul></li>
<li>Short-term long-term memory (Koolen &amp; Warmuth’s problem)
<ul>
<li>This is like clustering but with an exponential factor that disincentivizes switches at adjacent times (the graph is a line). Does that make it easier or harder? Seems like it could be easier since you don’t effectively get <span class="math inline">\(2^n\)</span> possible splits. The split step is simple, you can check all possibilities. (Problem: if local is a lot better than the global… but maybe if generative model is true this won’t be true?)</li>
<li>Use log-concavity.</li>
<li>Or: do sequential MC, e.g. with particle filters, estimating Z.
<ul>
<li>In the generative case, each correct mode will have enough mass (?).</li>
</ul></li>
</ul></li>
<li>Other possibilities
<ul>
<li>Dictionary learning, sparse coding (?). Problem: if not incoherent, can get stuck in local min?</li>
<li>Sparse logistic regression. Phase transitions, hardness results - check them out.</li>
<li>Inspire NN training.
<ul>
<li>Split/merge or delete/add.</li>
</ul></li>
</ul></li>
</ul></li>
<li>Online sampling
<ul>
<li>See followups.</li>
<li>Experiments.</li>
<li>For discrete distributions (main thing: need <span class="math inline">\(f\)</span>’s to change slowly, OK with Gibbs sampling coordinate-by-coordinate, not OK with bipartite Gibbs sampling)</li>
<li>Understand RBM training, how can we help there? What’s the right way to take the stochastic gradient there and can we reduce the variance? (may not satisfy above conditions…)</li>
<li>Check out ICML paper on stochastic gradient Gibbs sampling.</li>
</ul></li>
<li>LDS
<ul>
<li>Main obstacle was “projection to random subspace”, use the insight that directions are almost orthogonal</li>
<li>Identification, using Laplace instead of Fourier, <span class="citation" data-cites="Musco">@Musco</span></li>
</ul></li>
<li>Compositional function spaces: <a href="https://dynalist.io/d/80BlcNrzxATvu5wf__C99MZe#z=Hn0y1aMB_FTQLK7GhugDO15S">dynalist</a></li>
<li>Probabilistic model for grammar</li>
<li>Things to clarify
<ul>
<li>The relationship between sampling and optimization (see [RN], Cesa-Bianchi…)</li>
<li>What is a Bayesian relaxation? What are examples of its use? (Check out “sleeping” - is it an example?) Relationship between the finite (ex. k-means) and infinite (ex. CRP) versions.</li>
</ul></li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class="st_facebook_large" displayText="Facebook"></span>
    <span class="st_twitter_large" displayText="Tweet"></span>
    <span class="st_googleplus_large" displayText="Google +"></span>
    <span class="st_reddit_large" displayText="Reddit"></span>
    <span class="st__large" displayText></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>


<!-- Footer -->
<div id="footer">
  <div class="container">
    Built with
    <a href="http://jaspervdj.be/hakyll">Hakyll</a> 
    using 
    <a href="http://www.getbootstrap.com">Bootstrap</a>, 
    <a href="http://www.disqus.com">Disqus</a>,
    <a href="http://ignorethecode.net/blog/2010/04/20/footnotes/">Footnotes.js</a>,
    <a href="http://highlightjs.org/">Highlight.js</a>, 
    <a href="http://www.mathjax.org">MathJax</a>, 
    and <a href="http://www.sharethis.com">ShareThis</a>.
  </div>
</div>
</body>

</html>

<!-- SCRIPTS -->
<!-- jQuery-->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>

<script src="../../bootstrap/js/bootstrap.min.js"></script>

<!-- Extension : Highlight.js @ https://highlightjs.org/ -->
<!-- Syntax highlighting tomorrow-night-bright, agate-->
<link rel="stylesheet" href="../../highlight/css/tomorrow-night-bright.css">
<script src="../../highlight/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<!-- Extension : MathJax @ https://docs.mathjax.org/en/v2.5-latest/tex.html -->
<!-- MathJax/config/local/local.js contains macros. Need to provide entire URL-->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML,http://holdenlee.github.io/notebook/MathJax/config/local/local"></script>

<!-- Extension : Footnotes @ http://ignorethecode.net/blog/2010/04/20/footnotes/ -->
<script src="../../footnotes/js/footnotes.js"></script>

<!-- Extension : Disqus @ http://disqus.com -->
<!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->

<script src="../../disqus/js/disqus.js"></script>



<!-- Extension : Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-73261814-1', 'auto');
  ga('send', 'pageview');

</script>

