<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

  <meta name="description" content="Holden Lee's Research Notebook">
  <meta name="author" content="Holden Lee">
    
  <title>Fisher information</title>

  <!-- Bootstrap core CSS -->
  <link href="../../../bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
  <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

  <!-- Custom styles for this template -->
  <link href="../../../css/blog.css" rel="stylesheet">
  <link href="../../../css/default.css" rel="stylesheet">

  <!-- Extension : Footnotes -->
  <link href="../../../footnotes/css/footnotes.css" rel="stylesheet">

  <!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->
  

  <!-- Extension : Collapsible lists @ http://code.stephenmorley.org/javascript/collapsible-lists/-->
  <link href="../../../collapsible_lists/css/collapsible.css" rel="stylesheet">
  <script type="text/javascript" src="../../../collapsible_lists/js/CollapsibleLists.js"></script>

</head>

<body>

<!-- Navigation bar. navbar-inverse is black, navbar-default is white.-->
<!-- To make a button active (pressed), use <li class="active"> -->
<div id="header">
  <nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../">Notebook</a>
      </div>
      <div id="navbar" class="collapse navbar-collapse">
        <ul class="nav navbar-nav">
          <li><a href="../../../">Home</a></li>
          <li><a href="../../../sitemap.html">Sitemap</a></li>
<!-- TODO: Distinguish between PAPERS, RESEARCH QUESTIONS, BOOKS -->
<!-- TODO: make this part a for loop over main pages -->
        </ul>
      </div><!--/.nav-collapse -->
    </div>
  </nav>
</div>
<!-- Content -->
<!--div id="content">
  <h1>Mental Wilderness</h1>-->



<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Fisher information</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-04-04 
          , Modified: 2016-04-04 
	</p>
      
       <p>Tags: <a href="../../../tags/none.html">none</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#definitions">Definitions</a></li>
 <li><a href="#intuition">Intuition</a></li>
 <li><a href="#theorems">Theorems</a><ul>
 <li><a href="#cramer-rao">Cramer-Rao</a></li>
 <li><a href="#asymptotic-normality">Asymptotic normality</a></li>
 </ul></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="definitions">Definitions</h2>
Define the <strong>score</strong> and <strong>Fisher information</strong> by
\begin{align}
s(X;\te)&amp;=\pd{\ln f}{\te}\\
I(\te)&amp;=\Var_\te(s(X;\te))
\end{align}
<p>(This generalizes immediately to the multivariate case; for simplicity we consider the univariate case.)</p>
<p>The expecation of score is 0: <span class="math display">\[\E s=\int_{-\iy}^{\iy} s(X;\te) f\,dx=\int_{-\iy}^{\iy} \fc{\ln f}{f}f\dx=(\int_{-\iy}^{\iy}f\,dx)_{\te}=0.\]</span> Thus <span class="math display">\[I(\te) = \Var(s(X;\te)) = \E [(\ln f)_\te^2] = -\E((\ln f)_{\te\te}).\]</span></p>
<h2 id="intuition">Intuition</h2>
<p>Suppose a data point <span class="math inline">\(x\)</span> is observed. What is the posterior distribution on the parameter <span class="math inline">\(\te\)</span>? Consider the log of this probability, the log-likelihood. The Fisher information measures how curved the log-likelihood is at <span class="math inline">\(x\)</span>.</p>
<p>Consider the Fisher information at the MLE. If <span class="math inline">\(I(\te)\)</span> is large, then we are reasonably certain of the value of <span class="math inline">\(\te\)</span> (changing <span class="math inline">\(\te\)</span> by a bit decreases the log-probability of observing <span class="math inline">\(x\)</span> a lot).<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> If <span class="math inline">\(I(\te)\)</span> is small, then we are not certain.</p>
<h2 id="theorems">Theorems</h2>
<h3 id="cramer-rao">Cramer-Rao</h3>
<p><a href="https://en.wikipedia.org/wiki/Cramer-Rao_inequality">Wikipedia</a></p>
<p>This intuition is formalized by Cramer-Rao: the variance of any unbiased estimator for <span class="math inline">\(\te\)</span> is lower-bounded by the inverse of the Fisher information.</p>
<p><strong>Theorem (Cramer-Rao)</strong>: Suppose <span class="math inline">\(T(X)\)</span> is an unbiased estimator of <span class="math inline">\(\te\)</span>. Then <span class="math inline">\(\Var(T) \ge \rc{I(\te)}\)</span>. More generally, <span class="math inline">\(\Var(\psi(T)) \ge \fc{\psi'(\te)}{I(\te)}\)</span>.</p>
<p>In higher dimensions, <span class="math display">\[
Var(T) \succeq \pd{\psi}{\te} I^{-1}\pd{\psi}{\te}.
\]</span></p>
<p><em>Proof</em>: Suppose <span class="math inline">\(T=t(x)\)</span>. By Cauchy-Schwarz, <span class="math display">\[
\Var(T) \ge \fc{\text{Covar}(T,s_\te)^2}{\Var(s_\te)} = \fc{\int t(x)f (\ln f_\te)}{I(\te)} = \fc{\int g(x) f_{\te}(x)}{I(\te)}
=\fc{(\E g)_\te}{I(\te)}= \rc{I(\te)}.
\]</span> <!--randomized? --></p>
<h3 id="asymptotic-normality">Asymptotic normality</h3>
<!-- 3/16 p. 197-->
<p>Define the <strong>standard error</strong> by <span class="math inline">\(\se=\sqrt{\Var_\te(\wh{\te_n})}\)</span>.</p>
<p><strong>Theorem (Asymptotic normality of MLE)</strong>: <span class="math inline">\(\se\sim \sfc1{nI(\te)}\)</span> and <span class="math inline">\(\fc{\wh{\te_n}-\te}{\se}\to N(0,1)\)</span>.</p>
<p>(With a little more work, we can replace se by <span class="math inline">\(\wh{se}\)</span> (estimated standard error).)</p>
<p><em>Proof</em>: Denoting the log-likelihood by <span class="math inline">\(\ell(\te):= \ln \Pj(x^n|\te) = \sum_{i=1}^n \ln f(x_i;\te)\)</span>, linearize to find that <span class="math display">\[
\ell'(\wh \te)-\ell'(\te)\approx (\wh \te-\te)(\ell''(\te))\implies -\fc{\ell'}{\ell''}(\te)\approx \wh{\te}-\te.
\]</span> Now <span class="math display">\[
\sqrt n(\wh{\te_n}-\te)=\fc{\rc{\sqrt n}\ell'(\te)}{-\rc n\ell''(\te)}\to \fc{N(0,I(\te))}{I(\te)}\to N(0,1),
\]</span> the top in distribution, the bottom in probability. (The top uses CLT on <span class="math inline">\(\sum (\ln f)_\te\)</span>; the bottom uses LoLN on <span class="math inline">\(\sum -(\ln f)_{\te\te}\)</span>.)</p>
<!--
Define some quantities first.
\begin{df}
\begin{enumerate}
\item
\textbf{KL distance}
\[
D(f,g)=\int f(x)\ln \pf{f}{g}\,dx.
\]
Why do we care about this? Maximizing $\ell_n(\te)$ is equivalent to maximizing 
\[
M_n(\te)=\rc n\sum_i\ln \fc{f(X_i;\te)}{f(X_i;\te_*)}
\]
which has the nice property that the maximum is 0. (Without the $\rc n$ it would blow up.) By LLN the expected value of this is exactly $-D(\te_*,\te)$.
\item 
\textbf{score function} $s(X;\te)=\pd{\ln f}{\te}$.

Important property: $\E s=\int_{-\iy}^{\iy} s(X;\te) f\,dx=(\int_{-\iy}^{\iy}f\,dx)_{\te}=0$. 
\item
\textbf{Fisher information} $I(\te)=\Var_\te(s(X;\te))$, $I_n(\te)=nI(\te)$.
I.e., $I(\te)=-\E((\ln f)_{\te\te})$.
\end{enumerate}
\end{df}

\begin{enumerate}
\item
\begin{thm}[Convergence of MLE]
Suppose 
\begin{enumerate}
\item
$\sup_{\te\in \Te}|M_n(\te)-M(\te)|\xra{P}0$,
\item
for all $\ep>0$, $\sup_{|\te-\te_*|\ge\ep} M(\te)<M(\te_*)$.
\end{enumerate}
Then the MLE $\wh{\te_n}\xra P\te_*$.
\end{thm}
\begin{proof}
First show that $M(\te_*)-M(\wh{\te_n})\xra P0$. Then use continuity of $M$.
\end{proof}
\item
\begin{thm}[Asymptotic normality of MLE]
\begin{enumerate}
\item
$\se\sim \sfc1{nI(\te)}$ and $\fc{\wh{\te_n}-\te}{\se}\to N(0,1)$.
\item \fixme{$\wh{\se}=\sfc{1}{nI(\wh{\te_n})}$: why are we redefining $\wh{\se}$? We defined it a different way before. Do these definitions coincide?}
$\fc{\wh{\te_n}-\te}{\wh{\se}}\to N(0,1)$.
\end{enumerate}
\end{thm}
\begin{proof}
\begin{enumerate}
\item
Linearize to find that
\[
\ell'(\wh \te)-\ell'(\te)\approx (\wh \te-\te)(\ell''(\te))\implies -\fc{\ell'}{\ell''}(\te)\approx \wh{\te}-\te.
\]
Now
\[
\sqrt n(\wh{\te_n}-\te)=\fc{\rc{\sqrt n}\ell'(\te)}{-\rc n\ell''(\te)}\to \fc{N(0,I(\te))}{I(\te)}\to N(0,1),
\]
the top in distribution, the bottom in probability. (The top uses CLT on $\sum (\ln f)_\te$; the bottom uses LoLN on $\sum -(\ln f)_{\te\te}$.)
\item
Show that $\sfc{I(\wh{\te_n})}{I(\te)}\xra P 1$.
\end{enumerate}
\end{proof}
\item Think of this as a chain rule.
\begin{thm}
If $\tau=g(\te)$ and $g'(\te)\ne 0$, then $\fc{\wh{\tau_n}-\tau}{\wh{\se}(\wh{\tau})}\to N(0,1)$ where $\wh{\tau_n}=g(\wh{\te_n}),\wh{\se}(\wh{\tau_n})=|g'(\wh{\tau})|\wh{\se}(\wh{\tau_n})$.
\end{thm}
Proof: just expand $g$ using $g'$.
\item (Equivariance) If $\tau=g(\te)$ is 1-to-1, then $\wh{\tau_n}=g(\wh{\te_n})$. Follow definitions!
\end{enumerate}
-->
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>For sake of discussion suppose the log-likelihood function is convex in <span class="math inline">\(\te\)</span>, so there aren’t other local minima.<a href="#fnref1">↩</a></p></li>
</ol>
</section>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class="st_facebook_large" displayText="Facebook"></span>
    <span class="st_twitter_large" displayText="Tweet"></span>
    <span class="st_googleplus_large" displayText="Google +"></span>
    <span class="st_reddit_large" displayText="Reddit"></span>
    <span class="st__large" displayText></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>


<!-- Footer -->
<div id="footer">
  <div class="container">
    Built with
    <a href="http://jaspervdj.be/hakyll">Hakyll</a> 
    using 
    <a href="http://www.getbootstrap.com">Bootstrap</a>, 
    <a href="http://www.disqus.com">Disqus</a>,
    <a href="http://ignorethecode.net/blog/2010/04/20/footnotes/">Footnotes.js</a>,
    <a href="http://highlightjs.org/">Highlight.js</a>, 
    <a href="http://www.mathjax.org">MathJax</a>, 
    and <a href="http://www.sharethis.com">ShareThis</a>.
  </div>
</div>
</body>

</html>

<!-- SCRIPTS -->
<!-- jQuery-->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>

<script src="../../../bootstrap/js/bootstrap.min.js"></script>

<!-- Extension : Highlight.js @ https://highlightjs.org/ -->
<!-- Syntax highlighting tomorrow-night-bright, agate-->
<link rel="stylesheet" href="../../../highlight/css/tomorrow-night-bright.css">
<script src="../../../highlight/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<!-- Extension : MathJax @ https://docs.mathjax.org/en/v2.5-latest/tex.html -->
<!-- MathJax/config/local/local.js contains macros. Need to provide entire URL-->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML,http://holdenlee.github.io/notebook/MathJax/config/local/local"></script>

<!-- Extension : Footnotes @ http://ignorethecode.net/blog/2010/04/20/footnotes/ -->
<script src="../../../footnotes/js/footnotes.js"></script>

<!-- Extension : Disqus @ http://disqus.com -->
<!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->

<script src="../../../disqus/js/disqus.js"></script>



<!-- Extension : Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-73261814-1', 'auto');
  ga('send', 'pageview');

</script>

