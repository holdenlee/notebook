<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Research Notebook</title>
    <link href="http://holdenlee.github.io/notebook/atom.xml" rel="self" />
    <link href="http://holdenlee.github.io/notebook" />
    <id>http://holdenlee.github.io/notebook/atom.xml</id>
    <author>
        <name>Holden Lee</name>
        <email>oldheneel@gmail.com</email>
    </author>
    <updated>2017-02-21T00:00:00Z</updated>
    <entry>
    <title>Adversarial examples in neural networks</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/neural_nets/adversarial.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/neural_nets/adversarial.html</id>
    <published>2017-02-21T00:00:00Z</published>
    <updated>2017-02-21T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Adversarial examples in neural networks</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-21 
          , Modified: 2017-02-21 
	</p>
      
       <p>Tags: <a href="/tags/neural%20nets.html">neural nets</a>, <a href="/tags/uncertainty.html">uncertainty</a>, <a href="/tags/aaml.html">aaml</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#introduction">Introduction</a><ul>
 <li><a href="#statement">Statement</a></li>
 <li><a href="#literature">Literature</a></li>
 <li><a href="#experiments">Experiments</a></li>
 <li><a href="#theory">Theory</a></li>
 </ul></li>
 <li><a href="#lcls17-delving-into-transferable-adversarial-examples">[LCLS17] Delving into Transferable Adversarial Examples</a><ul>
 <li><a href="#experiments-1">Experiments</a></li>
 <li><a href="#ensemble-based-approaches">Ensemble-based approaches</a></li>
 <li><a href="#geometry">Geometry</a></li>
 </ul></li>
 <li><a href="#questions">Questions</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="introduction">Introduction</h2>
<h3 id="statement">Statement</h3>
<p>Neural networks can be easily fooled—ex. an adversary adding a small amount of noise can change the classification from “dog” to “cat” with high confidence. It can be fooled even by a weak adversary with just black-box access!</p>
<p>Related to making NN’s resistant: Have NN’s give a confidence bound.</p>
<p>Ideas:</p>
<ul>
<li>Use uncertainty quantification from statistics: Fisher information. See personal communication with Jacob.</li>
<li>Use an ensemble of neural nets. Train an ensemble in parallel, vs. train together against a discriminator.</li>
<li>Sleeping in NN</li>
<li>Use some kind of calibration</li>
<li>Active learning</li>
<li>Make Lipschitz/other regularization. Give noisy example with the kind of noise you want to be resistant against.</li>
<li>Boosting</li>
</ul>
<h3 id="literature">Literature</h3>
<ul>
<li>[SZSB14] Intriguing properties of neural networks <a href="https://arxiv.org/pdf/1312.6199.pdf?not-changed">paper</a></li>
<li>Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014.</li>
<li></li>
<li></li>
<li>[LCLS17] Delving into Transferable Adversarial Examples and Black-box Attacks</li>
</ul>
<h3 id="experiments">Experiments</h3>
<ul>
<li>Reproduce adversarial examples result on a simple dataset, e.g. MNIST.</li>
<li>Try training an ensemble of NN in parallel and compare to predictions of a single one.</li>
</ul>
<h3 id="theory">Theory</h3>
<ul>
<li>Think in terms of learning theory, VC dimension…</li>
</ul>
<h2 id="lcls17-delving-into-transferable-adversarial-examples">[LCLS17] Delving into Transferable Adversarial Examples</h2>
<ol type="1">
<li>Model, training data, training process, test label set unknown to attacker.</li>
<li>Large dataset (ImageNet)</li>
<li>Do not construct substitute model</li>
</ol>
<p>What is the difference between targeted and non-targeted transferability?</p>
<ol type="1">
<li>Non-targeted: <span class="math inline">\(x^*\approx x\)</span>, <span class="math inline">\(f_\te(x^*)\ne f_\te(x) = y\)</span>. (Constrain <span class="math inline">\(d(x,x^*)\le B\)</span>.)</li>
<li>Targeted: <span class="math inline">\(x^*\approx x\)</span>, <span class="math inline">\(f_\te(x^*)=y^*\)</span>.</li>
</ol>
<p>3 approaches: Suppose <span class="math inline">\(f = \max_i J_\te(x)_i\)</span>, where <span class="math inline">\(J_\te(x)\)</span> is vector of probabilities.</p>
<ol type="1">
<li>Optimization <span class="math inline">\(\amin_{x^*} \la d(x,x^*) - \ell(\one_y, J_\te(x^*))\)</span>. Ex. <span class="math inline">\(\ell(u,v) = \ln (1-u\cdot v)\)</span>.</li>
<li>Fast gradient <span class="math inline">\(x^* \leftarrow \text{clamp}(x+B\sign (\nb_x \ell(\one_y, J_\te(x))))\)</span>.</li>
<li>Fast gradient sign <span class="math inline">\(x^* \leftarrow \text{clamp}\pa{x+B\nv{\nb_x\ell(\one_y, J_\te(x))}}\)</span>.</li>
</ol>
<p>Approaches for targeted: Replace constraint with <span class="math inline">\(f_\te(x^*)=y^*\)</span></p>
<ol type="1">
<li>Optimization <span class="math inline">\(\amin_{x^*} \la d(x,x^*) \redd{+} \redd{\ell'(\one_{y^*}}, J_\te(x^*))\)</span>. Ex. <span class="math inline">\(\ell'(u,v) = \redd{-\sum_i u_i \lg v_i}\)</span>.</li>
<li>Fast gradient <span class="math inline">\(x^* \leftarrow \text{clamp}(x\redd{-}B\sign (\nb_x \redd{\ell'(\one_{y^*}}, J_\te(x))))\)</span>.</li>
<li>Fast gradient sign <span class="math inline">\(x^* \leftarrow \text{clamp}\pa{x\redd{-}B\nv{\nb_x\redd{\ell'(\one_y}, J_\te(x))}}\)</span>.</li>
</ol>
<h3 id="experiments-1">Experiments</h3>
<p>Choose 100 images (ILSVRC2012 dataset) which can be correctly classified by all 5 models.</p>
<p>Non-target transferability: accuracy = percentage of adversarial examples for one model correctly classified for the other. (For NN to be good, want this to be high)</p>
<p>Targeted transferability: matching rate = percentage of adversarial examples classified as target label by other model. (Want this to be low)</p>
<p>Root mean square deviation <span class="math inline">\(d(x^*,x) = \sfc{\sum_i (x_i^*-x_i^2)}{N}\)</span>.</p>
<p>Q: isn’t the optimizer using gradient information? (We can estimate it by sampling though!)</p>
<p>Use small learning rate to generate images with RMSD&lt;2. Actually can set <span class="math inline">\(\la=0\)</span>.</p>
<p>(Accuracy is low. But what is the confidence?)</p>
<ul>
<li>Optimization can mislead the models.</li>
<li>FG cannot fully mislead the models. A potential reason is that, FG can be viewed as approximating the optimization, but is tailored for speed over accuracy.</li>
</ul>
<p>Find the minimal transferable RMSD by linear search.</p>
<p>Note FGS minimizes distortion’s <span class="math inline">\(L_\iy\)</span> norm while FG minimizes <span class="math inline">\(L_2\)</span> norm.</p>
<p>Target labels do not transfer. Fast gradient-based approaches don’t do well because they only search in 1-D subspace.</p>
<h3 id="ensemble-based-approaches">Ensemble-based approaches</h3>
<p>These do better! If an adversarial image remains adversarial for multiple models, it is more likely to transfer to other models. <span class="math display">\[
\amin_{x^*} -\ln \pa{\pa{\sumo ik \al_i J_i(x^*)}\cdot \one_{y^*}} + \la d(x,x^*)
\]</span> For each of the five models, we treat it as the black-box model to attack, and generate adversarial images for the ensemble of the rest four, which is considered as white-box. This attack does well!</p>
<p>Non-targeted adversarial images have almost perfect transferability!</p>
<p>Fast gradient doesn’t work with ensemble.</p>
<h3 id="geometry">Geometry</h3>
<ul>
<li>The gradient directions of different models in our evaluation are almost orthogonal to each other. - this makes sense</li>
<li>Choose 2 orthogonal directions, one being a gradient direction. There are up to 21 different regions
<ul>
<li>Boundaries align well.</li>
<li>Boundary diameter along gradient direction smaller. (Even in the direction of increasing the prediction probability!)</li>
</ul></li>
</ul>
<h2 id="questions">Questions</h2>
<ul>
<li>Can you use adversarial examples to improve training?</li>
<li>What if you try denoising first?</li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Weekly summary 2017-02-25</title>
    <link href="http://holdenlee.github.io/notebook/posts/summaries/2017-02-25.html" />
    <id>http://holdenlee.github.io/notebook/posts/summaries/2017-02-25.html</id>
    <published>2017-02-21T00:00:00Z</published>
    <updated>2017-02-21T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Weekly summary 2017-02-25</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-21 
          , Modified: 2017-02-21 
	</p>
      
       <p>Tags: <a href="/tags/neural%20nets.html">neural nets</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#adversarial-examples-in-neural-networks">Adversarial examples in neural networks</a><ul>
 <li><a href="#statement">Statement</a></li>
 <li><a href="#literature">Literature</a></li>
 <li><a href="#experiments">Experiments</a></li>
 <li><a href="#theory">Theory</a></li>
 </ul></li>
 <li><a href="#diversity-in-ml">Diversity in ML</a><ul>
 <li><a href="#literature-1">Literature</a></li>
 </ul></li>
 <li><a href="#gans">GANs</a></li>
 <li><a href="#decision-theory-and-logical-induction">Decision theory and logical induction</a></li>
 <li><a href="#pomdp">POMDP</a></li>
 <li><a href="#alexa">Alexa</a></li>
 <li><a href="#logic-and-ml">Logic and ML</a></li>
 <li><a href="#meta">Meta</a></li>
 <li><a href="#blogging">Blogging</a></li>
 <li><a href="#learning">Learning</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="adversarial-examples-in-neural-networks">Adversarial examples in neural networks</h2>
<p><a href="/posts/tcs/machine_learning/neural_nets/adversarial.html">main page</a></p>
<h3 id="statement">Statement</h3>
<p>Neural networks can be easily fooled—ex. an adversary adding a small amount of noise can change the classification from “dog” to “cat” with high confidence. It can be fooled even by a weak adversary with just black-box access!</p>
<p>Related to making NN’s resistant: Have NN’s give a confidence bound.</p>
<p>Ideas:</p>
<ul>
<li>Use uncertainty quantification from statistics: Fisher information. See personal communication with Jacob.</li>
<li>Use an ensemble of neural nets. Train an ensemble in parallel, vs. train together against a discriminator.</li>
<li>Sleeping in NN</li>
<li>Use some kind of calibration</li>
<li>Active learning</li>
<li>Make Lipschitz/other regularization.</li>
<li>Boosting</li>
</ul>
<h3 id="literature">Literature</h3>
<ul>
<li>[SZSB14] Intriguing properties of neural networks <a href="https://arxiv.org/pdf/1312.6199.pdf?not-changed">paper</a></li>
<li>Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014.</li>
<li>Papernot 2016</li>
<li>[LCLS17] Delving into Transferable Adversarial Examples and Black-box Attacks</li>
</ul>
<h3 id="experiments">Experiments</h3>
<ul>
<li>Reproduce adversarial examples result on a simple dataset, e.g. MNIST.</li>
<li>Try training an ensemble of NN in parallel and compare to predictions of a single one.</li>
</ul>
<h3 id="theory">Theory</h3>
<ul>
<li>Think in terms of learning theory, VC dimension…</li>
</ul>
<h2 id="diversity-in-ml">Diversity in ML</h2>
<h3 id="literature-1">Literature</h3>
<ul>
<li>Putting Bayes to Sleep</li>
<li>[KPRV17] Overcoming catastrophic forgetting in neural networks</li>
</ul>
<h2 id="gans">GANs</h2>
<p>The original formulation of GANs is plagued by many mathematical problems. What are mathematically better alternatives?</p>
<ul>
<li>Wasserstein GAN</li>
<li>Neural net GAN</li>
</ul>
<h2 id="decision-theory-and-logical-induction">Decision theory and logical induction</h2>
<p>See page on decision/game theory.</p>
<ul>
<li>UDT</li>
<li>Reflective oracles</li>
<li>Background on logic and provability</li>
<li>Logical induction: the daemon (rocket) problem &lt;&gt; sleeping?</li>
</ul>
<h2 id="pomdp">POMDP</h2>
<p>Anchor POMDPs.</p>
<p>What are real-life problems involving POMDPs?</p>
<h2 id="alexa">Alexa</h2>
<ul>
<li>Entity extraction and feeding into knowledge graphs
<ul>
<li>Structured knowledge graphs?</li>
</ul></li>
<li>Recognize simple queries in a reflective manner - maybe building on AIML</li>
<li>Formalize modes of conversation</li>
<li>Look at semantic parsing literature</li>
<li>What kind of experiments could I run?</li>
<li>Look for examples of conversations on popular topics. Try to engage in them.</li>
<li>Do a web search with heuristics.</li>
</ul>
<h2 id="logic-and-ml">Logic and ML</h2>
<p>???</p>
<h2 id="meta">Meta</h2>
<p>What is good research?</p>
<h2 id="blogging">Blogging</h2>
<ul>
<li>Diversity series
<ul>
<li>Trees</li>
<li>Diversity in ML</li>
</ul></li>
<li>Boosting, etc.</li>
<li>Logical induction</li>
</ul>
<h2 id="learning">Learning</h2>
<ul>
<li>Boosting, etc.</li>
<li>RL</li>
<li>TF in Haskell!</li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Questions</title>
    <link href="http://holdenlee.github.io/notebook/posts/math/logic/questions.html" />
    <id>http://holdenlee.github.io/notebook/posts/math/logic/questions.html</id>
    <published>2017-02-19T00:00:00Z</published>
    <updated>2017-02-19T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Questions</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-19 
          , Modified: 2017-02-19 
	</p>
      
       <p>Tags: <a href="/tags/logic.html">logic</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"></div>

  <div class="blog-main">
    <p>Things I’m confused about.</p>
<ul>
<li>I’m uncomfortable with theorems in the meta-logic. How do you define the meta-logic without infinite recursion (meta-meta, etc.)? Godel incompleteness, etc. are NOT theorems in the logic, but the meta-logic—if you want them as theorems in the logic then you have to define the logic inside the logic—there’s no reflection, right? Because that would be <span class="math inline">\(\square A to A\)</span>.</li>
<li>What did I mean by reflection?</li>
<li>Nesting is unsatisfactory…</li>
<li>Is <span class="math inline">\(PA\vdash A\implies PA\vdash B \iff PA\vdash \square A \to \square B\)</span> a theorem in the meta-logic?</li>
<li>Is <span class="math inline">\(PA\vdash \square A\implies PA\vdash A\)</span> a theorem in the meta-logic? An axiom?</li>
<li>How do you define “truth” in the meta-logic?</li>
<li>Is <span class="math inline">\(\square \square A \to \square A\)</span> a theorem?</li>
<li>Is <span class="math inline">\(PA\vdash \square A \to \square B, PA\vdash A \implies PA\vdash B\)</span>? How about <span class="math inline">\(PA\vdash \square (\square A \to \square B)\wedge \square A \to \square B\)</span>?</li>
<li>Can you add quantifiers? Is it true that <span class="math inline">\(\forall x, \square P(x) \imples \square \forall x, P(x)\)</span>? My guess is not (at least, it can’t be proved). Should <span class="math inline">\(\square\)</span> be Bew here? I think you’re not allowed to use <span class="math inline">\(\square\)</span> here, but that’s ok, you can state it with Bew. <span class="math inline">\(\square\)</span> is interpreted as <span class="math inline">\(Bew(\ce{})\)</span> in PA, right?</li>
<li>Is <span class="math inline">\((\square A \to \square B) \to \square (A\to B)\)</span> a theorem?</li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>UDT</title>
    <link href="http://holdenlee.github.io/notebook/posts/cs/ai/control/udt.html" />
    <id>http://holdenlee.github.io/notebook/posts/cs/ai/control/udt.html</id>
    <published>2017-02-19T00:00:00Z</published>
    <updated>2017-02-19T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>UDT</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-19 
          , Modified: 2017-02-19 
	</p>
      
       <p>Tags: <a href="/tags/ai%20safety.html">ai safety</a>, <a href="/tags/game%20theory.html">game theory</a>, <a href="/tags/decision%20theory.html">decision theory</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"></div>

  <div class="blog-main">
    <p>Main notes <a href="game_theory.html">here</a>.</p>
<ul>
<li>It seems we don’t need to quine - we can just view A, U as functions of each other’s source codes. Just impose some halting criterion. Then just evaluate <span class="math inline">\(U(\ce{A})\)</span>… Oh, but how does U give A its own code?
<ul>
<li>External program runs them? I don’t like this.</li>
<li>I don’t like co-quining them because then I feel I lose the algorithmic interpretability - now I don’t feel like they’re programs anymore. For some reason I’m having trouble thinking about quines in terms of programs, I can think about them in terms of logic statements.</li>
<li>I think the programs should handle the quining themselves. Ah. If U doesn’t quine itself, it has no way of running A with its own source code. So U is a quine in the sense that it can give A its own source code. This solves things. Otherwise, U would not be able to run A. A also has incentive to quine itself, otherwise it cannot simulate U on A, or prove statements about itself.</li>
<li>Can a non-quined program be taken advantage of?</li>
<li>Wait, but writing the code I didn’t do any quining!</li>
<li>Oh, you can just assume U, A can run themselves. You assume they’re quined for convenience in reasoning about them, but you don’t actually need them to be quined themselves.</li>
<li>Quining is just the way in logic to get access to own source code - in programming you don’t need to do it explicitly because the source code is in the file.</li>
<li>Do you need to quine for corecursion?</li>
<li>I don’t think any of this is important–they’re all basically taken care of by the programming language.</li>
<li>! You can’t separate what the agent does from who it is: ex. why you can’t just feed all possible functions into something else, then let yourself be the best function. The other agent would act differently against that function vs. against you. Ex. playing against PrudentBot, PrudentBot defects against both <code>const c</code> and <code>const d</code>, if these are the only things you’re trying, you’ll just defect!</li>
<li>For U/A say the agent has fixed runtime, the universe has finite runtime (alternatively it can rely on the truth of logical statements). For A/A say both have fixed (large) runtime.</li>
</ul></li>
<li>What if we want U to have access to some oracle? How can we ensure that we can actually prove the output of U? Can this be made equivalent to the condition that U halts?</li>
<li>Is there a way to implement these agents without having them search for proofs? Ex. do “lazy evaluation?” I don’t see a way to do this.</li>
<li>If <code>fairBot x = (if x coopBot == c then c else d)</code> then</li>
<li>I want to say something like, there’s a sequence Bot1, Bot2,… with longer lookbacks, and Bot-k outperforms Bot-(k-1) by “pretending” to be something that Bot-(k-1) will cooperate with and then stabbing it in the back… this seems to be going the other way.</li>
<li>Why do we keep talking about “embedded” agents?</li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>The Blessing and the Curse of the Multiplicative Updates</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/optimization/multiplicative_update.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/optimization/multiplicative_update.html</id>
    <published>2017-02-12T00:00:00Z</published>
    <updated>2017-02-12T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>The Blessing and the Curse of the Multiplicative Updates</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-12 
          , Modified: 2017-02-12 
	</p>
      
       <p>Tags: <a href="/tags/multiplicative%20update.html">multiplicative update</a>, <a href="/tags/online%20learning.html">online learning</a>, <a href="/tags/biology.html">biology</a>, <a href="/tags/evolution.html">evolution</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#dispelling-the-curse">Dispelling the curse</a></li>
 <li><a href="#summary">Summary</a></li>
 </ul> </div>

  <div class="blog-main">
    <p>(Chapter by Manfred Warmuth)</p>
<p>Setting: online learning</p>
<p>Maintain weights where <span class="math inline">\(w_i\)</span> is the belief that the <span class="math inline">\(i\)</span>th expert is best. Prediction: weighted average.</p>
<p>Multiplicative updates motivated by minimum relative entropy principle. Simplest is Bayes’s rule for updating priors.</p>
<blockquote>
<p>The “blessing” of these updates is that they learn very fast in the short term because the good weights grow exponentially. However, their “curse” is that they learn too fast and wipe out other weights too quickly. This loss of variety can have a negative effect in the long term because adaptivity is required when there is a change in the process generating the data stream.</p>
</blockquote>
<blockquote>
<p>Surprisingly, some of Nature’s methods parallel the ones developed in machine learning, but Nature also has some additional tricks.</p>
</blockquote>
<p>Evolution on 2 scales:</p>
<ul>
<li>Short-term: mutation and selection (multiplicative update)</li>
<li>Long-term: stability - requires mechanism for preventing quick convergence to currently fittest strategy or gene.</li>
</ul>
<p><span class="math display">\[
\wt s_i = \fc{s_ie^{-\eta \text{loss}_i}}{Z}
= \amin_{r\in \R^n, \sum_i r_i=1} \sum_i KL(r||s) + \eta\sum_i r_il_i
\]</span> Relative entropy keeps <span class="math inline">\(\wt s\)</span> close to <span class="math inline">\(s\)</span>. <span class="math inline">\(\eta\)</span> is tradeoff parameter. <span class="math inline">\(W_i = e^{-\eta l_i}\)</span> is the fitness of strategy <span class="math inline">\(i\)</span>. Bayes Rule: expected log loss, <span class="math inline">\(\eta=1\)</span>.</p>
<p>(systematic way of deriving such updates by trading off a relative entropy between the new and old weight vector with a loss function that measures how well the weights did on the current instance vector)</p>
<p>Why multiplicative, not additive update? Converge quickly when data stream generating process is static.</p>
<p>Problem: data changes over time. MU loss of variety.</p>
<p>Use of MU: separate good/bad RNA, reamplify good. Loop. Use PCR.</p>
<p>Assumption: <span class="math inline">\(W_i\)</span> independent of share vector <span class="math inline">\(s\)</span>. (Otherwise: apostatic effects.) <span class="math inline">\(\wt s_i = \fc{w_iW_i}{\an{s,W}}\)</span>.</p>
<p>In-vitro selection: iterate Bayes with same data likelihoods.</p>
<blockquote>
<p>“brittle” because the gradients of the losses appear in the exponents of the update factors. This is problematic when there is noise in the data and the data-generating process changes over time</p>
</blockquote>
<p>Compounded: weights have constant precision.</p>
<p>Curse is extinctino in nature.</p>
<h3 id="dispelling-the-curse">Dispelling the curse</h3>
<p>Ex. Bacteria in nutriet solution separate into 3 niches, 3 species. Mixing kills all but one.</p>
<blockquote>
<p>three species of bacteria that play an RPS game. When started on a Petri dish, colonies of each species develop that slowly chase each other around the dish: R invades S’s colonies, S invades P, and P invades R</p>
</blockquote>
<ol type="1">
<li>Niche boundaries help prevent the curse. (Human: multiplicative update of meme shares causes loss of variety.)
<ul>
<li>Key problem 1 (that cannot be solved by MU alone): There are three strands of RNA in a tube and the goal is to amplify the mixture while keeping the percentages of the strands unchanged. This is to be done without sequencing the strands and determining their concentrations.
<ul>
<li>Solution: Translate to (double stranded) DNA and using an enzyme, add a specific short “end strand” to both ends of all strands in the tube. These end strands function as connectors between strands and make it possible to randomly ligate many strands together into long strands. Now separate out one long strand. With the help of an enzyme, add “primer strands” to both ends of that long strand. Apply PCR iteratively starting with the long selected strand, always making complete copies of the same original long strand that is located between the primers. Stop when you have the target amount of DNA. Now divide the long strands into their constituents by cutting them at the specific end strand that functioned as the connector. Finally, remove all short primer and end strands and convert back to RNA.</li>
<li>The long strand functions as a “chromosome.” Free floating genes in the nuclei of cells would compete.</li>
</ul></li>
</ul></li>
<li>Coupling preserves diversity.
<ul>
<li>Genes on chromosome selected for together; genes “cooperate” for sake of efficient copying.</li>
<li>What updates can be implemented with in-vitro selection/blind computation? Can you have negative weights?</li>
<li><span class="math inline">\(EG^{\pm}\)</span> algorithm: maintain 2 weight vectors <span class="math inline">\(s^+,s^-\in \R^n\)</span>. Label <span class="math inline">\((s^+-s^-)\cdot x\)</span>, loss <span class="math inline">\(L((s^+-s^-)\cdot x,y) = ((s^+-s^-_)\cdot x-y)^2\)</span> so that fitness is inverse.</li>
<li>Problem 2: find small set of RNA strands that can bind to <span class="math inline">\(q\)</span> different protein sheets. (Assume that among all strands in a 1-liter tube of RNA, there is a particular set of two strands such that for each of q proteins, at least one of the two has a high fraction of attachment. Can you use PCR to get <span class="math inline">\(\approx (0.5, 0.5, 0,\ldots)\)</span>?)
<ul>
<li>First idea: cycle through <span class="math inline">\(q\)</span> proteins and do in-vitro selection.</li>
<li>Problem: overselecting can kill off one.</li>
<li>ML problem: <span class="math inline">\(\exists u\)</span> with <span class="math inline">\(k\)</span> nonzeros of value <span class="math inline">\(\rc k\)</span>, <span class="math inline">\(u\cdot W_j\ge \rc k\)</span>. Find <span class="math inline">\(s\)</span> with <span class="math inline">\(s\cdot W_j \ge \rc{2k}\)</span>.</li>
<li>Normalized winnow algorithm: If <span class="math inline">\(s\cdot W_j\ge \rc{2k}\)</span>, then <span class="math inline">\(\wt s=s\)</span> (conservative update), else apply MU.</li>
</ul></li>
<li>ML 1: Prevent over-training by making the update conservative.</li>
<li>in the context of in-vitro selection this means that RNA strands that attached to the protein sheet are simply recombined into the tube without the PCR amplification step.</li>
<li>the amplification step occurs at most <span class="math inline">\(O(k\log \fc Nk)\)</span> times if there is a consistent k-literal disjunction and this is information theoretically optimal. Grows logarithmically in <span class="math inline">\(n\)</span>.</li>
<li>If select for <span class="math inline">\(\binom nk\)</span> combinations, not necessary to be conservative. But this is too large.</li>
<li>Coupling can be replaced by thresholding.</li>
<li>Cap shares/weight from above.</li>
</ul></li>
<li>Super (apex) predator.
<ul>
<li>Nibbles at the highest bar of the histogram of possible prey species. (Removing it causes this species to take over.) The more frequent a species, the more opportunity for a disease to spread and this can keep a species from taking over.</li>
<li>ML2: Cap the weights from above for the purpose of learning a set of experts.</li>
<li>After MU: all weights that exceed c are reduced to c and the total weight gained is redistributed among the remaining components that lie below c so that their ratios are preserved and the total weight still sums to one. (cf. exploration, <span class="math inline">\(\ep\)</span>-greedy.)</li>
<li>capping solves a constrained optimization problem.</li>
<li>Ex. constrain to be in convex hull of <span class="math inline">\(k\)</span>-corners. This still only needs <span class="math inline">\(n\)</span> weights.</li>
<li>In matrix MU, share vectors are density matrices - prob vector of eigenvalues</li>
<li>quantum relative entropy instead of the regular relative entropy</li>
<li>MMU with capping on eigenvalues: PCA. <span class="math inline">\(k\)</span> experts become <span class="math inline">\(k\)</span>-dim subspace. Capped density matrices are convex combs of <span class="math inline">\(k\)</span>-dim subspaces.</li>
<li>relating: lower bound shares.</li>
<li>keep a batch of the initial mixture in reserve. When too uniform, add some!</li>
<li>Disk spindown problem.</li>
<li><span class="math inline">\(\wt s = (1-\al) s^m + \al \rc N\one\)</span>.</li>
</ul></li>
<li>Mutations keep a base variety.
<ul>
<li>Data shifts once in a while and some are a return back to data seen previously. Need:</li>
<li>Capability to bring up shares quickly.</li>
<li>Remember experts that did well in past. (Sleeping)</li>
<li>ML4: Sleeping realizes long-term memory.</li>
<li>Keep track of average share vector, mix in <span class="math inline">\(\al\)</span> of <span class="math inline">\(r\)</span>.</li>
<li>Markov network with 2 tracks (tubes).</li>
<li>It is reasonable to expect that Nature makes use of the sleeping mechanism as well. (Seed sprouting.)</li>
</ul></li>
</ol>
<p>How is sleeping realized at genetic level. Junk DNA, sex?</p>
<h2 id="summary">Summary</h2>
<p>Machine Learning mechanisms:</p>
<ol type="1">
<li>conservative update for learning multiple goals</li>
<li>upper bounding weights for learning multiple goals</li>
<li>lower bounding weights for robustness against change</li>
<li>sleeping for realizing a long-term memory.</li>
</ol>
<p>Nature’s mechanisms:</p>
<ol type="1">
<li>coupling for preserving variety</li>
<li>boundaries for preserving variety</li>
<li>super-predators for preserving variety</li>
<li>mutations for keeping a base variety.</li>
</ol>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Game theory and decision theory</title>
    <link href="http://holdenlee.github.io/notebook/posts/cs/ai/control/game_theory.html" />
    <id>http://holdenlee.github.io/notebook/posts/cs/ai/control/game_theory.html</id>
    <published>2017-02-12T00:00:00Z</published>
    <updated>2017-02-12T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Game theory and decision theory</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-12 
          , Modified: 2017-02-12 
	</p>
      
       <p>Tags: <a href="/tags/ai%20safety.html">ai safety</a>, <a href="/tags/game%20theory.html">game theory</a>, <a href="/tags/decision%20theory.html">decision theory</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#references">References</a><ul>
 <li><a href="#online">Online</a></li>
 <li><a href="#books">Books</a></li>
 </ul></li>
 <li><a href="#towards-idealized-decision-theory">Towards idealized decision theory</a><ul>
 <li><a href="#problems-with-edt-cdt">Problems with EDT, CDT</a><ul>
 <li><a href="#why-not-recursively-improve-from-edtcdt">Why not recursively improve from EDT/CDT?</a></li>
 </ul></li>
 <li><a href="#policy-selection">Policy selection</a></li>
 <li><a href="#logical-counterfactuals">Logical counterfactuals</a><ul>
 <li><a href="#graphical-udt.">Graphical UDT.</a></li>
 <li><a href="#proof-based-udt">Proof-based UDT</a></li>
 </ul></li>
 </ul></li>
 <li><a href="#lobs-theorem-in-miri-research">Lob’s Theorem in MIRI Research</a><ul>
 <li><a href="#lob">Lob</a></li>
 <li><a href="#applications">Applications</a><ul>
 <li><a href="#lobstacle">Lobstacle</a></li>
 <li><a href="#lobian-cooperation">Lobian cooperation</a></li>
 <li><a href="#spurious-counterfactuals">3.3 Spurious counterfactuals</a></li>
 </ul></li>
 <li><a href="#model-theory">Model theory</a></li>
 <li><a href="#godel-lob-modal-logic">Godel-Lob Modal Logic</a></li>
 <li><a href="#fixed-points-of-modal-statements">Fixed points of modal statements</a></li>
 <li><a href="#applications-of-gl-modal-logic">Applications of GL modal logic</a></li>
 </ul></li>
 <li><a href="#reflective-oracles-as-foundation">Reflective oracles as foundation</a></li>
 <li><a href="#reflective-oracles-and-solomonoff-induction">Reflective oracles and Solomonoff induction</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="references">References</h2>
<p>Papers on game theory/decision theory:</p>
<ul>
<li>Andrew Critch. 2017. “Toward Negotiable Reinforcement Learning: Shifting Priorities in Pareto Optimal Sequential Decision-Making.” <a href="https://arxiv.org/abs/1608.04112">arXiv:1701.01302</a> [cs.AI].</li>
<li>Andrew Critch. 2016. “Parametric Bounded Lob’s Theorem and Robust Cooperation of Bounded Agents.” <a href="http://arxiv.org/abs/1602.04184">arXiv:1602.04184</a> [cs:GT].</li>
<li>Jan Leike, Jessica Taylor, and Benya Fallenstein. 2016. “<a href="http://www.auai.org/uai2016/proceedings/papers/87.pdf">A Formal Solution to the Grain of Truth Problem</a>.” Paper presented at the 32nd Conference on Uncertainty in Artificial Intelligence.</li>
<li>Benja Fallenstein, Jessica Taylor, and Paul Christiano. 2015. “Reflective Oracles: A Foundation for Classical Game Theory.” <a href="http://arxiv.org/abs/1508.04145">arXiv:1508.04145</a> [cs.AI]. Previously published as MIRI technical report 2015-7. Published in abridged form as “Reflective Oracles: A Foundation for Game Theory in Artificial Intelligence” in Proceedings of LORI 2015.</li>
<li>Nate Soares and Benja Fallenstein. 2015. “Toward Idealized Decision Theory.” <a href="http://arxiv.org/abs/1507.01986">arXiv:1507.01986</a> [cs.AI]. Previously published as MIRI technical report 2014-7. Published in abridged form as “Two Attempts to Formalize Counterpossible Reasoning in Deterministic Settings” in Proceedings of AGI 2015.</li>
<li>Mih’aly B’asr’asz, Paul Christiano, Benja Fallenstein, Marcello Herreshoff, Patrick LaVictoire, and Eliezer Yudkowsky. 2014. “Robust Cooperation on the Prisoner’s Dilemma: Program Equilibrium via Provability Logic.” <a href="http://arxiv.org/abs/1401.5577">arXiv:1401.5577</a> [cs.GT].</li>
<li>Tsvi Benson-Tilsen. 2014. “UDT with Known Search Order.” <a href="https://intelligence.org/files/UDTSearchOrder.pdf">MIRI technical report 2014-4</a></li>
<li>Patrick LaVictoire, Benja Fallenstein, Eliezer Yudkowsky, Mih’aly B’ar’asz, Paul Christiano and Marcello Herreshoff. 2014. “<a href="https://intelligence.org/files/ProgramEquilibrium.pdf">Program Equilibrium in the Prisoner’s Dilemma via Lob’s Theorem</a>.” Paper presented at the AAAI 2014 Multiagent Interaction without Prior Coordination Workshop.</li>
<li>Benja Fallenstein. 2013. “<a href="https://intelligence.org/files/TilingAgents510.pdf">The 5-and-10 Problem and the Tiling Agents Formalism.</a>” MIRI technical report 2013-9.</li>
<li><a href="https://intelligence.org/wp-content/uploads/2014/10/Hintze-Problem-Class-Dominance-In-Predictive-Dilemmas.pdf">Problem class dominance</a></li>
</ul>
<h3 id="online">Online</h3>
<ul>
<li>ADT</li>
<li><a href="https://agentfoundations.org/item?id=1279">Entangled Equilibria and the Twin Prisoners’ Dilemma</a></li>
<li><a href="http://lesswrong.com/lw/15m/towards_a_new_decision_theory/">UDT</a>
<ul>
<li><a href="https://dl.dropboxusercontent.com/u/34639481/Updateless_Decision_Theory.pdf">Formalization</a></li>
</ul></li>
<li><a href="https://intelligence.org/research-guide/#four">MIRI research guide</a></li>
<li><a href="http://lesswrong.com/lw/gu1/decision_theory_faq/">Decision theory FAQ</a></li>
<li><a href="http://lesswrong.com/lw/dbe/introduction_to_game_theory_sequence_guide/">Game thepory sequence</a></li>
<li><a href="http://lesswrong.com/lw/eaa/a_model_of_udt_with_a_concrete_prior_over_logical/">UDT with concrete prior over logical statements</a></li>
<li><a href="http://lesswrong.com/lw/b5t/an_example_of_selffulfilling_spurious_proofs_in/">Self-fulfilling spurious proofs</a></li>
<li><a href="https://agentfoundations.org/item?id=160">Forum digest</a></li>
<li><a href="https://agentfoundations.org/item?id=117">UDT in the land of probabilistic oracles</a></li>
<li><a href="https://agentfoundations.org/item?id=4">Using modal fixed points to formalize logical causality</a> <a href="http://scrible.com/s/2DR66">h</a></li>
<li><a href="https://agentfoundations.org/item?id=47">Evil decision problems</a> <a href="http://scrible.com/s/2LB66">h</a></li>
<li><a href="https://agentfoundations.org/item?id=1281">Are daemons a problem for ideal agents?</a> (a.k.a. the rocket problem)</li>
</ul>
<h3 id="books">Books</h3>
<ul>
<li>Game theory, Steven Tadelis</li>
<li>Algorithmic game theory, Tim Roughgarden <a href="http://theory.stanford.edu/~tim/books.html">page</a></li>
<li>Computability and Logic by Boolos, Burgess, and Jeffrey</li>
</ul>
<h2 id="towards-idealized-decision-theory">Towards idealized decision theory</h2>
<p>But what are the available actions? And what are the counterfactual universes correspond- ing to what “would happen” if an action “were taken”?</p>
<p>(A deterministic agent could only have taken one action.)</p>
<p>To fully describe the problem faced by intelligent agents making decisions, it is necessary to provide an idealized procedure which takes a description of an environment and one of the agents within, and identifies the best action available to that agent</p>
<h3 id="problems-with-edt-cdt">Problems with EDT, CDT</h3>
<p>Evidential blackmail: AI researcher knows whether the AI will lose $150 mil from an investment (scandal). If either is true, the AI researcher sends the info and asks for $100 mil:</p>
<ul>
<li>No scandal, will pay</li>
<li>Scandal, won’t pay</li>
</ul>
<p>Conditioned on refusing, loses $150 mil.</p>
<p>Counterfactual blackmail: Developer has developed computer virus which would cause both to lose $150 mil. Once deployed, only way to prevent activation 1 day later is to wire $100 mil. Researcher would only deploy if quite sure agent will pay.</p>
<h4 id="why-not-recursively-improve-from-edtcdt">Why not recursively improve from EDT/CDT?</h4>
<p>CDT prescribes that an agent resist certain attempts to improve its decision procedures.</p>
<p>Retro blackmail: AI researcher has access to original source code. Can self-modify after researcher acquires original source code but before researcher decides whether to deploy.</p>
<p>Self-modify to not give in to demands.</p>
<p>But CDT and any decision procedure to which CDT would self-modify would lose money.</p>
<h3 id="policy-selection">Policy selection</h3>
<p>CDT: Alas, the virus has been deployed. I would have preferred that the virus not be deployed, but since it has been, I must now decide whether or not to pay up. Paying up is bad, but refusing is worse, so I’ll pay up.</p>
<p>Policy selection: The optimal policy is to refuse to pay up upon observing that the virus has been deployed. I now observe that the virus has been deployed. Therefore, I refuse to pay.</p>
<h3 id="logical-counterfactuals">Logical counterfactuals</h3>
<p>Consider Prisoner’s dilemma when</p>
<ul>
<li>opponent’s action guaranteed to match your own. (dependent)</li>
<li>some probability <span class="math inline">\(p\)</span> opponent defects. (independent)</li>
</ul>
<p>However, CDT evaluates actions according to a physical counterfactual where the action is changed but everything causally separated from the action is held constant. It is not the physical output of the agent’s hardware which must be modified to construct a counterfactual, it is the logical output of the agent’s decision algorithm.</p>
<p>Cf. <span class="math inline">\(10 \E a - a\)</span>.</p>
<p>UDT chooses the best action according to a world-model which represents not only causal relationships in the world, but also the logical effects of algorithms upon the world.</p>
<h4 id="graphical-udt.">Graphical UDT.</h4>
<p>How to encode logical relations in graph? Underspecified: constructing graph is difficult. Graph for UDT further requires some ability to identify and separate “algorithms” from the physical processes that implement them. How is UDT supposed to recognize that the agent and its opponent implement the same algorithm?</p>
<p>To illustrate, consider UDT identify- ing the best action available to an agent playing a Pris- oner’s Dilemma against an opponent that does exactly the same thing as the agent 80% of the time, and takes the opposite action otherwise.</p>
<p>(Problem seems to be identifying what something is doing logically - it might be obfuscated. Also, graph loses info from algorithm.)</p>
<h4 id="proof-based-udt">Proof-based UDT</h4>
<p>Evaluate logical implications of the agent’s algorithm selecting the policy <span class="math inline">\(\pi\)</span>.</p>
<p>Graph is unnecessary: the environment itself is an algorithm.</p>
<p>evaluates policies by searching for formal proofs, using some mathematical theory such as Peano Arithmetic (PA), of how much utility is attained in the world-model if A() selects the policy <span class="math inline">\(\pi\)</span>.</p>
<p>But: requires halting oracle. can only identify the best policy if there exists a proof that ex- ecuting that policy leads to a good outcome</p>
<p>Problem in stochastic environments (? if can model prior, seems ok)</p>
<p>Ex. agent uses UDT, play game with human. If numbers written sum to <span class="math inline">\(\$10\)</span>, each paid, else 0.</p>
<p>UDT misidentifies best policy:</p>
<p>Human: I don’t quite know how UDT works, but I remember hearing that it’s a very powerful predictor. So if I decide to write down 9, then it will predict this, and it will decide to write 1. Therefore, I can write down 9 without fear.</p>
<p>But agent with superior predictive power loses to the dumber agent! Human’s lack of power to predict UDT gives an advantage!</p>
<p>Problem: not guaranteed to work. As soon as proof-based UDT proves that an agent will not take a certain policy, it concludes that taking that policy leads to the best possible outcome (because from a contradiction, anything follows).</p>
<p>(I don’t get this…) <span class="math display">\[
A() = UDT(\ce{E()}, \ce{A()}).
\]</span></p>
<p>(What is an embedding of an agent?)</p>
<h2 id="lobs-theorem-in-miri-research">Lob’s Theorem in MIRI Research</h2>
<p>Why Lob? The short answer is that this theorem illustrates the basickind of self-reference involved when an algorithm considers its own output as part of theuniverse, and it is thus germane to many kinds of research involving self-modifying agents,especially when formal verification is involved or when we want to cleanly prove things inmodel problems.</p>
<p>Problem: How can Deep Thought 1.0 build Deep Thought 2.0 with guarantee of good consequences?</p>
<p>DT1 can’t actually figure out what actions DT2 is going to take. Naively, it seems as if it should be enough for DT1 toknow that DT2 has the same goals as DT1, that DT2’s deductions are reliable, and that DT2 only takes actions that it deduces to have good consequences on balance.</p>
<p>If we tryand model DT1 and DT2 as proving statements in two formal systems (one stronger thanthe other), then the only way that DT1 can make such a statement about DT2’s reliability is if DT1 (and thus both) are in fact unreliable!</p>
<h3 id="lob">Lob</h3>
<p>One (anachronistic) way of stating Godel’s key insight is that you can use computer pro-grams to search for proofs, and you can prove statements about computer programs</p>
<p>This makes it more intuitive that we can embed self-reference in mathematics, because we can embed self-reference in computer code!</p>
<p>Quines: programs can be made which perform arbitrary tasks using their own source code we can have a program G which refers to itself in this way, and searches for proofs inarithmetic related to its own source code.</p>
<p>G searches for a proof of “G runs forever”. G never finds a proof, but we can never prove that G runs forever.</p>
<p>We can add “G never halts” or “G halts” as a new axiom.</p>
<p><strong>First incompleteness</strong>. If the theory of arithmetic is consistent, then there exist undecidable statements in the theory of arithmetic.</p>
<p>Lob’s Theorem:</p>
<ul>
<li><span class="math inline">\(X\)</span> logical statement</li>
<li>ProofSeeker(X) searches for proofs of <span class="math inline">\(X\)</span>.</li>
<li><span class="math inline">\(L(X)=\)</span>“if ProofSeeker(X) halts, then X”</li>
</ul>
<p>Intuition: if <span class="math inline">\(L(X)\)</span> were provable for every <span class="math inline">\(X\)</span>, you can prove consistency.</p>
<ol type="1">
<li>If <span class="math inline">\(X\)</span> is provable, ProofSeeker(X) halts, and <span class="math inline">\(L(X)\)</span> is true.</li>
<li>If <span class="math inline">\(X\)</span> is disprovable, then ProofSeeker(X) does not halt, but you can’t prove it—because that would be like proving consistency! (cf. second inconsistency. Lob implies 2nd inconsistency.)</li>
<li>If <span class="math inline">\(X\)</span> is neither provable nor disprovable, then does not halt. (Also can’t prove it.)</li>
</ol>
<p>Also a finite version of Lob’s theorem, controls length of proof of <span class="math inline">\(\phi\)</span> in terms of <span class="math inline">\(\square \phi\to \phi\)</span>.</p>
<h3 id="applications">Applications</h3>
<h4 id="lobstacle">Lobstacle</h4>
<p>DT1 trusts DT2: if the action is deduced to be good, then it must actually be good.</p>
<p>(It can’t even trust itself?)</p>
<p>a simple agent with a utility function will only create successors whose formal systems are strictly weaker thanits own, since only those are fully trusted by the current system.</p>
<p>References: Tiling Agents for Self-Modifying AI, and the Lobian Obstacle [18] and Problems of self-reference in self-improving space-time embedded intelligence [9].</p>
<h4 id="lobian-cooperation">Lobian cooperation</h4>
<p>algorithm and theirs get to read the opponent’s source code, calculate for as long as they like, and then play only once.</p>
<p>Cooperate iff source code identical: fragile.</p>
<p>FairBot: search through all proofs of length <span class="math inline">\(\le N\)</span> to see if valid proofs of <span class="math inline">\(X(FairBot)=C\)</span>. If yes, output <span class="math inline">\(C\)</span>.</p>
<p>Intuitively, it seems like both mutual cooperation and mutual defection are stable fixed points of the situation. However, a Lobian statement breaks the deadlock in favor of cooperation!</p>
<p>Proof: L(“FairBot(FairBot)=C”) follows. By Lob, there must be a proof of FairBot(FairBot=C). (! This is a case where Lob actually helps prove something!)</p>
<p>See Program Equilibrium in the Prisoner’s Dilemma via Lob’s Theorem.</p>
<h4 id="spurious-counterfactuals">3.3 Spurious counterfactuals</h4>
<p>Note on model:</p>
<ul>
<li>If universe was computable (with agent’s resources) and extensionally fair, then the problem is simple: A simply selects the function that maximizes its expected utility. (Suppose A has a time limit it must halt by.)</li>
<li>Problem: Nesting - what if they keep calling one another? (I think this is not an issue if you enforce time limit.)</li>
<li>Problem: It doesn’t make sense for agent to have enough computing power to simulate the universe. In general we want to allow the universe to have more computing power. “Agent simulates universe” is not the shape of things we want.</li>
<li>Problem: May examine source code.</li>
</ul>
<p>When agent and universe are quined, you can’t “run the universe” on <span class="math inline">\(A\)</span> or <span class="math inline">\(A'\)</span>. You search for proofs of <span class="math inline">\(A()=x\to U()=c\)</span>. Problem: ordering matters. If you prove <span class="math inline">\(x\)</span> is better you choose <span class="math inline">\(x\)</span>, even though it could be worse, because <span class="math inline">\(A()=\neg x\to U()=c\)</span> is true for any <span class="math inline">\(c\)</span>.</p>
<p>(Why can’t extensional work? Search for proofs in universe quined with <span class="math inline">\(A'\)</span>, then choose <span class="math inline">\(A'\)</span>.)</p>
<p>careful ordering of which proofs it pays attention to, and that agent can be shown to make thecorrect decisions (given enough deductive power). The idea was originally due to Benja Fal-lenstein; Tsvi Benson-Tilson’s paper UDT with Known Search Order</p>
<h3 id="model-theory">Model theory</h3>
<p>the same theory can have many models, some of them not at all what you were thinking of when you made the axioms. Notes: to get Peano Arithmetic need</p>
<ul>
<li><span class="math inline">\(\forall x\in \N, Sx\ne O\)</span> to avoid mod <span class="math inline">\(n\)</span>.</li>
<li>But what about <span class="math inline">\(\N\cup \{\text{Bob}\}\)</span>? In order to express induction in the language (which doesn’t have variables for properties, only for numbers), we must resort to an infinite family of new axioms.</li>
</ul>
<p>There are models of Peano arithmetic where G holds, and other models where G fails to hold. In Robinson arithmetic “Bob” might satisfy the formula G is checking. In PA nonstandard models are weirder.</p>
<p>The key to understanding these is that G never halts at any finite number, but we can’t actually define in our formal language what “finite” means. Thenonstandard models of Peano Arithmetic are those which have all the usual numbers butalso lots of extra numbers that are “too large” to ever be written as lots of S’s followed by an O, but which nonetheless are swept along in any inductive statement.</p>
<p>Remark: nonstandard analysis</p>
<p>Ponder for a moment the formal system which has all the axioms of PA, plus the axiom that PA is consistent, plus the axiom that “the systemwhich has all the axioms of PA, plus the axiom that PA is consistent” is inconsistent. As it turns out, this is a perfectly consistent system (What happens if you take the recursively axiomatizable “consistency<span class="math inline">\({}^n\)</span>, <span class="math inline">\(n\in \N\)</span>?)</p>
<p>We might want to endorse some particular model as the “true” one (for instance, our standard model of the natural numbers, without all of those weird nonstandard numbers), and say that logical statements are true if they hold in that model and false if they don’t. This truth predicate exists outside the language, and so the logical statements can’t talk about the truth predicate, only about weaker notions like provability.</p>
<p>The trouble comes when we try to construct a language that contains its own truth predicate such that <span class="math inline">\(T(\phi)\lra \phi\)</span>. <span class="math inline">\(T(X)\lra T(\neg X)\)</span>.</p>
<p>if P isn’t allowed to make exact statements about its own values, but only arbitrarily precise approximations, then everything can work out consistently.</p>
<p>P can’t rule out the possibility that reciprocals of nonstandard natural numbers (infinitesimals) exist.</p>
<p>followup paper by Christiano on computationally tractable approxima-tions of probabilistic logic: Non-Omniscience, Probabilistic Inference, and Metamathematics</p>
<h3 id="godel-lob-modal-logic">Godel-Lob Modal Logic</h3>
<p>We’re interested in a particular modal logic that constitutes a reflection of Lobian phenomena in PA, etc.</p>
<p>GL axiom: <span class="math inline">\(\square (\square A \to A)\to \square A\)</span>.</p>
<p>(What about things like <span class="math inline">\(\forall x, \square P(x)\)</span>?)</p>
<p>some special cases where there are efficient algorithms for deducing provability in GL.</p>
<h3 id="fixed-points-of-modal-statements">Fixed points of modal statements</h3>
<p>All sorts of formulas that refer to themselves and each other by quining. Formulas <span class="math inline">\(p\lra \phi(p,q_1,\ldots, q_k)\)</span> modalized in <span class="math inline">\(p\)</span>: every <span class="math inline">\(p\)</span> in <span class="math inline">\(\phi\)</span> is in scope of some <span class="math inline">\(\square\)</span>.</p>
<p>When <span class="math inline">\(p\)</span> equivalent to formula modalized in <span class="math inline">\(p\)</span>, then <span class="math inline">\(p\)</span> is equivalent to something which doesn’t use <span class="math inline">\(p\)</span>. Godel statement <span class="math inline">\(\lra\)</span> inconsistency of arithmetic <span class="math inline">\(\square (p\lra \square \neg p) \lra \square (p\lra \square \perp)\)</span>.</p>
<p>formula is provable in the modal logic if and only if a corresponding property holds for every Kripke frame in that class.</p>
<h3 id="applications-of-gl-modal-logic">Applications of GL modal logic</h3>
<p>Robust Cooperation in the Prisoner’s Dilemma: Program Equilibrium via Provability Logic.</p>
<p>One embarrassing thing about FairBot is that it doesn’t check whether its potential cooperation would actually make any difference. (ex. it cooperates against a rock.)</p>
<p>Ex. PrudentBot</p>
<p>if we assume infinite computational power (i.e. the ability to consult a halting oracle about proof searches in Peano Arithmetic), then they can be written out as simple statements in modal logic</p>
<p>Find what happens using efficient algorithm!</p>
<p>Modal agents of rank 0: <span class="math inline">\(p\lra \phi(p,q)\)</span>, modalized in both <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> (don’t run, only prove). Equivalent to something <span class="math inline">\(p\lra \phi(q)\)</span>.</p>
<h2 id="reflective-oracles-as-foundation">Reflective oracles as foundation</h2>
<h2 id="reflective-oracles-and-solomonoff-induction">Reflective oracles and Solomonoff induction</h2>
<p><a href="https://en.wikipedia.org/wiki/AIXI">AIXI</a></p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Boosting</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/boosting.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/boosting.html</id>
    <published>2017-02-08T00:00:00Z</published>
    <updated>2017-02-08T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Boosting</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-08 
          , Modified: 2017-02-08 
	</p>
      
       <p>Tags: <a href="/tags/Boosting.html">Boosting</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#weak-learnability">Weak learnability</a></li>
 <li><a href="#boosting-problem">Boosting problem</a></li>
 <li><a href="#adaboost">AdaBoost</a></li>
 </ul> </div>

  <div class="blog-main">
    <p>Ref:</p>
<ul>
<li>Ch. 10 of <a href="http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning">Machine learning theory and algorithms</a></li>
<li><a href="http://cseweb.ucsd.edu/~yfreund/papers/IntroToBoosting.pdf">notes</a></li>
<li>0306 and 0311 in COS511 lectures</li>
</ul>
<p>Generalization of linear predictors to address 2 issues</p>
<ul>
<li>bias-complexity tradeoff (smooth control)</li>
<li>computational complexity of learning (amplify accuracy of weak learner - ERM can be hard)</li>
</ul>
<p>AdaBoost relies on the family of hypothesis classes obtained by composing a linear predictor on top of simple classes.</p>
<h2 id="weak-learnability">Weak learnability</h2>
<p><span class="math inline">\(C\)</span> is strongly PAC-learnable by <span class="math inline">\(A\)</span> if:</p>
<ul>
<li><span class="math inline">\(\forall\)</span> distribution <span class="math inline">\(D\)</span> over <span class="math inline">\(X\)</span>,</li>
<li><span class="math inline">\(\forall c\in C\)</span></li>
<li><span class="math inline">\(\forall \ep&gt;0\)</span></li>
<li><span class="math inline">\(\forall \de&gt;0\)</span>,</li>
<li><span class="math inline">\(A\)</span>, given <span class="math inline">\(m=\poly(\rc\ep,\rc \de)\)</span> examples, computes <span class="math inline">\(h\)</span> with <span class="math inline">\(\Pj[err(h)\le \ep] \ge 1-\de\)</span>.</li>
</ul>
<p><span class="math inline">\(C\)</span> is weakly PAC-learnable by <span class="math inline">\(A\)</span> if:</p>
<ul>
<li><span class="math inline">\(\exists \ga &gt;0\)</span></li>
<li><span class="math inline">\(\forall\)</span> distribution <span class="math inline">\(D\)</span> over <span class="math inline">\(X\)</span>,</li>
<li><span class="math inline">\(\forall c\in C\)</span></li>
<li><span class="math inline">\(\forall \de&gt;0\)</span></li>
<li><span class="math inline">\(A\)</span>, given <span class="math inline">\(m=\poly(\rc\de)\)</span> examples, computes <span class="math inline">\(h\)</span> with <span class="math inline">\(\Pj[err(h)\le \rc2-\ga] \ge 1-\de\)</span>.</li>
</ul>
<p>[Q: what is an explicit example of a provable weak learner?]</p>
<p>Q: Is weak learning equivalent to strong learning?</p>
<p>A: Yes if you increase the hypothesis class.</p>
<h2 id="boosting-problem">Boosting problem</h2>
<p>Given <span class="math inline">\((x_i,y_i)\)</span> with <span class="math inline">\(y_i\in \{-1,+1\}\)</span> and access to a weak learner <span class="math inline">\(A\)</span>, find <span class="math inline">\(H\)</span> such <span class="math inline">\(\Pj(err_D(H)\le \ep)\ge 1-\de\)</span> (learn strongly).</p>
<h2 id="adaboost">AdaBoost</h2>
<p>Idea: produce different distributions <span class="math inline">\(D\)</span> from <span class="math inline">\(\mathcal D\)</span>. Pick distributions at each round that provide info about points that are hard to learn.</p>
<ul>
<li>At each step, run weak learner on <span class="math inline">\(D_t\)</span>. Suppose error is <span class="math display">\[err_{D_t}(h_t) = \rc2-\ga_t=\ep_t.\]</span></li>
<li>Set <span class="math inline">\(\al_t=\ln \pf{1-\ep_t}{\ep_t}\)</span>. (If error is close to <span class="math inline">\(\rc2\)</span>, this is small.)</li>
<li>Update distribution:
<span class="math display">\[\begin{align}
D_1(i) &amp;=\rc m\\
D_{t+1}(i) &amp;= \fc{D_t(i)}{Z_t}e^{\one_{h_t(x_i)=y_i}\al_t}
\end{align}\]</span></li>
<li>Return <span class="math inline">\(H(x) = \sgn \pa{\sumo tT \al_t h_t(x)}\)</span>.</li>
</ul>
<p>Q: Can we unify this with multiplicative weights? This seems like some kind of dual. (Check multiplicative weights paper?)</p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Variational Bayes</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/probabilistic/vb.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/probabilistic/vb.html</id>
    <published>2017-02-06T00:00:00Z</published>
    <updated>2017-02-06T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Variational Bayes</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-06 
          , Modified: 2017-02-06 
	</p>
      
       <p>Tags: <a href="/tags/neural%20nets.html">neural nets</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"></div>

  <div class="blog-main">
    <ul>
<li><a href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods">Wiki</a></li>
<li><a href="https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf">Notes by Blei</a></li>
</ul>
<p>Two purposes:</p>
<ol type="1">
<li>To provide an analytical approximation to the posterior probability of the unobserved variables, in order to do statistical inference over these variables.</li>
<li>To derive a lower bound for the marginal likelihood (sometimes called the “evidence”) of the observed data (i.e. the marginal probability of the data given the model, with marginalization performed over unobserved variables). This is typically used for performing model selection.</li>
</ol>
<p>Monte Carlo techniques provide a numerical approximation to the exact posterior using a set of samples. Variational Bayes provides a locally-optimal, exact analytical solution to an approximation of the posterior.</p>
<p>Find the minimizer of <span class="math inline">\(D_{KL}(Q||P)\)</span> over some class <span class="math inline">\(Q\)</span> of distributions.</p>
<p>Ex. for <span class="math inline">\(Q(Z) =\prodo iM q_i(Z_i|X)\)</span>, <span class="math display">\[
q_j^*(Z_j|X) = \fc{e^{\E_{i\ne j}[\ln p(Z,X)]}}{\int e^{\E_{i\ne j}[\ln p(Z_{-j},X)]}\,dZ_j}.
\]</span> Simplify, get circular dependencies between parameters in one and other partition, solve in iterative fashion like EM.</p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Logical induction</title>
    <link href="http://holdenlee.github.io/notebook/posts/cs/ai/control/logical_induction.html" />
    <id>http://holdenlee.github.io/notebook/posts/cs/ai/control/logical_induction.html</id>
    <published>2017-02-01T00:00:00Z</published>
    <updated>2017-02-01T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Logical induction</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-01 
          , Modified: 2017-02-01 
	</p>
      
       <p>Tags: <a href="/tags/ai%20safety.html">ai safety</a>, <a href="/tags/logic.html">logic</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#definitions">Definitions</a></li>
 <li><a href="#theorem">Theorem</a></li>
 <li><a href="#properties">Properties</a><ul>
 <li><a href="#limit-properties">Limit properties</a></li>
 <li><a href="#pattern-recognition">Pattern recognition</a><ul>
 <li><a href="#definitions-1">Definitions</a></li>
 <li><a href="#properties-1">Properties</a></li>
 </ul></li>
 <li><a href="#self-knowledge">Self-knowledge</a><ul>
 <li><a href="#definitions-2">Definitions</a></li>
 <li><a href="#results">Results</a></li>
 </ul></li>
 </ul></li>
 <li><a href="#extended-paper-intro">Extended paper: Intro</a></li>
 <li><a href="#properties-2">Properties</a><ul>
 <li><a href="#others-not-covered-before">Others not covered before</a></li>
 </ul></li>
 <li><a href="#construction">Construction</a><ul>
 <li><a href="#marketmaker">MarketMaker</a></li>
 <li><a href="#budgeter">Budgeter</a></li>
 <li><a href="#tradingfirm">TradingFirm</a></li>
 <li><a href="#lia-logical-induction-algorithm">LIA (Logical Induction Algorithm)</a></li>
 <li><a href="#runtime-and-convergence">Runtime and convergence</a></li>
 <li><a href="#selected-proofs">Selected proofs</a></li>
 </ul></li>
 <li><a href="#discussion">Discussion</a><ul>
 <li><a href="#open-problems">Open problems</a></li>
 </ul></li>
 <li><a href="#misc">Misc</a><ul>
 <li><a href="#extended-paper">Extended paper</a></li>
 </ul></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="definitions">Definitions</h2>
<ul>
<li>Let <span class="math inline">\(L\)</span> be a language of propositional logic<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>, and <span class="math inline">\(S\)</span> be sentences in <span class="math inline">\(L\)</span>.</li>
<li>A <strong>valuation</strong> is <span class="math inline">\(\mathbb V:S\to [0,1]\)</span>.
<ul>
<li>A <strong>pricing</strong> is <span class="math inline">\(\Pj: S\to \Q \cap [0,1]\)</span>.</li>
<li>A <strong>belief state</strong> is a pricing with finite support. (Syntactically. Semantically, think of it as probabilities.)</li>
</ul></li>
<li><strong>Valuation sequence</strong> <span class="math inline">\(\mathbb N\to (S\to [0,1])\)</span>.
<ul>
<li>A <strong>market</strong> is a computable sequence of pricings <span class="math inline">\(\Pj_i:S\to \Q\cap [0,1]\)</span>. (i.e., <span class="math inline">\(\N \to (S\to \Q\cap [0,1])\)</span>).</li>
<li>A <strong>computable belief sequence</strong> is a market with each <span class="math inline">\(\Pj_i\)</span> having finite support. (Syntactically. Semantically, think of it as probabilities.)</li>
</ul></li>
<li>A <strong>deductive process</strong> <span class="math inline">\(\ol D:\N^+\to \text{Fin}(S)\)</span> (finite subsets of <span class="math inline">\(S\)</span>) is a computable nested sequence <span class="math inline">\(D_1\subeq D_2\subeq\cdots\)</span> of sentences. Let <span class="math inline">\(D_\iy:=\bigcup_n D_n\)</span>.</li>
<li>A <strong>world</strong> is a truth assignment <span class="math inline">\(\mathbb W: S\to \mathbb B\)</span>. True/false in <span class="math inline">\(\mathbb W\)</span> means <span class="math inline">\(\mathbb W(\phi)=0,1\)</span>.
<ul>
<li><span class="math inline">\(\mathbb W\)</span> is <strong>propositionally consistent (p.c.)</strong> if it satisfies
<span class="math display">\[\begin{align}
\mathbb W(\phi\wedge \psi)&amp;= \mathbb W(\phi) \wedge \mathbb W(\psi)\\
\mathbb W(\phi\vee \psi)&amp;= \mathbb W(\phi) \vee\mathbb W(\psi)\\
\mathbb W(\neg \phi) &amp;= 1-\mathbb W(\phi)
\end{align}\]</span>
<p>(cf. Christiano. Can define more complicated equivalences, but becomes more computationally difficult to verify consistency; you can’t make it intractable.)</p>
<span class="math inline">\(PC(D)\)</span> is the set of worlds where <span class="math inline">\(\mathbb W(\phi)=1\)</span> for <span class="math inline">\(\phi\in D\)</span>. <span class="math inline">\(PC(D)\)</span> is the set of worlds propositionally consistent with <span class="math inline">\(D\)</span>.</li>
<li><span class="math inline">\(\mathbb W\)</span> is <strong>consistent</strong> with <span class="math inline">\(\Ga\)</span>, <span class="math inline">\(\mathbb \in C(\Ga)\)</span>, if you can’t prove contradiction from <span class="math inline">\(\mathbb W\)</span> and <span class="math inline">\(\Ga\)</span>.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> <span class="math display">\[
\Ga \cup \set{\phi}{\mathbb W(\phi)=1}\cup \set{\neg \phi}{\mathbb W (\phi)=0}\not\vdash \perp.
\]</span></li>
</ul></li>
<li><strong>Efficiently computable</strong> <span class="math inline">\((x_n)_{n=1}^{\iy}\)</span> means <span class="math inline">\(x_n\)</span> computable in time <span class="math inline">\(\poly(n)\)</span>.</li>
<li>A valuation <strong>feature</strong> <span class="math display">\[
\al:\ub{[0,1]^{S\times \N^+}}{\text{valuation sequences}}\to \R
\]</span> is a continuous function such that <span class="math inline">\(\al(\ol{\mathbb V})\)</span> depends only on <span class="math inline">\(\mathbb V_{\le n}\)</span> for some <span class="math inline">\(n\in \N^+\)</span> called the rank.
<ul>
<li><strong>Price feature</strong> (cf. evaluation functional) <span class="math display">\[\psi^{*n}(\ol{\mathbb V}):=\mathbb V_n(\phi)\]</span></li>
<li><strong>Expressible feature</strong> is built up from price features, <span class="math inline">\(\Q, +, \times, \max, \max(\cdot, 1)^{-1}\)</span>. <span class="math inline">\(\mathcal{EF}\)</span> is the set of expressible features, <span class="math inline">\(\mathcal{EF}_n\)</span> of rank <span class="math inline">\(\le n\)</span> (commutative ring).</li>
</ul></li>
<li>A <strong>trading strategy</strong> is an affine combination <span class="math display">\[T = \pa{-\sum_i \xi_i \phi_i^{*n}} + \sum_i \xi_i \phi_i^{*n}\]</span> where <span class="math inline">\(\phi_i\in S\)</span>, <span class="math inline">\(\xi_i\)</span> are expressible features of rank <span class="math inline">\(\le n\)</span>. (I.e., it is an element of <span class="math inline">\(\ker(\ph)\)</span> where <span class="math display">\[\ph:\mathcal{EF}_n^{\opl S} \opl \mathcal{EF_n}
= \mathcal{EF}_n^{\opl S\cup \{1\}} \mapsto \mathcal{EF_n}\]</span> given by <span class="math inline">\(\ph:x\opl y\mapsto x^{*n}+y\)</span>.) Let <span class="math inline">\(T[\phi]\)</span> be the coefficient of <span class="math inline">\(\phi\)</span>, <span class="math inline">\(T[1]\)</span> be the constant term.
<ul>
<li>A <strong>trader</strong> <span class="math inline">\(\ol T\)</span> is a sequence <span class="math inline">\((T_1,T_2,\ldots)\)</span> where each <span class="math inline">\(T_n\)</span> is a trading strategy for day <span class="math inline">\(n\)</span>.</li>
<li>Think of <span class="math inline">\(\phi-\phi^{*n}\)</span> as meaning “buy share of <span class="math inline">\(\phi_i\)</span> at prevailing price.”</li>
<li>Example of trading strategy: Arbitrage <span class="math inline">\(\psi\)</span> against <span class="math inline">\(\neg \neg \psi\)</span>. <span class="math display">\[
[(\neg \neg \phi)^{*n} - \phi^{*n}](\phi-\phi^{*n}) + [\phi^{*n}-(\neg\neg\phi)^{*5}](\neg \neg \phi - (\neg\neg \phi)^{*5}).
\]</span></li>
<li>Define evaluation of a value function on a <span class="math inline">\(\mathcal F\)</span>-combination, <span class="math inline">\((S\to [0,1]) \times (\mathcal F^{\opl(S\cup \{1\})}) \to \mathcal F\)</span> in the natural way, sending <span class="math inline">\(\phi\)</span> to <span class="math inline">\(\mathbb V(\phi)\)</span> and extending by linearity. (<span class="math inline">\(\mathbb V(1)=1\)</span>.)</li>
</ul></li>
<li><span class="math inline">\(\ol T\)</span> <strong>exploits</strong> <span class="math inline">\(\mathbb V\)</span> relative to a deductive process <span class="math inline">\(\ol D\)</span> if <span class="math display">\[
\set{\mathbb W\pa{\sumz in \mathbb V_i(T_i)}}{n\in \N^+, \mathbb W\in PC(D_n)}
\]</span> is bounded below, but not bounded above.<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> This set is the set of <strong>plausible assessments</strong> of net worth. “The trader can make unbounded returns with bounded risk.”
<ul>
<li>Ex. if PA proves <span class="math inline">\(\phi\vee \psi\)</span>, then a trader who buys <span class="math inline">\(\phi,\psi\)</span> at combined price <span class="math inline">\(&lt;1\)</span> exploits the market.<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></li>
</ul></li>
<li><span class="math inline">\(\ol{\Pj}\)</span> satisfies the <strong>logical induction criterion</strong> relative to deductive process <span class="math inline">\(\ol D\)</span> if there is no efficiently computable trader <span class="math inline">\(\ol T\)</span> that exploits <span class="math inline">\(\ol\Pj\)</span> relative to <span class="math inline">\(\ol D\)</span>. <span class="math inline">\(\ol \Pj\)</span> is a <strong>logical inductor</strong>.
<ul>
<li>A logical inductor over a <span class="math inline">\(\Ga\)</span>-complete deductive process <span class="math inline">\(\ol D\)</span> is a <strong>logical inductor</strong> over <span class="math inline">\(\Ga\)</span>.</li>
</ul></li>
<li><span class="math inline">\(\ol\Pj\)</span> assigns <span class="math inline">\(\ol p\)</span> to <span class="math inline">\(\ol\phi\)</span> in a timely manner if <span class="math inline">\(\Pj_n(\phi_n) \simeq_n p_n\)</span>.</li>
</ul>
<h2 id="theorem">Theorem</h2>
<p>For any deductive process <span class="math inline">\(\ol D\)</span>, there exists a computable belief sequence <span class="math inline">\(\ol \Pj\)</span> satisfying the logical induction criterion relative to <span class="math inline">\(\ol D\)</span>.</p>
<p>For any recursively axiomatizable <span class="math inline">\(\Ga\)</span>, there exists a computable belief sequence that is a logical inductor over <span class="math inline">\(\Ga\)</span>.</p>
<p>Intuition: Consider any polynomial-time method for efficiently identifying patterns in logic. If the market prices don’t learn to reflect that pattern, a clever trader can use it to exploit the market. For example, if there is a polynomial-time method for identifying theorems that are always underpriced by the market, a clever trader could use that pattern to buy those theorems low, exploiting the market. To avoid exploitation, logical inductors must learn to identify many different types of patterns in logical statements.</p>
<p>(Note: I expected that the logical inductor would be the trader, but no, it’s the market! The traders are people trying to take advantage of the market. But I’m thinking of the AI against nature, and nature throwing catastrophes in the sense of trying to find things the AI would reason badly about.)</p>
<h2 id="properties">Properties</h2>
<h3 id="limit-properties">Limit properties</h3>
<ul>
<li>Convergence: <span class="math inline">\(\Pj_\iy(\phi) :=\limn \Pj_n(\phi)\)</span> exists.</li>
<li>Limit coherence: <span class="math inline">\(\Pj_\iy\)</span> defines a probability measure on the set of worlds consistent with <span class="math inline">\(\Ga\)</span>. <span class="math display">\[
\Pj(\mathbb W(\phi)=1):=\Pj_\iy(\phi).
\]</span></li>
<li>Occam bounds: There exists <span class="math inline">\(C&gt;0\)</span> such that, letting <span class="math inline">\(\ka(\phi)\)</span> be <a href="http://www.scholarpedia.org/article/Algorithmic_complexity#Prefix_complexity">prefix complexity</a> of <span class="math inline">\(\phi\)</span>,<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a>
<span class="math display">\[\begin{align}
\Pj_\iy(\phi) &amp;\ge C 2^{-\ka(\phi)}\\
\Pj_\iy(\phi) &amp;\le 1-C2^{-\ka(\phi)}.
\end{align}\]</span></li>
<li>Domination of universal semimeasure<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> <span class="math inline">\(M\)</span>: Let <span class="math inline">\(\ol{\si}_n\)</span> be the statement: the first <span class="math inline">\(n\)</span> bits of the observed sequence is <span class="math inline">\(\si_{\le n}\)</span>. There is universal <span class="math inline">\(C\)</span> such that <span class="math inline">\(\Pj_\iy(\ol \si_{\le n}) \ge CM(\ol\si_{\le n})\)</span>.</li>
</ul>
<h3 id="pattern-recognition">Pattern recognition</h3>
<h4 id="definitions-1">Definitions</h4>
<ul>
<li>Write <span class="math inline">\(x_n\simeq_n y_n\)</span> for <span class="math inline">\(\limn x_n-y_n=0\)</span>. <span class="math inline">\(\gtrsim\)</span> and <span class="math inline">\(\lesssim\)</span> for <span class="math inline">\(\liminf\ge 0\)</span>, <span class="math inline">\(\limsup\le 0\)</span>.</li>
<li>A divergent weighting is <span class="math inline">\(\ol w\in [0,1]^{\N^+}\)</span> with <span class="math inline">\(\su w_n=\iy\)</span>. <span class="math inline">\(\ol q\)</span> is <strong>generable</strong> from <span class="math inline">\(\ol\Pj\)</span> if there exists e.c. <span class="math inline">\(\mathcal{EF}\)</span>-progression <span class="math inline">\(\ol{q^{\dagger}}(\ol\Pj) =q_n\)</span>. (<span class="math inline">\(q_n^{\dagger}(\ol\Pj) = \ol\Pj_n(q_n^{\dagger})\)</span>.)
<ul>
<li>“Divergent weightings generable from <span class="math inline">\(\ol\Pj\)</span> are the pattern detectors that logical inductors can use.”</li>
</ul></li>
<li>Elements of <span class="math inline">\(\R^{\opl (S\cup \{1\})}\)</span> are constraints.</li>
<li><strong>Bounded combination sequences</strong> <span class="math inline">\(BCS(\ol \Pj)\)</span>: <span class="math inline">\(\ol\Pj\)</span>-generable <span class="math inline">\(\ol A\)</span> (<span class="math inline">\(A_n\in \R^{\opl (S\cup \{1\})}\)</span>) that are bounded (<span class="math inline">\(\exists b, \forall n,|A_n[1]|\le b\)</span>).</li>
</ul>
<h4 id="properties-1">Properties</h4>
<ul>
<li>Provability induction: Let <span class="math inline">\(\ol{\phi}\)</span> be e.c. sequence of theorems. Then <span class="math display">\[
\Pj_n(\phi_n) \simeq_n 1
\]</span> For disprovable sentences, <span class="math inline">\(\simeq_n0\)</span>. (Analogy: Ramanujan and Hardy)</li>
<li>Preemptive learning: For e.c. sequence <span class="math inline">\(\ol\phi\)</span>, <span class="math inline">\(\liminf_{n\to \iy}\Pj_n(\phi_n) = \liminf_{n\to \iy} \sup_{m\ge n} \Pj_m(\phi_n).\)</span> and similarly for inf/sup switched.
<ul>
<li>if <span class="math inline">\(P\)</span> always eventually pushes <span class="math inline">\(\phi_n\)</span> up to a probability at least <span class="math inline">\(p\)</span>, then it will learn to assign each <span class="math inline">\(\phi_n\)</span> a probability at least <span class="math inline">\(p\)</span> in a timely manner (and similarly for least upper bounds). (p.26 in main paper)</li>
</ul></li>
<li>Learning pseudorandom frequencies. <span class="math inline">\(\ol{\phi}\)</span> of decidable sentences is <strong>pseudorandom with frequency p</strong> wrt set of divergent weightings <span class="math inline">\(S\)</span> if for all <span class="math inline">\(\ol w\in S\)</span>, <span class="math inline">\(\limn \fc{\sumo in w_i \one_{\phi_i \text{ is theorem in }\Ga}}{\sumo in w_i}=p\)</span>. For <span class="math inline">\(\ol\phi\)</span> e.c., if <span class="math inline">\(\ol\phi\)</span> is pseudorandom over <em>all <span class="math inline">\(\ol\Pj\)</span>-generable divergent weightings</em>, <span class="math inline">\(\Pj_n(\phi_n) \simeq_n p\)</span>.
<ul>
<li>Think of <span class="math inline">\(\ol{\Pj}\)</span>-generable as meaning: trading strategies you could come up with looking at past history of beliefs. This still doesn’t fit my picture of traders as adversaries, rather than unkind nature.</li>
</ul></li>
<li>Affine coherence: Let <span class="math inline">\(\ol A\in BCS(\ol\Pj)\)</span>. <span class="math display">\[
\liminf_{n\to \iy} \inf_{\mathbb W\in C(\Ga)} \mathbb W(A_n) \le \liminf_{n\to \iy} \Pj_\iy (A_n) \le \lim_{n\to \iy} \Pj_n (A_n).
\]</span> Reverse inequalities for sup.
<ul>
<li>“Tie ground truth on <span class="math inline">\(\ol A\)</span> to value of <span class="math inline">\(\ol A\)</span> on main diagonal.”</li>
<li>“learns in a timely manner to respect all linear inequalities that actually hold between sentences, so long as those relationships can be enumerated in polynomial time.” Ex. if exactly one of <span class="math inline">\(A_n,B_n,C_n\)</span> is true, will get that.<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></li>
<li>What is each inequality saying?</li>
</ul></li>
</ul>
<p>I’m confused: Consider a sequence <span class="math inline">\(y_n=f(x_n)\)</span>, <span class="math inline">\(f:B^{2n}\to B^n\)</span> which is hard-to-invert. Theorem <span class="math inline">\(n\)</span> is <span class="math inline">\(y_n\in \im f\)</span>. How can we hope to assign probabilities <span class="math inline">\(\to 1\)</span>?</p>
<p>Can we add true randomness? Randomness in <span class="math inline">\(\Ga\)</span> is not allowed because axioms are recursively computable. (Footnote 3 in paper says we can add randomness to market.) How about allowing traders to be random?</p>
<h3 id="self-knowledge">Self-knowledge</h3>
<h4 id="definitions-2">Definitions</h4>
<ul>
<li><strong>Logically uncertain variable (LUV)</strong>: formula <span class="math inline">\(X\)</span> free in one variable that defines a unique value via <span class="math inline">\(\Ga\)</span>: (<span class="math inline">\(\exists!\)</span>) <span class="math display">\[
\Ga \perp \exists x: \forall x': X(x')\to x'=x.
\]</span> Value of <span class="math inline">\(X\)</span> in <span class="math inline">\(\mathbb W\in C(\Ga)\)</span> is <span class="math display">\[
\mathbb W(X):= \sup \set{x\in [0,1]}{\mathbb W(&quot;X\ge x&quot;)=1}.
\]</span> Because it may not be clear that <span class="math inline">\(X\)</span> has a unique value, “<span class="math inline">\(X\ge p\)</span>” is shorthand for <span class="math inline">\(\forall x: X(x)\to x&lt;p\)</span>.
<ul>
<li>Ex. “<span class="math inline">\(\nu\)</span> is 1/0 if Goldbach’s conjecture is true/false.”</li>
<li>Problem with a defining <span class="math inline">\(\E\)</span> the normal way: <span class="math inline">\(\ol\Pj\)</span> may not have figured out that <span class="math inline">\(X\)</span> takes a unique value!</li>
<li><strong>Indicator LUV</strong> <span class="math inline">\(\one(\phi) := &quot;(\phi \wedge (\nu = 1))\vee (\neg \psi \wedge (\nu=0))&quot;\)</span>.</li>
<li><strong>Approximate expectation operator</strong> with precision <span class="math inline">\(k\)</span>: For <span class="math inline">\(X\)</span> a <span class="math inline">\([0,1]\)</span>-LUV, <span class="math display">\[
\E_k^{\mathbb V}(X):=\sumz i{k-1}\rc k \mathbb V(&quot;X&gt;i/k&quot;).
\]</span> Let <span class="math inline">\(\E_n:=\E_n^{\Pj_n}\)</span>.</li>
</ul></li>
<li><span class="math inline">\(f:\N^+\to \N^+\)</span> is <strong>deferral function</strong> if <span class="math inline">\(f(n)&gt;n\)</span> for all <span class="math inline">\(n\)</span>, <span class="math inline">\(f(n)\)</span> can be computed in time <span class="math inline">\(\poly(f(n))\)</span>. Say <span class="math inline">\(f\)</span> defers <span class="math inline">\(n\)</span> to <span class="math inline">\(f(n)\)</span>.</li>
<li>Continuous threshold indicator <span class="math inline">\(\Ind_\de(x&gt;y)\)</span> interpolates between 0 and 1 on <span class="math inline">\([y,y+\de]\)</span>.</li>
</ul>
<h4 id="results">Results</h4>
<p>You can use the logic to encode the computation of the market prices, i.e. <span class="math inline">\(\ul{\Pj}_{\ul{n}}(\ul{\phi_n})\)</span>. (I’m omitting underlines in the following theorem statements.)</p>
<ul>
<li>Introspection: Let <span class="math inline">\(\ol \phi\)</span> be e.c. sequence of sentences, <span class="math inline">\(\ol a,\ol b\)</span> be e.c. sequences of probabilities expressible from <span class="math inline">\(\ol \Pj\)</span>. For any e.c. sequence of <span class="math inline">\(\Q^+\)</span> with <span class="math inline">\(\ol \de\to 0\)</span>, there exists e.c. sequence of <span class="math inline">\(\Q^+\)</span> with <span class="math inline">\(\ol\ep\to 0\)</span>, s.t. for all <span class="math inline">\(n\)</span>,
<span class="math display">\[\begin{align}
\Pj_n(\phi_n)&amp;\in (a_n+\de_n,b_n-\de_n)&amp;\implies \Pj_n(&quot;a_n&lt;\Pj_n(\phi_n)&lt;b_n&quot;)&amp;&gt;1-\ep_n\\
\Pj_n(\phi_n)&amp;\nin (a_n-\de_n,b_n+\de_n)&amp;\implies \Pj_n(&quot;a_n&lt;\Pj_n(\phi_n)&lt;b_n&quot;)&amp;&lt;\ep_n
\end{align}\]</span>
<!--(Asymptotically faster than any e.c. sequence!)-->
<ul>
<li>“If there is e.c. pattern of the form your probabilities on <span class="math inline">\(\ol{\phi}\)</span> will be in <span class="math inline">\((a,b)\)</span> then <span class="math inline">\(\ol{\Pj}\)</span> learns to believe that pattern iff it is true subject to finite precision.”</li>
</ul></li>
<li>Paradox resistance: Define paradoxical sentences <span class="math inline">\(\ol{\chi^p}\)</span> <span class="math display">\[
\Ga \vdash \ul{\chi_n^p} \lra (\Pj_n(\chi_n^p)&lt;p).
\]</span> Then <span class="math inline">\(\lim_{n\to \iy} \Pj_n(\chi_n^p) = p\)</span>.<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a>
<ul>
<li>p. 16: Brain scanner.</li>
</ul></li>
<li>Expectations
<ul>
<li>Convergence: <span class="math inline">\(\E_\iy\)</span> exists.</li>
<li><strong>Linearity of expectation</strong>. <span class="math inline">\(\ol \al,\ol\be\)</span> e.c. sequences of <span class="math inline">\(\Q\)</span> expressible from <span class="math inline">\(\ol\Pj\)</span>, <span class="math inline">\(\ol X, \ol Y, \ol Z\)</span> e.c. of <span class="math inline">\([0,1]\)</span>-LUV. <span class="math display">\[
\forall n, \Ga\vdash Z_n = \al_nX_n  +\be_nY_n\implies \al_n\E_n(X_n) + \be_n\E_n(Y_n) \simeq_n \E_n(Z_n).
\]</span></li>
<li><strong>Expectation coherence</strong>. $B<span class="math inline">\(BLCS(\)</span>$) set of bounded LUV-combination sequences. <span class="math display">\[
\liminf_{n\to \iy} \inf_{\mathbb W\in C(\Ga)} \mathbb W(B_n) \le \liminf_{n\to \iy} \E_\iy (B_n) \le \lim_{n\to \iy} \E_n (B_n)
\]</span> and reverse for sup.</li>
</ul></li>
<li>No expected net update: <span class="math inline">\(f\)</span> deferral, <span class="math inline">\(\ol\phi\)</span> e.c. sequence of sentences. <span class="math display">\[\Pj(\phi_n) \simeq_n \E_n(&quot;\Pj_{f(n)} (\phi_n)&quot;).\]</span>
<ul>
<li>If <span class="math inline">\(\ol\Pj\)</span> on day <span class="math inline">\(n\)</span> believes on day <span class="math inline">\(f(n)\)</span> it will believe <span class="math inline">\(\phi_n\)</span> whp, then it already believes <span class="math inline">\(\phi_n\)</span> whp today. “In other words, logical inductors learn to adopt their predicted future beliefs as their current beliefs in a timely manner.”</li>
</ul></li>
<li>Self-trust: <span class="math inline">\(f\)</span> deferral, <span class="math inline">\(\ol\phi\)</span> e.c., <span class="math inline">\(\ol\de\in (\Q^+)^n\)</span> e.c., <span class="math inline">\(\ol p\)</span> e.c. sequence of rational probs expressible from <span class="math inline">\(\ol\Pj\)</span>. Then <span class="math display">\[
\E_n (&quot;\one(\phi_n)\Ind_{\de_n} (\Pj_{f(n)}(\phi_n)&gt;p_n)&quot;) \gtrsim_n p_n \E_n (&quot;\Ind_{\de_n}(\Pj_{f(n)}(\phi_n)&gt;p_n)&quot;).
\]</span>
<ul>
<li>“Trust that if beliefs change, they must have changed for good reason”</li>
<li>Roughly: If we ask <span class="math inline">\(\ol\Pj\)</span> what it believes about <span class="math inline">\(\phi\)</span> now if it learned it was going to believe <span class="math inline">\(\phi\)</span> wp <span class="math inline">\(\ge p\)</span> in the future, it will answer with probability <span class="math inline">\(\ge p\)</span>. (Some subtlety with continuous indicators, paradoxical sentences.)</li>
</ul></li>
</ul>
<h2 id="extended-paper-intro">Extended paper: Intro</h2>
<ul>
<li>13 Gaifman inductivity: Given a <span class="math inline">\(\Pi_1\)</span> statement <span class="math inline">\(\phi = \forall x, \psi\)</span>, as the set of examples approaches all examples, belief in <span class="math inline">\(\phi\)</span> approaches 1.</li>
<li>18 Use of old evidence: When a bounded reasoner comes up with a new theory that neatly describes anomalies in the old theory, the old evidence should count in favor of the new theory. (Why isn’t this Bayesian? Bayesian keeps track of all hypotheses at all times.)</li>
<li>1, 2, 13 cannot be satisfied simultaneously (why?). 1, 6, 13, weak 2 cannot be satisfied simultaneously.</li>
<li>Algorithm doesn’t satisfy 13, 14, 15. 16, 17 are unclear.</li>
<li>1 and 12 are key.</li>
</ul>
<h2 id="properties-2">Properties</h2>
<ol type="1">
<li>Convergence and Coherence: In the limit, the prices of a logical inductor describe a belief state which is fully logically consistent, and represents a probability distribution over all consistent worlds.</li>
<li>Timely Learning: For any efficiently computable sequence of theorems, a logical inductor learns to assign them high probability in a timely manner, regardless of how difficult they are to prove. (And similarly for assigning low probabilities to refutable statements.)</li>
<li>Learning Statistical Patterns: If a sequence of sentences appears pseudorandom to all reasoners with the same runtime as the logical inductor, it learns the appropriate statistical summary (assigning, e.g., 10% probability to the claim “the nth digit of <span class="math inline">\(\pi\)</span> is a 7” for large n, if digits of <span class="math inline">\(\pi\)</span> are actually hard to predict).</li>
<li>Calibration and Unbiasedness: Logical inductors are well-calibrated and, given good feedback, unbiased.</li>
<li>Learning Logical Relationships: Logical inductors inductively learn to respect logical constraints that hold between different types of claims, such as by ensuring that mutually exclusive sentences have probabilities summing to at most 1.</li>
<li>Non-Dogmatism: The probability that a logical inductor assigns to an independent sentence <span class="math inline">\(\phi\)</span> is bounded away from 0 and 1 in the limit, by an amount dependent on the complexity of <span class="math inline">\(\phi\)</span>. In fact, logical inductors strictly dominate the universal semimeasure in the limit. This means that we can condition logical inductors on independent sentences, and when we do, they perform empirical induction.</li>
<li>Conditionals: Given a logical inductor P, the market given by the conditional probabilities <span class="math inline">\(P(- | \psi)\)</span> is a logical inductor over <span class="math inline">\(\ol D\)</span> extended to include <span class="math inline">\(\psi\)</span>. Thus, when we condition logical inductors on new axioms, they continue to perform logical induction.</li>
<li>Expectations: Logical inductors give rise to a well-behaved notion of the expected value of a logically uncertain variable.</li>
<li>Trust in Consistency: If the theory <span class="math inline">\(\Ga\)</span> underlying a logical inductor’s deductive process is expressive enough to talk about itself, then the logical inductor learns inductively to trust <span class="math inline">\(\Ga\)</span>.</li>
<li>Reasoning about Halting: If there’s an efficient method for generating programs that halt, a logical inductor will learn in a timely manner that those programs halt (often long before having the resources to evaluate them). If there’s an efficient method for generating programs that don’t halt, a logical inductor will at least learn not to expect them to halt for a very long time.</li>
<li>Introspection: Logical inductors “know what they know”, in that their beliefs about their current probabilities and expectations are accurate.</li>
<li>Self-Trust: Logical inductors trust their future beliefs.</li>
</ol>
<h3 id="others-not-covered-before">Others not covered before</h3>
<ul>
<li>4.2.3 persistence of knowledge: If <span class="math inline">\(\ol\Pj\)</span> assigns <span class="math inline">\(\ol p\)</span> to <span class="math inline">\(\ol\phi\)</span> in the limit, then <span class="math inline">\(\ol\Pj\)</span> assigns probability near <span class="math inline">\(p_n\)</span> to <span class="math inline">\(\phi_n\)</span> at times <span class="math inline">\(m\ge n\)</span>.</li>
<li>4.3 Calibration and unbiasedness is hard to check.
<ul>
<li>Check conditional rather than marginal probabilities.</li>
<li><ol type="a">
<li>restrict our consideration to sequences where the average frequency of truth converges; or</li>
</ol></li>
<li><ol start="2" type="a">
<li>look at subsequences of <span class="math inline">\(\phi\)</span> where P has “good feedback” about the truth values of previous elements of the subsequence, in a manner defined below.</li>
</ol></li>
<li>4.3.3 Recurring calibration: In any sequence, consider the theorems that were assigned probabilities in <span class="math inline">\((a,b)\)</span>. (<span class="math inline">\(a&lt;\Pj_i(\phi_i)&lt;b\)</span>.) This sequence has a limit point in <span class="math inline">\([a,b]\)</span>.
<ul>
<li>If the frequency of truth diverges (like <span class="math inline">\(1-2+4-8...\)</span>) then it’s still well-calibrated infinitely often.</li>
</ul></li>
<li>A trader can cheat; we want unbiasedness: no efficient method for detecting bias in beliefs.</li>
<li>4.3.6 Recurring unbiasedness: For any decidable ec <span class="math inline">\(\ol\phi\)</span>, any generable divergent weighting, weighted average of <span class="math inline">\(\Pj_i(\phi_i) - Thm_\Ga(\phi)\)</span> has limit point 0.</li>
<li>Bias converges when weighting is sparse enough so that <span class="math inline">\(\ol\Pj\)</span> can gather sufficient feedback between guesses.</li>
<li>4.3.8 Unbiasedness from feedback: deferral <span class="math inline">\(f\)</span>. for <span class="math inline">\(Supp \ol w\subeq \im f\)</span>, <span class="math inline">\(Thm_\Ga(\phi_{f(n)})\)</span> computable in <span class="math inline">\(O(f(n+1))\)</span> time. (Figure out how previous elements turned out before forced to predict the next one.)</li>
</ul></li>
<li>4.4 Learning statistical patterns
<ul>
<li>Weaken pseudorandom.</li>
<li><span class="math inline">\(\ol w\)</span> is <span class="math inline">\(f\)</span>-patient if weight it places between <span class="math inline">\(n\)</span>, <span class="math inline">\(f(n)\)</span> is bounded.</li>
<li>4.4.4. <span class="math inline">\(\ol p\)</span>-varied pseudorandom sequence: Relative to set <span class="math inline">\(S\)</span> of <span class="math inline">\(f\)</span>-patient divergent weightings, <span class="math inline">\(\E_w(p_i-Thm_\Ga(\phi_i))\simeq 0_n\)</span>.</li>
<li>4.4.5. If there is some <span class="math inline">\(f\)</span> such that <span class="math inline">\(\ol\phi\)</span> is <span class="math inline">\(\ol p\)</span>-varied pseudorandom, <span class="math inline">\(\Pj_n(\phi_n)\simeq_np_n\)</span>.</li>
<li>(? where is assumption of <span class="math inline">\(n\)</span> being decided before <span class="math inline">\(n+1\)</span> presented?)</li>
</ul></li>
<li>4.5 Logical relationships
<ul>
<li>4.5.1 Exclusive-exhaustive</li>
<li>4.5.5 Affine coherence: learns in a timely manner to respect all linear inequalities that actually hold between sentences, so long as those relationships can be enumerated in polynomial time.</li>
<li>(is BCS bound for all <span class="math inline">\(\Pj\)</span>?)</li>
<li>4.5.6 Persistence of affine knowledge.</li>
<li>4.5.7. Affine preemptive</li>
<li>… (skip)</li>
</ul></li>
<li>4.6 Non-dogmatism
<ul>
<li>4.6.1 Closure under finite perturbations</li>
<li>Non-dogmatism doesn’t guarantee reasonable beliefs about theories</li>
<li>Uniform non-dogmatism: For any computably enumerable sequence such that <span class="math inline">\(\Ga\cup \ol\phi\)</span> is consistent, there is <span class="math inline">\(\ep&gt;0\)</span>, <span class="math inline">\(\forall n\)</span>, <span class="math inline">\(\Pj_\iy(\phi_n)\ge \ep\)</span>.</li>
<li>Domination, strict domination of universal semimeasure. (Logical inductors assign positive probabilities to set of completions of theories, universal semimeasures do not.)</li>
</ul></li>
<li>4.7 Conditionals
<ul>
<li>Define <span class="math inline">\(\mathbb V(\phi|\psi)\)</span>. <span class="math inline">\(=1\)</span> if <span class="math inline">\(\mathbb V(\phi\wedge \psi)\ge \mathbb V(\psi)\)</span>.</li>
<li>4.7.2 Closure under conditioning. <span class="math inline">\(\Pj_n(-|\bigwedge_{i\le n}\psi_i)\)</span> is logical inductor over <span class="math inline">\(\Ga\cup \Psi\)</span>.</li>
</ul></li>
<li>4.8 Expectations
<ul>
<li>Idea of expectation definition: integration by parts naturally puts in terms of <span class="math inline">\(\mathbb V\)</span>.</li>
<li>4.8.6 Expectation of indicators.</li>
</ul></li>
<li>4.9 Trust in consistency
<ul>
<li><span class="math inline">\(Con(\Ga')(\nu)\)</span> is “There is no proof of <span class="math inline">\(\perp\)</span> from <span class="math inline">\(\ol{\Ga'}\)</span> with <span class="math inline">\(\le \nu\)</span> symbols.”</li>
<li>Belief in finitistic consistency: for <span class="math inline">\(f\)</span> computable, <span class="math inline">\(\Pj_n(Con(\Ga)(``f(n)&quot;))\simeq_n1\)</span>.</li>
<li>Learns to trust PA inductively.</li>
<li>Also true if replace <span class="math inline">\(\Ga\)</span> with <span class="math inline">\(\Ga'\)</span> any recursively axiomatizable consistent theory.</li>
<li>4.9.4 Disbelief in (sequence of) inconsistent theories.</li>
</ul></li>
<li>4.10 Halting
<ul>
<li>4.10.1/2. Learn (ec) halting patterns “<span class="math inline">\(m_n\)</span> halts on input <span class="math inline">\(x_n\)</span>” and nonhalting patterns.</li>
<li>Only apply to cases where <span class="math inline">\(\Ga\)</span> can prove machines halt or don’t. Else,</li>
<li>4.10.3 learning not to anticipate halting: in <span class="math inline">\(f(n)\)</span> steps.</li>
<li>It is impossible to tell whether or not a Turing machine halts in full generality, but for large classes of well-behaved computer programs (such as e.c. sequences of halting programs and provably non-halting programs) it’s quite possible to develop reasonable and accurate beliefs</li>
</ul></li>
<li>4.11 Introspection
<ul>
<li>Expectations of probabilities, iterated expectations</li>
</ul></li>
<li>4.12 Self-trust
<ul>
<li>4.12.1 Expected future expectations: current expectation on day <span class="math inline">\(n\)</span> already equal to expected value in <span class="math inline">\(f(n)\)</span> days.</li>
<li>4.12.2/3: No expected net update under conditionals.</li>
</ul></li>
</ul>
<p>[Q: can SoS give reasonable estimates of probabilities to a given statement given a web of propositional statements?]</p>
<p>[Don’t want traders to do more computation beyond propositional correctness… they can still utilize eventual theoremhood by not keeping too much open.]</p>
<h2 id="construction">Construction</h2>
<p>Given deductive process <span class="math inline">\(\ol D\)</span>, construct computable belief sequence <span class="math inline">\(\ol{LIA}\)</span>.</p>
<ul>
<li>Belief history <span class="math inline">\(\Pj_\le n\)</span>: sequence of belief states.</li>
<li><span class="math inline">\(n\)</span>-strategy history <span class="math inline">\(T_{\le n}\)</span>: finite list of trading strategies, <span class="math inline">\(T_i\)</span> is <span class="math inline">\(i\)</span>-strategy.</li>
</ul>
<h3 id="marketmaker">MarketMaker</h3>
<p>Sets market prices anticipating what a single trader is about to do.</p>
<p><strong>Fixed point lemma</strong> Let <span class="math inline">\(T_n\)</span> be <span class="math inline">\(n\)</span>-strategy, <span class="math inline">\(\Pj_{\le n-1}\)</span> belief history. There exists <span class="math inline">\(\mathbb V\)</span>, <span class="math inline">\(\Supp(\mathbb V)\subeq \Supp(T_n):=S'\)</span>, s.t. <span class="math display">\[
\forall \mathbb\in \mathcal W, \mathbb W(T_n(\Pj_{\le n-1}, \mathbb V))\le 0.
\]</span></p>
<p><em>Proof</em>. Define <span class="math inline">\(V' = [0,1]^{S'}\)</span>, <span class="math display">\[
f(\mathbb V)(\phi):= \text{clamp}_{[0,1]} [\mathbb V(\phi) + T(\Pj_{\le n-1}, \mathbb V)[\phi]].
\]</span> Idea: if the trader buys under <span class="math inline">\(\mathbb V\)</span>, then increase the price. (Note the scaling of <span class="math inline">\(T\)</span> doesn’t really matter.) If the trader doesn’t buy/sell <span class="math inline">\(\phi\)</span>, there is no change.</p>
<p>By Brouwer on the simply connected compact <span class="math inline">\([0,1]^{S'}\)</span>, there is a fixed point <span class="math inline">\(\mathbb V^{\text{fix}}\)</span>. <span class="math inline">\(T_n\)</span> only buys shares when <span class="math inline">\(\mathbb V^{\text{fix}}=1\)</span>, and sell when <span class="math inline">\(=0\)</span>: no profit!</p>
<p><strong>MarketMaker</strong>: on input <span class="math inline">\(T_n, \Pj_{\le n-1}\)</span>, return <span class="math inline">\(\Pj\subeq [0,1]^{S'}\)</span>, <span class="math display">\[
\forall \mathbb\in \mathcal W, \mathbb W(T_n(\Pj_{\le n-1}, \mathbb V))\le 2^{-n}.
\]</span></p>
<p>(Note we haven’t restricted to consistent worlds at all.)</p>
<p>Idea: brute force approximate search.</p>
<p>Let <span class="math inline">\(\mathbb W' = \mathbb W\one_{S'}\)</span>. Consider <span class="math display">\[g:\mathbb V \mapsto \max_{\mathbb W'\in \mathcal W'} \mathbb W'(T_n(\Pj_{\le n-1}, \mathbb V)).\]</span> We find a rational belief state <span class="math inline">\(\Pj\in (g')^{-1}((-\iy, 2^{-n}))\)</span> because we can compute <span class="math inline">\(g\)</span>.</p>
<p><strong>Lemma</strong>. MarketMaker <span class="math inline">\(\Pj_n=MarketMaker_n(T_n,\Pj_{\le n-1})\)</span> is not exploitable by <span class="math inline">\(\ol T\)</span> relative to any <span class="math inline">\(\ol D\)</span>.</p>
<p>(No assumptions on <span class="math inline">\(D\)</span>.)</p>
<p><em>Proof</em>. Sum <span class="math inline">\(\le 1\)</span>.</p>
<h3 id="budgeter">Budgeter</h3>
<p>Alter trader to stay within budget <span class="math inline">\(b\)</span>.</p>
<p>If there is some PC world where the trader could have lost $b or more, do nothing. Else, scale down to stay within budget in worst possible world.</p>
<p>Define Budgeter<span class="math inline">\({}_n^{\ol D}(b, T_{\le n}, \Pj_{\le n-1})\)</span> by:</p>
<ul>
<li>if <span class="math inline">\(\mathbb W(\sum_{i\le m}T_i(\Pj_{\le i}))\le -b\)</span> for some <span class="math inline">\(m&lt;n\)</span>, <span class="math inline">\(\mathbb W \in PC(D_m)\)</span>, then 0.</li>
<li>else: <span class="math inline">\(T_n \inf_{\mathbb W\in PC(D_n)}\ba{\max\pa{1,\fc{-\mathbb W(T_n)}{b+ \mathbb W(\sum_{i\le n-1} T_i(\Pj_{\le i}))}}^{-2}}\)</span>. (can write as <span class="math inline">\(\min\pa{1, \fc{b+ \mathbb W(...)}{-\mathbb W(T_n)}}\)</span>.)</li>
</ul>
<p><strong>Lemma</strong> (Properties):</p>
<ol type="1">
<li>B doesn’t change <span class="math inline">\(T\)</span> if for all past times <span class="math inline">\(m\le n\)</span>, in all PC worlds (<span class="math inline">\(\mathbb W\in PC(D_m)\)</span>) the value is <span class="math inline">\(&gt;-b\)</span> (<span class="math inline">\(\mathbb W(\sum_{i\le m}T_i(\ol \Pj))&gt;-b\)</span>).</li>
<li>(Stays within budget) <span class="math inline">\(\mathbb W(\sum_{i\le n}B_i^b(\ol\Pj)) \ge -b\)</span>.</li>
<li>If <span class="math inline">\(\ol T\)</span> exploits <span class="math inline">\(\ol\Pj\)</span> relative to <span class="math inline">\(\ol D\)</span>&lt; then so does <span class="math inline">\(\ol B^b\)</span> for some <span class="math inline">\(b\in \N^+\)</span>. (Proof. choose <span class="math inline">\(b\)</span> to be the lower bound, then <span class="math inline">\(T\)</span> doesn’t change.)</li>
</ol>
<h3 id="tradingfirm">TradingFirm</h3>
<p>Uses budgeter to combine infinite (enumerable) sequence of e.c. traders into a single trader that exploits a given market if any e.c. trader exploits the market. <!-- carefully chosen--></p>
<p>(5.3.1) there exists a computable sequence of e.c. traders containing every e.c. trader.</p>
<p>Idea of construction of TradingFirm</p>
<ul>
<li>At finite step <span class="math inline">\(n\)</span>, incorporate the first <span class="math inline">\(n\)</span> traders in the list <span class="math inline">\(\ol T^k\)</span>.</li>
<li>We don’t know the right <span class="math inline">\(b\)</span>, so define a converging sum over <span class="math inline">\(b\)</span>.</li>
</ul>
<p>In math:</p>
<ul>
<li><span class="math inline">\(S_n^k = \one_{n\ge k} T^k_n\)</span>.</li>
<li>TradingFirm<span class="math inline">\({}_n^{\ol D} (\Pj_{\le n-1}) = \sumo k{\iy}\sumo b{\iy}2^{-k-b} \text{Budgeter}_n^{\ol D} (b, S_{\le n}^k, \Pj_{\le n-1})\)</span>.</li>
</ul>
<p>Note this is a computable finite sum because we can compute a lower bound on <span class="math inline">\(\mathbb W(\sum_{i\le m} S_i^k (\Pj_{\le m}))\)</span>, <span class="math inline">\(-C_n:=-\sum_{i\le n}\ve{S_i^k (\ol{\mathbb V})}_1\)</span>. When the budget is more than <span class="math inline">\(C_n\)</span>, the trading strategy doesn’t change.</p>
<p><strong>Lemma</strong> (Trading firm dominance): If there exists any e.c. trader <span class="math inline">\(\ol T\)</span> that exploits <span class="math inline">\(\ol\Pj\)</span> relative to <span class="math inline">\(\ol D\)</span>, then <span class="math inline">\((\text{TradingFirm}_n^{\ol D}(\Pj_{\le n-1}))_{n\in \N^+}\)</span> also exploits <span class="math inline">\(\ol\Pj\)</span> relative to <span class="math inline">\(\ol D\)</span>.</p>
<p><em>Proof</em>. Use repeatedly: If <span class="math inline">\(A_n\)</span> exploits <span class="math inline">\(\ol\Pj\)</span> and <span class="math inline">\(\mathbb W(\sum_{i\le n}A_n(\Pj)) \ge c_1 \mathbb W(\sum_{i\le n}T_n^k(\Pj)) + c_2\)</span> for <span class="math inline">\(c_1&gt;0\)</span>, then <span class="math inline">\(B_n\)</span> exploits <span class="math inline">\(\ol \Pj\)</span>.</p>
<h3 id="lia-logical-induction-algorithm">LIA (Logical Induction Algorithm)</h3>
<p>Uses MarketMaker to make market not exploitable by TradingFirm.</p>
<p>Define <span class="math display">\[
LIA_n := \text{MarketMaker}_n(\text{TradingFirm}_n^{\ol D}(LIA_{\le n-1}), LIA_{\le n-1}).
\]</span></p>
<p><strong>LIA satisfies the logical induction criterion.</strong></p>
<p><em>Proof</em>. If any e.c. trader exploits LIA, then so does the trading firm, contradiction.</p>
<h3 id="runtime-and-convergence">Runtime and convergence</h3>
<p>Tradeoff between runtime of <span class="math inline">\(\Pj_n\)</span> as function of <span class="math inline">\(n\)</span> and how quickly <span class="math inline">\(\Pj_n(\phi) \to \Pj_\iy(\phi)\)</span>.</p>
<h3 id="selected-proofs">Selected proofs</h3>
<p>Idea: if a market doesn’t satisfy nice properties, then there are ec traders taking advantage of this.</p>
<ul>
<li>Convergence: <span class="math inline">\(\Pj_\iy(\phi):=\limn \Pj_n(\phi)\)</span> exists.
<ul>
<li>Proof sketch: If <span class="math inline">\(\ol\Pj\)</span> never makes up its mind about <span class="math inline">\(\phi\)</span> then it can be exploited by a trader that buys at <span class="math inline">\(&lt;p-\ep\)</span> and sells at <span class="math inline">\(&gt;p+\ep\)</span>. (cf. <a href="/posts/math/probability/martingales.html#martingales-almost-sure-convergence">upcrossing inequality</a>) Technicalities
<ul>
<li>Use a continuous indicator function.</li>
<li>Need to track net <span class="math inline">\(\phi\)</span>-shares bought (holdings <span class="math inline">\(H_n\)</span>). Don’t buy too many, so maintain bounded risk. (E.g. Cap at 1 at all times.)</li>
</ul></li>
</ul></li>
<li>Limit coherence:
<ul>
<li>Show that 3 properties are satisfied:
<ul>
<li><span class="math inline">\(\Ga \vdash \phi\implies \Pj_\iy(\phi)=1\)</span>.</li>
<li><span class="math inline">\(\Ga \vdash \neg \phi\implies \Pj_\iy(\phi)=0\)</span>.</li>
<li><span class="math inline">\(\Ga \vdash \neg(\phi\wedge \psi)\implies \Pj_\iy(\phi\vee \psi) = \Pj_\iy(\phi)+\Pj_\iy(\psi)\)</span>.</li>
<li>Otherwise, we can construct a trader taking advantage of this “inconsistency”.</li>
</ul></li>
<li>Gaifman showed that these properties imply that <span class="math inline">\(\Pj\)</span> extends to a probability measure. (<a href="https://en.wikipedia.org/wiki/Kolmogorov_extension_theorem">Kolmogorov extension</a> over <span class="math inline">\(\{0,1\}^S\)</span>?)</li>
<li>It’s important here that the trader considers PC worlds—over PC worlds, these trading strategies are bounded below. (More generally, if you allow other computable transformations, I think what happens is that <span class="math inline">\(\Pj_\iy\)</span> will be guaranteed to respect those transformations.)</li>
</ul></li>
<li>Non-dogmatism
<ul>
<li>Proof that if <span class="math inline">\(\Ga\not\vdash \neg \phi\)</span>, then <span class="math inline">\(\Pj_\iy(\phi)&gt;0\)</span>. Otherwise, for every <span class="math inline">\(k\)</span>, make sure the trader buys one share of <span class="math inline">\(\phi\)</span> for price <span class="math inline">\(\le 2^{-k}\)</span>.</li>
<li>Idea: we can have <span class="math inline">\(\sum a_k 2^{-k}\)</span> bounded (spend a bounded amount of money in any world) but <span class="math inline">\(\sum a_k (1-2^{-k})\)</span> unbounded (potentially unbounded returns in the world where <span class="math inline">\(\phi\)</span> is true).</li>
</ul></li>
<li>Pseudorandom frequencies
<ul>
<li>Buy <span class="math inline">\(\phi_n\)</span> shares whenever price goes below <span class="math inline">\(p-\ep\)</span>. <span class="math inline">\(p\)</span> proportion pays out (by pseudorandomness—since there is by definition no way you can get something other than <span class="math inline">\(p\)</span> by a poly trader looking at <span class="math inline">\(\Pj\)</span>). Make trades continuous and budget.
<ul>
<li>(Q: this seems probabilistic—how do you prevent having bad luck for arbitrarily long bounded time?)</li>
<li><strong>This seems more complicated than the rest; read this proof.</strong></li>
</ul></li>
</ul></li>
<li>Provability induction
<ul>
<li>Use pseudorandomness with answer 1.</li>
<li>Confusion: what if deduction process doesn’t hit all theorems?</li>
</ul></li>
</ul>
<h2 id="discussion">Discussion</h2>
<p>Compare with Solomonoff induction.</p>
<blockquote>
<p>This (uncomputable) algorithm is impractical, but has nevertheless been of theoretical use: its basic idiom-consult a series of experts, reward accurate predictions, and penalize complexity-is commonplace in statistics, predictive analytics, and machine learning.</p>
</blockquote>
<blockquote>
<p>experts consulted by logical inductors don’t make predictions about what is going to happen next; instead, they observe the aggregated advice of all the experts (including themselves) and attempt to exploit inefficiencies in that aggregate model.</p>
</blockquote>
<blockquote>
<p>consider the task of designing an AI system that reasons about the behavior of computer programs, or that reasons about its own beliefs and its own effects on the world. While practical algorithms for achieving these feats are sure to make use of heuristics and approximations, we believe scientists will have an easier time designing robust and reliable systems if they have some way to relate those approximations to theoretical algorithms that are known to behave well in principle</p>
</blockquote>
<p>3 takeaways.</p>
<ol type="1">
<li>Make predictions by combining advice from ensemble of experts (Solomonoff + Gaifman). Note LIA many only see sequence of sets from a theorem prover. (Ex. only see “#1 is true” “#2 is false or #3 is true”, etc.)
<ul>
<li>No meta-cognition (what to think about)</li>
<li>Not practical—bad bounds</li>
</ul></li>
<li>Keep experts small. <strong>Experts do not predict the world</strong>. They identify inconsistencies even if they don’t know what’s actually happening.</li>
<li>Make trading functions continuous.</li>
</ol>
<blockquote>
<p>Showing traders the current market prices is not trivial, because the market prices on day n depend on which trades are made on day n, creating a circular dependency. Our framework breaks this cycle by requiring that the traders use continuous betting strategies, guaranteeing that stable beliefs can be found… something like continuity is strictly necessary, if the market is to have accurate beliefs about itself.</p>
</blockquote>
<p>This breaks paradoxes. Ex. <span class="math inline">\(\chi = &quot;\Pj_n(\chi)&lt;0.5&quot;\)</span>.</p>
<p>Generality:</p>
<ul>
<li>not tied to any specific notion of efficiency.</li>
<li>definition of trader flexible.</li>
<li>not specific to domain of logic (all that is necessary is a set of atomic events that can be “true” or “false”, a language for talking about Boolean combinations of those atoms, and a deductive process that asserts things about those atoms over time)</li>
</ul>
<h3 id="open-problems">Open problems</h3>
<ul>
<li><ol start="15" type="1">
<li>Decision rationality: target specific, decision-relevant claims; reason as efficiently as possible about those claims. (Ex. reason about one sentence in particular.) <!-- also steer deductive process? --></li>
</ol></li>
<li><ol start="16" type="1">
<li>Answers counterpossible questions.</li>
</ol>
<ul>
<li>Why? Need to reason what would happen if agent had output a vs. b.</li>
</ul></li>
<li><ol start="17" type="1">
<li>Use of old evidence.</li>
</ol>
<blockquote>
<p>a strong solution to the problem of old evidence isn’t just about finding new ways to use old data every so often; it’s about giving a satisfactory account of how to algorithmically generate new scientific theories.</p>
</blockquote></li>
<li><ol start="14" type="1">
<li>Efficiency</li>
</ol>
<blockquote>
<p>Imagine we pick some limited domain of reasoning, and a collection of constant- and linear-time traders. Imagine we use standard approximation methods (such as gradient descent) to find approximately-stable market prices that aggregate knowledge from those traders.</p>
</blockquote></li>
</ul>
<h2 id="misc">Misc</h2>
<p>“No dutch book” in expected utility theory, Bayesian probability theory</p>
<p>Given a sequence of bits which follow a polytime generable pattern, will it learn it in the limit?</p>
<p>Limitation (5.5.1): If <span class="math inline">\(\ol\Pj\)</span> is a logical inductor over <span class="math inline">\(\Ga\)</span> representing computable functions, <span class="math inline">\(\forall \phi, \Ga\vdash \phi, \forall n&gt;f(\phi,\ep), \Pj_n(\phi) &gt;1-\ep\)</span>, then <span class="math inline">\(f\)</span> is uncomputable.</p>
<p>Otherwise, you can use <span class="math inline">\(f\)</span> to design an algorithm that tells whether <span class="math inline">\(\Ga\vdash \phi\)</span>. (Falsify <span class="math inline">\(\phi\)</span> by finding <span class="math inline">\(n&gt;f(\phi,\rc b)\)</span> and <span class="math inline">\(\Pj_n(\phi)\le 1-\rc b\)</span>.</p>
<p>If <span class="math inline">\(D\)</span> does not eventually spew out a theorem <span class="math inline">\(\phi\)</span>, then there’s no guarantee of convergence for <span class="math inline">\(\phi\)</span>?</p>
<h3 id="extended-paper">Extended paper</h3>
<ul>
<li>In what sense is self-trust impossible in formal logic? p. 8</li>
<li>Where do you use the fact, in proving the consequences, that it was against polytime continuous traders with coefficients in <span class="math inline">\(\mathcal EF\)</span>?</li>
</ul>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>What does this mean? Surely not <span class="math inline">\(L\)</span> is only propositional logic. <span class="math inline">\(L\)</span> is any logic that’s universal (in the sense that you can express anything in arithmetic), right?<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Checking propositional consistency is tractable if you restrict to a finite number of sentences. Otherwise (given oracle to <span class="math inline">\(\mathbb W\)</span>), of course not because there’s infinitely many things to check.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Why this definition? (Note: in the paper this is written as <span class="math inline">\(T_i(\ol{\mathbb{V}})\)</span>. I changed this to be more consistent in notation.)<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>At any finite time a trader can earn arbitrarily large amount of money, but this is a statement about unbounded, not arbitrarily large.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>??? Prefix complexity has to be with respect to something.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>What is this?<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>What about transformations? Ex. if <span class="math inline">\(P\)</span> is a polytime transformation <span class="math inline">\(S\to \R^{\opl (S\cup \{1\})}\)</span>, such that <span class="math inline">\(P(s)=0\)</span> in all worlds ((or just is provable) and this is provable within <span class="math inline">\(\Ga\)</span>?), then eventually it becomes 0? (I mean on worst case <span class="math inline">\(s\)</span> too, not just specific <span class="math inline">\(s\)</span>.) Also, do there exist computable sequences <span class="math inline">\(A_n\)</span> of theorems such that for each <span class="math inline">\(n\)</span>, <span class="math inline">\(A_n\)</span> is provable, but <span class="math inline">\(\forall n, A_n\)</span> is not provable? (Here we don’t have the generators for <span class="math inline">\(A_n\)</span>. Could we do more with the generators? The <span class="math inline">\(A_n\)</span> are just given to us by some adversary.)<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>How do polytime traders get access to prices if they are real numbers? Do they only get <span class="math inline">\(\rc{\poly(n)}\)</span> precision?<a href="#fnref8">↩</a></p></li>
</ol>
</section>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Concrete problems in AI safety</title>
    <link href="http://holdenlee.github.io/notebook/posts/cs/ai/control/concrete.html" />
    <id>http://holdenlee.github.io/notebook/posts/cs/ai/control/concrete.html</id>
    <published>2017-02-01T00:00:00Z</published>
    <updated>2017-02-01T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Concrete problems in AI safety</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-01 
          , Modified: 2017-02-01 
	</p>
      
       <p>Tags: <a href="/tags/ai%20safety.html">ai safety</a>, <a href="/tags/machine%20learning.html">machine learning</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"></div>

  <div class="blog-main">
    <blockquote>
<p>Focus is on the empirical study of practical safety problems in modern machine learning systems, which we believe is likely to be robustly useful across a broad variety of potential risks, both short-and long-term</p>
</blockquote>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>

</feed>
