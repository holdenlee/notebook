---
title: Theorem proving with modern ML
published: 2017-09-05
modified: 2017-09-05
tags: theorem proving
type: problem
showTOC: True
---

# Vlad's references

1. Neural Meta-Induction and Program Synthesis
	* [arxiv](https://arxiv.org/abs/1703.07469)
	* [microsoft](https://www.microsoft.com/en-us/research/blog/deep-learning-program-synthesis/)
2. DeepMath - continuous representations of symbolic expressions [arxiv](https://arxiv.org/abs/1611.01423)
3. Terpret-  A language for program Induction [arxiv](https://arxiv.org/abs/1608.04428)
4. End to End differentiable proving [arxiv]( https://arxiv.org/pdf/1705.11040.pdf)
5. Alemi et al., "Deepmath - Deep sequence models for premise selection". NIPS 2016. arxiv, research@google.
6. Kaliszyk, Chollet, Szegedy., "HolStep: A machine learning dataset for higher-order logic theorem proving". ICLR 2017. arxiv,research@google
7. Alemi et al., "Deep variational information bottleneck". ICLR 2017. arxiv
8. Loos et al., "Deep network guided proof search". LPAR 2017. arxiv, research@google.
9.  Learning to Discover Efficient Mathematical Identities [arxiv](https://arxiv.org/abs/1406.1584)

# Game plan

* Skim over.
* Understand one theorem prover deeply (ex. HOL), interfacing with it.
