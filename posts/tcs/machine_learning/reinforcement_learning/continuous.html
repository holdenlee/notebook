<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

  <meta name="description" content="Holden Lee's Research Notebook">
  <meta name="author" content="Holden Lee">
    
  <title>MDP's with continuous state space</title>

  <!-- Bootstrap core CSS -->
  <link href="../../../../bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
  <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

  <!-- Custom styles for this template -->
  <link href="../../../../css/blog.css" rel="stylesheet">
  <link href="../../../../css/default.css" rel="stylesheet">

  <!-- Extension : Footnotes -->
  <link href="../../../../footnotes/css/footnotes.css" rel="stylesheet">

  <!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->
  

  <!-- Extension : Collapsible lists @ http://code.stephenmorley.org/javascript/collapsible-lists/-->
  <link href="../../../../collapsible_lists/css/collapsible.css" rel="stylesheet">
  <script type="text/javascript" src="../../../../collapsible_lists/js/CollapsibleLists.js"></script>

</head>

<body>

<!-- Navigation bar. navbar-inverse is black, navbar-default is white.-->
<!-- To make a button active (pressed), use <li class="active"> -->
<div id="header">
  <nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../../">Notebook</a>
      </div>
      <div id="navbar" class="collapse navbar-collapse">
        <ul class="nav navbar-nav">
          <li><a href="../../../../">Home</a></li>
          <li><a href="../../../../sitemap.html">Sitemap</a></li>
<!-- TODO: Distinguish between PAPERS, RESEARCH QUESTIONS, BOOKS -->
<!-- TODO: make this part a for loop over main pages -->
        </ul>
      </div><!--/.nav-collapse -->
    </div>
  </nav>
</div>
<!-- Content -->
<!--div id="content">
  <h1>Mental Wilderness</h1>-->



<div class="container">
  <div id="content">
    <div class="page header">
      <h1>MDP's with continuous state space</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-10-14 
          , Modified: 2016-10-14 
	</p>
      
       <p>Tags: <a href="../../../../tags/none.html">none</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#starting-points">Starting points</a></li>
 <li><a href="#model">Model</a><ul>
 <li><a href="#first-try">First try</a></li>
 <li><a href="#second-try">Second try</a></li>
 </ul></li>
 <li><a href="#references">References</a><ul>
 <li><a href="#online">Online</a></li>
 <li><a href="#books">Books</a></li>
 <li><a href="#papers">Papers</a></li>
 </ul></li>
 <li><a href="#misc">Misc</a></li>
 </ul> </div>

  <div class="blog-main">
    <p><a href="https://en.wikipedia.org/wiki/Kalman_filter">Kalman filter</a></p>
<p>Come up with a class of MDPs on exponentially large/continuous space that is interesting and tractable. Think of generalizing from contextual bandits * Basically we want a reasonable model of a MDP with a very large (exponential or continuous) state space and be able to do something with it. Wanted to include some dynamics like in Kalman filters but we weren’t sure whether Kalman filters are tractable * Todo: learn about Kalman filters</p>
<h2 id="starting-points">Starting points</h2>
<ol type="1">
<li>HMM’s have discrete state space. What happens with continuous state space? Suppose there are some dynamics as in Kalman filters. Infer the hidden state. References
<ul>
<li>Continuous HMM paper (RKHS)</li>
<li>Kalman filters (see examples)</li>
<li>Grad descent learning dynamical systems.</li>
</ul></li>
<li>Contextual bandits + MDP’s. Don’t assume there’s a hidden state here, just that next state depends, say, linearly on action and noise.</li>
<li>Context vector/random walk model for documents: transition probabilities <span class="math inline">\(\propto \exp(-\an{c_1,c_2})\)</span> and observation probabilities <span class="math inline">\(\propto \exp(-\an{c_1,x})\)</span>.</li>
</ol>
<h2 id="model">Model</h2>
<h3 id="first-try">First try</h3>
<ul>
<li>Stochastic setting.</li>
<li><span class="math inline">\(c_t\)</span> is context at time <span class="math inline">\(t\)</span>.</li>
<li>Set of actions <span class="math inline">\(A\)</span>. (For example, <span class="math inline">\(A=\{e_1,\ldots, e_n\}\)</span>.)</li>
<li>Next context <span class="math inline">\(c_{t+1}=\)</span> (Here <span class="math inline">\(w_t\)</span> is noise.)
<ul>
<li><span class="math inline">\(F_a c_t + w_t\)</span>. (Transformation depends on action.)</li>
<li><span class="math inline">\(F c_t + B a + w_t\)</span>. (Action is a forcing term. This matches Kalman formulation. More reasonable?) (*)</li>
</ul></li>
<li>Payoff depends on context and actions in some way.
<ul>
<li>Model 1: depends only on context <span class="math inline">\(\te^T c_t\)</span>. (*)</li>
<li>Model 2: depends on context and action <span class="math inline">\(\te^T[c_t;a]\)</span>.</li>
<li>? Some probability?</li>
</ul></li>
</ul>
<p>This setting looks like reinforcement learning + control theory. Prior work? How is RL used in continuous systems right now? Basic control theory background?</p>
<p>Need the model to be a generalization of regular MDP.</p>
<p>(*) may be interesting from control theory perspective, but doesn’t generalize discrete MDP. (Seems like best to learn the dynamics, and then do optimal thing from there…)</p>
<h3 id="second-try">Second try</h3>
<ul>
<li>Finite number of actions</li>
<li><span class="math inline">\(c_{t+1} = F_a c_t + w_t\)</span>. (Only probability is noise.)</li>
<li>Payout <span class="math inline">\(\te_^T c_t\)</span>.</li>
</ul>
<p>Captures deterministic MDP, but not probabilistic, by letting <span class="math inline">\(A=\{e_i\}\)</span>.</p>
<h2 id="references">References</h2>
<h3 id="online">Online</h3>
<ul>
<li><a href="http://castlelab.princeton.edu/">CASTLE Labs</a>
<ul>
<li><a href="http://optimallearning.princeton.edu/">Optimal learning</a></li>
<li><a href="http://adp.princeton.edu/">Approximate dynamic programming</a>
<ul>
<li><a href="http://adp.princeton.edu/adpIntros.htm">Intros</a></li>
</ul></li>
<li><a href="http://castlelab.princeton.edu/jungle.htm#unifiedframework">Unified framework</a></li>
</ul></li>
<li><a href="https://github.com/andrewliao11/Deep-Reinforcement-Learning-Survey/blob/master/Reinforcement-Learning-Papers.md">Deep RL</a></li>
</ul>
<h3 id="books">Books</h3>
<p><a href="https://www.quora.com/What-are-the-best-books-about-reinforcement-learning">Recommendations</a></p>
<ul>
<li><a href="https://books.google.com/books?id=VvBjBAAAQBAJ&amp;printsec=frontcover&amp;dq=continuous+markov+decision+processes&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjo3OLywOnPAhVHWD4KHXzgDWUQ6AEIKTAC#v=onepage&amp;q=continuous%20markov%20decision%20processes&amp;f=false">Puterman14</a></li>
<li><p><a href="https://books.google.com/books?id=-6RiQgAACAAJ&amp;dq=Dynamic+Programming:+Deterministic+and+Stochastic+Models&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjc0pfAyefPAhUGFz4KHaVIDecQ6AEIHjAA">Bertsekas87</a></p></li>
<li><a href="http://site.ebrary.com/lib/princeton/detail.action?docID=10560566">Optimal learning</a></li>
<li><p><a href="http://www.crcnetbase.com/isbn/9781439821091">Function approximators</a></p></li>
</ul>
<h3 id="papers">Papers</h3>
<ul>
<li><a href="http://people.csail.mit.edu/agf/Files/13FTML-RLTutorial.pdf">lin function approximators</a></li>
<li><a href="https://hal.archives-ouvertes.fr/hal-00747575v5/document">optimistic principle</a></li>
<li><a href="http://web.mit.edu/dimitrib/www/dpchapter.pdf">ADP</a></li>
<li><a href="http://site.ebrary.com/lib/princeton/reader.action?docID=10501323">Approximate DP</a></li>
<li><p><a href="http://www.morganclaypool.com/doi/abs/10.2200/S00268ED1V01Y201005AIM009">Algorithms for RL</a></p></li>
<li></li>
</ul>
<h2 id="misc">Misc</h2>
<p>Do as well as best Bayes net? Actions in some class. Finite set of actions, vs. exponential/continuous set of actions. In latter case, will depend on optimizability of that set…</p>
<p>Ex. class is a SVM.</p>
<p>“Do as well as best estimator of <span class="math inline">\(q\)</span> function in a certain class (assume convexity or something?)” (cf. contextual bandits first)</p>
<!--Definitely need something stronger than: there exist something that works! if can encode crypto 

Upper confidence bounds
-->

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class="st_facebook_large" displayText="Facebook"></span>
    <span class="st_twitter_large" displayText="Tweet"></span>
    <span class="st_googleplus_large" displayText="Google +"></span>
    <span class="st_reddit_large" displayText="Reddit"></span>
    <span class="st__large" displayText></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>


<!-- Footer -->
<div id="footer">
  <div class="container">
    Built with
    <a href="http://jaspervdj.be/hakyll">Hakyll</a> 
    using 
    <a href="http://www.getbootstrap.com">Bootstrap</a>, 
    <a href="http://www.disqus.com">Disqus</a>,
    <a href="http://ignorethecode.net/blog/2010/04/20/footnotes/">Footnotes.js</a>,
    <a href="http://highlightjs.org/">Highlight.js</a>, 
    <a href="http://www.mathjax.org">MathJax</a>, 
    and <a href="http://www.sharethis.com">ShareThis</a>.
  </div>
</div>
</body>

</html>

<!-- SCRIPTS -->
<!-- jQuery-->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>

<script src="../../../../bootstrap/js/bootstrap.min.js"></script>

<!-- Extension : Highlight.js @ https://highlightjs.org/ -->
<!-- Syntax highlighting tomorrow-night-bright, agate-->
<link rel="stylesheet" href="../../../../highlight/css/tomorrow-night-bright.css">
<script src="../../../../highlight/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<!-- Extension : MathJax @ https://docs.mathjax.org/en/v2.5-latest/tex.html -->
<!-- MathJax/config/local/local.js contains macros. Need to provide entire URL-->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML,http://holdenlee.github.io/notebook/MathJax/config/local/local"></script>

<!-- Extension : Footnotes @ http://ignorethecode.net/blog/2010/04/20/footnotes/ -->
<script src="../../../../footnotes/js/footnotes.js"></script>

<!-- Extension : Disqus @ http://disqus.com -->
<!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->

<script src="../../../../disqus/js/disqus.js"></script>



<!-- Extension : Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-73261814-1', 'auto');
  ga('send', 'pageview');

</script>

