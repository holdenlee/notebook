<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->

  <meta name="description" content="Holden Lee's Research Notebook">
  <meta name="author" content="Holden Lee">
    
  <title>Reinforcement learning convergence</title>

  <!-- Bootstrap core CSS -->
  <link href="../../../../bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
  <!-- <link href="../../assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet"> -->

  <!-- Custom styles for this template -->
  <link href="../../../../css/blog.css" rel="stylesheet">
  <link href="../../../../css/default.css" rel="stylesheet">

  <!-- Extension : Footnotes -->
  <link href="../../../../footnotes/css/footnotes.css" rel="stylesheet">

  <!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->
  

  <!-- Extension : Collapsible lists @ http://code.stephenmorley.org/javascript/collapsible-lists/-->
  <link href="../../../../collapsible_lists/css/collapsible.css" rel="stylesheet">
  <script type="text/javascript" src="../../../../collapsible_lists/js/CollapsibleLists.js"></script>

</head>

<body>

<!-- Navigation bar. navbar-inverse is black, navbar-default is white.-->
<!-- To make a button active (pressed), use <li class="active"> -->
<div id="header">
  <nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../../">Notebook</a>
      </div>
      <div id="navbar" class="collapse navbar-collapse">
        <ul class="nav navbar-nav">
          <li><a href="../../../../">Home</a></li>
          <li><a href="../../../../sitemap.html">Sitemap</a></li>
<!-- TODO: Distinguish between PAPERS, RESEARCH QUESTIONS, BOOKS -->
<!-- TODO: make this part a for loop over main pages -->
        </ul>
      </div><!--/.nav-collapse -->
    </div>
  </nav>
</div>
<!-- Content -->
<!--div id="content">
  <h1>Mental Wilderness</h1>-->



<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Reinforcement learning convergence</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-10-24 
          , Modified: 2016-11-21 
	</p>
      
       <p>Tags: <a href="../../../../tags/reinforcement%20learning.html">reinforcement learning</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#policy-estimation">Policy estimation</a></li>
 <li><a href="#policyvalue-iteration">Policy/value iteration</a><ul>
 <li><a href="#changing-ga">Changing <span class="math inline">$\ga$</span></a></li>
 <li><a href="#alternating-policy-improvementevaluation">Alternating policy improvement/evaluation</a></li>
 </ul></li>
 <li><a href="#q-learning">Q-learning</a><ul>
 <li><a href="#preliminaries">Preliminaries</a></li>
 <li><a href="#convergence-of-q-learning">Convergence of Q-learning</a></li>
 </ul></li>
 </ul> </div>

  <div class="blog-main">
    <p>Here we’re interested in convergence guarantees for algorithms/methods used in practice. (Rather than, e.g., coming up with provable polytime theoretical algorithms that work but are too slow to be used in practice.)</p>
<p>Recall: Mixing time <span class="math inline">\(\tau_\ep = \min\set{t}{\max_{P_0} \ve{P_t - P_{\text{eq}}}\le \ep} \le \fc{\ln \pf{N}{\ep}}{\de}\)</span>, <span class="math inline">\(\de=1-\max_{k\ge 2}|\la_k|\)</span>.</p>
<h2 id="policy-estimation">Policy estimation</h2>
Policy satisfies
<span class="math display">\[\begin{align}
v_\pi  &amp;= d(P_\pi^T R_\pi) + \ga P_\pi v\\
\iff 
v_\pi &amp;= (I-\ga P_\pi)^{-1} d(P_\pi^T R_\pi).
\end{align}\]</span>
Then
<span class="math display">\[\begin{align}
v_{k+1} &amp;= d(P_\pi^T R_\pi) + \ga P_\pi v_k\\
v_{k+1} - v_\pi &amp;= \ga P_\pi (v_k-v_\pi).
\end{align}\]</span>
<p>So convergence happens at rate of <span class="math inline">\(\ga \ve{P_\pi}_2\)</span> to <span class="math inline">\(v_\pi\)</span>.</p>
<p>For nondiscounted case, we get <span class="math display">\[
v_t = \rc t[d + P_\pi d+ \cdots + P_\pi^{t-1} d].
\]</span> We find (are stochastic matrices diagonalizable?) <span class="math inline">\(v\)</span> is the projection of <span class="math inline">\(d\)</span> onto space of 1-eigenvectors.</p>
<p>(Notation is easier if the reward only depends on <span class="math inline">\(s,a\)</span>; then we just get <span class="math inline">\(v_\pi = r_\pi + \ga P_\pi v_\pi\)</span>.)</p>
<h2 id="policyvalue-iteration">Policy/value iteration</h2>
<p>Why does it improve? Let</p>
<ul>
<li><span class="math inline">\(P_{\pi, s',s} = \Pj(s'|s,\pi(s))\)</span></li>
<li><span class="math inline">\(R_{\pi, s',s} = r(s,\pi(s),s')\)</span></li>
<li><span class="math inline">\(q_{\pi,\pi'} = q_\pi(s,\pi'(s))\)</span>.</li>
</ul>
Write the Bellman equation as (<span class="math inline">\(d(A)\)</span> is the diagonal of <span class="math inline">\(A\)</span>)
<span class="math display">\[\begin{align}
v_\pi &amp;= d(P_\pi^TR) + \ga P_\pi^T v_\pi\\
q_{\pi,\pi'} &amp;= d(P_{\pi'}^TR_{\pi'}) + \ga P_{\pi'}^T v_\pi\\
v_\pi &amp;=(I-\ga P_\pi^T)^{-1} d(P_{\pi'}^T, R_{\pi'})\\
q_{\pi,\pi'} &amp;= (1-\ga P_{\pi'}^T)^{-1} d(P_{\pi'}^TR_{\pi'})
\end{align}\]</span>
We have
<span class="math display">\[\begin{align}
q_{\pi,\pi'} &amp; \ge q_{\pi,\pi} = v_\pi\\
\iff 
d(P_{\pi'}^TR_{\pi'}) + \ga P_{\pi'}^T v_\pi &amp; \ge v_\pi \\
\iff
v_{\pi'} = (I-\ga P_{\pi'}^T)^{-1} d(P_{\pi'}^TR) &amp; \ge (I-\ga P_{\pi'}^T)^{-1} (I-\ga P_{\pi'}^T) v_\pi = v_\pi.
\end{align}\]</span>
<!--\ge d(P_\pi^T R_\pi) + P_\pi^T v_\pi-->
<p>(Note <span class="math inline">\(I-\ga P_{\pi'}^T\)</span> is a geometric series so has positive entries.)</p>
<!-- analysis for $q$-values. How improve when $\ga$ increases to 1?-->
<!--$q$-iteration weirder? $q_a^{t+1} = R_a + \ga P_a^t q_b$. No, don't work with q-->
<ol type="1">
<li><p>Value iteration: <span class="math inline">\(\ve{v^{n+1}-v^n}\le \fc{\ep(1-\la)}{2\la}\implies \ve{v^{n+1}-v_\la^*}&lt;\eph\)</span>. (161)</p>
Proof: Let <span class="math inline">\(v^{n+1}\)</span> be the vale if you follow <span class="math inline">\(\pi^n\)</span> after choosing the best <span class="math inline">\(a\)</span> and <span class="math inline">\(v^{*n+1}\)</span> be the value if you follow <span class="math inline">\(\pi^{n+1}\)</span>. Then
<span class="math display">\[\begin{align}
\ve{v^{*n+1} - v^{n+1}} &amp;\le \ve{Lv^{*n+1} - Lv^{n+1}} + \ve{Lv^{n+1} - v^{n+1}}\\
\implies \ve{v^{*n+1} - v^{n+1}} &amp;\le \fc{\la }{1-\la} \ve{v^{n+1}-v^n}
\end{align}\]</span>
Geometric series gives <span class="math display">\[\ve{v^{n+1} - v_\la^*} \le \fc{\la}{1-\la} \ve{v^{n+1} - v^n}.\]</span></li>
<li><p>Policy iteration (180)</p></li>
</ol>
<h3 id="changing-ga">Changing <span class="math inline">\(\ga\)</span></h3>
<p>Do a triangle inequality between <span class="math display">\[
v_{*'}^{\ga'} = (I-\ga'P_*')^{-1}r_*, v_{*'}^{\ga}, v_\pi^\ga, v_\pi^{\ga'}.
\]</span> More involved with averaging <span class="math inline">\(\lim_{T\to \iy}\rc T\cdots\)</span>. Choose <span class="math inline">\(\ga\)</span> small enough so that can be approximated with rectangles, etc.</p>
<h3 id="alternating-policy-improvementevaluation">Alternating policy improvement/evaluation</h3>
<p><span class="math display">\[\pi'(s) = \amax_a \sum_{s'} p(s'|s,a) [r(s,a,s') + \ga v_\pi(s')].\]</span></p>
<h2 id="q-learning">Q-learning</h2>
<ul>
<li>[WatkinsDayan92] Q-learning</li>
<li>[Tsitsiklis94] Asynchronous Stochastic Approximation and Q-learning</li>
</ul>
<p>Main idea: to solve a fixed-point equation, need an unbiased approximation of operator <span class="math inline">\(F\)</span>, and <span class="math inline">\(F\)</span> to be a contraction. (Noise is not a big deal—finiteness is usually enough.)</p>
<h3 id="preliminaries">Preliminaries</h3>
<p>Abstraction: Solve fixed point equation <span class="math display">\[F(x)=x.\]</span> Let <span class="math inline">\(T^i\)</span> be the set of times when <span class="math inline">\(x_i\)</span> is updated, and the update equation be <span class="math display">\[x_i(t+1) = x_i(t) + \al_i(t) (F_i(x^i(t)) + w_i(t) - x_i(t)).\]</span> The components of <span class="math inline">\(x^i(t)\)</span> are <span class="math inline">\(x_j(\tau_j^i(t))\)</span>, possibly outdated. (If they are not outdated, <span class="math inline">\(\tau=t\)</span>.)</p>
<p>Assumptions: Let <span class="math inline">\(\mathcal F(t)\)</span> be the subfield at time <span class="math inline">\(t\)</span>. Define <span class="math inline">\(\ve{x}_v=\max_i \fc{|x_i|}{v_i}\)</span>.</p>
<ol type="1">
<li><span class="math inline">\(\forall i,j, \lim_{t\to \iy} \tau_j^i(t)=\iy\)</span>. (This allows outdated info!)</li>
<li>(Noise)
<ul>
<li>Mean: <span class="math inline">\(\E[w_i(t)|\mathcal F(t)]=0\)</span>.</li>
<li>Variance: <span class="math inline">\(\E[w_i(t)^2| \mathcal F(t)]\le A + B\max_j \max_{\tau\le t}|x_j(\tau)|^2\)</span>.</li>
</ul></li>
<li>(Enough updating, but not too much)
<ul>
<li><span class="math inline">\(\sumz t{\iy} \al_i(t)=\iy\)</span></li>
<li><span class="math inline">\(\sumz t{\iy} \al_i^2(t) \le C\)</span>.</li>
</ul></li>
<li><span class="math inline">\(F\)</span> is monotone wrt pointwise <span class="math inline">\(\le\)</span>, continuous, has unique fixed point, and is 1-Lipschitz in the <span class="math inline">\(\one\)</span> direction.</li>
<li>(Contraction) <span class="math inline">\(\exists v&gt;0, \be\in [0,1),\forall x, \ve{F(x) - x^*}_v\le \be \ve{x-x^*}_v\)</span>.</li>
<li>(Weaker form of contraction) <span class="math inline">\(\exists v&gt;0, \be\in[0,1), D, \forall x, \ve{F(x)}_v\le \be \ve{x}_v+D\)</span>.</li>
<li>For undiscounted state only: There exists at least one proper stationary policy (probability at being absorbing state <span class="math inline">\(\to 1\)</span>), and every improper stationary policy has <span class="math inline">\(\iy\)</span> expected cost for some initial state.</li>
</ol>
<p><strong>Theorem</strong>: 1, 2, 3, 5 imply that <span class="math inline">\(x(t)\to x^*\)</span> w.p. 1.</p>
<p><strong>Lemma</strong>: Let <span class="math inline">\(\{\mathcal F(t)\}\)</span> be an increasing sequence of <span class="math inline">\(\si\)</span>-fields, <span class="math inline">\(\al(t),w(t-1), B(t)\)</span> be <span class="math inline">\(\mathcal F(t)\)</span>-measurable. If</p>
<ul>
<li><span class="math inline">\(\E[w(t)|\mathcal F(t)]=0\)</span></li>
<li><span class="math inline">\(\E[w^2(t)|\mathcal F(t)]\le B(t)\)</span></li>
<li><span class="math inline">\(\al(t)\in [0,1]\)</span></li>
<li><span class="math inline">\(\sumz t{\iy} \al(t)=\iy\)</span></li>
<li><span class="math inline">\(\sumz t{\iy}\al^2(t)\le C\)</span></li>
<li><span class="math inline">\(\{B(t)\}\)</span> is bounded wp 1</li>
</ul>
<p>and <span class="math inline">\(W(t+1)=(1-\al(t))W(t) + \al(t) w(t)\)</span> then <span class="math inline">\(\lim_{t\to \iy}W(t)=0\)</span> wp 1.</p>
<p><em>Proof</em>. Write out the expression for <span class="math inline">\(W(t)\)</span>. The term <span class="math inline">\(\prodz t{T} (1-\al(t))W^0(t)\to 0\)</span>. The other terms: square and use Chebyshev.</p>
<p><strong>Theorem</strong>. 1, 2, 3, 6 imply that <span class="math inline">\(x(t)\)</span> is bounded.</p>
<p><em>Proof</em>. We have <span class="math inline">\(\max |F_i(x)|\le \ga \max(\max_j (|x_j|,G_0))\)</span>.</p>
<p>Look at the relative fluctuations (wrt the nearest power of <span class="math inline">\(G_0\)</span>). As <span class="math inline">\(M(t)=\max_{\tau\le t}\ve{x(\tau)}_\iy\)</span> gets big it gets more and more difficult for the relative fluctuations (actually, relative to the next smaller <span class="math inline">\(G\ga^{-k}\)</span>, for technical reasons) to be big. To argue this, apply lemma to normalized <span class="math inline">\(\wt w_i(t) = \fc{w_i(t)}{G(t)}\)</span> to show the fluctuations after <span class="math inline">\(t_0\)</span> are go to 0 as <span class="math inline">\(t_0\to \iy\)</span>. (Define <span class="math inline">\(\wt W(t_0;t_0)=0\)</span> and define <span class="math inline">\(\wt W(t;t_0)\)</span> with the recurrence but with <span class="math inline">\(\wt w_i(t)\)</span>.) Now <span class="math inline">\(\wt W_i(t;t_0)\)</span> small means that <span class="math inline">\(x_i(t+1)\)</span> can’t “overcome” the <span class="math inline">\(\ga\)</span> contraction factor.</p>
<p>Adding in assumption 5: Now show that <span class="math inline">\(\ve{x(t)}_{\iy}\le D_k\)</span> implies that <span class="math inline">\(\ve{x(t)}_{\iy}\le D_{k+1} := \be (1+2\ep)D_k\)</span> at some later <span class="math inline">\(r\)</span>. Proof is similar, except we establish contraction instead of just non-expansion. When bounding <span class="math inline">\(x_i(t+1)\)</span> use assumption 5.</p>
<p><strong>Question: what is the convergence rate? (Exercise!)</strong> Based on the analysis (proceeding by a geometric sequence), it’s probably linear.</p>
<h3 id="convergence-of-q-learning">Convergence of Q-learning</h3>
<p><span class="math inline">\(c_{iu}\)</span> is cost of <span class="math inline">\(u\)</span> at state <span class="math inline">\(i\)</span>.</p>
<p>Here</p>
<span class="math display">\[\begin{align}
T_i(V) &amp;= \min_{u\in U(i)}
\ba{\E[c_{iu}] + \be\sum_{j\in S} p_{ij}(u)V_j}\\
F_{iu} (Q) &amp; = \E c_{iu} + \be \sum_{j\in S} p_{ij}(u) \min_{v\in U(j)} Q_{jv}\\
W_{iu}(t) &amp;= c_{iu} - \E c_{iu} + \min_{v\in U(s(i,u))} Q_{s(i,u),v}(t) - \E[\min_{v\in U(s,(i,u))} Q_{s(i,u),v}(t) | \mathcal F(t)]
\end{align}\]</span>
<p>(Note that implicitly <span class="math inline">\(\min_{v...}Q... = \sum_{j\in S} p_{ij}(u) \min_{v\in U(j)}Q_{jv}\)</span>.)</p>
<p>(Skip: discounted policies.)</p>
<p>(cf. stochastic gradient descent?)</p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class="st_facebook_large" displayText="Facebook"></span>
    <span class="st_twitter_large" displayText="Tweet"></span>
    <span class="st_googleplus_large" displayText="Google +"></span>
    <span class="st_reddit_large" displayText="Reddit"></span>
    <span class="st__large" displayText></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>


<!-- Footer -->
<div id="footer">
  <div class="container">
    Built with
    <a href="http://jaspervdj.be/hakyll">Hakyll</a> 
    using 
    <a href="http://www.getbootstrap.com">Bootstrap</a>, 
    <a href="http://www.disqus.com">Disqus</a>,
    <a href="http://ignorethecode.net/blog/2010/04/20/footnotes/">Footnotes.js</a>,
    <a href="http://highlightjs.org/">Highlight.js</a>, 
    <a href="http://www.mathjax.org">MathJax</a>, 
    and <a href="http://www.sharethis.com">ShareThis</a>.
  </div>
</div>
</body>

</html>

<!-- SCRIPTS -->
<!-- jQuery-->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>

<script src="../../../../bootstrap/js/bootstrap.min.js"></script>

<!-- Extension : Highlight.js @ https://highlightjs.org/ -->
<!-- Syntax highlighting tomorrow-night-bright, agate-->
<link rel="stylesheet" href="../../../../highlight/css/tomorrow-night-bright.css">
<script src="../../../../highlight/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<!-- Extension : MathJax @ https://docs.mathjax.org/en/v2.5-latest/tex.html -->
<!-- MathJax/config/local/local.js contains macros. Need to provide entire URL-->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML,http://holdenlee.github.io/notebook/MathJax/config/local/local"></script>

<!-- Extension : Footnotes @ http://ignorethecode.net/blog/2010/04/20/footnotes/ -->
<script src="../../../../footnotes/js/footnotes.js"></script>

<!-- Extension : Disqus @ http://disqus.com -->
<!-- Extension : InlineDisqussions @ https://github.com/tsi/inlineDisqussions -->

<script src="../../../../disqus/js/disqus.js"></script>



<!-- Extension : Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-73261814-1', 'auto');
  ga('send', 'pageview');

</script>

