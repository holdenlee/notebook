<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Research Notebook</title>
    <link href="http://holdenlee.github.io/notebook/atom.xml" rel="self" />
    <link href="http://holdenlee.github.io/notebook" />
    <id>http://holdenlee.github.io/notebook/atom.xml</id>
    <author>
        <name>Holden Lee</name>
        <email>oldheneel@gmail.com</email>
    </author>
    <updated>2017-02-24T00:00:00Z</updated>
    <entry>
    <title>AdaGAN</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/neural_nets/AdaGAN.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/neural_nets/AdaGAN.html</id>
    <published>2017-02-24T00:00:00Z</published>
    <updated>2017-02-24T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>AdaGAN</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-24 
          , Modified: 2017-02-24 
	</p>
      
       <p>Tags: <a href="/tags/neural%20nets.html">neural nets</a>, <a href="/tags/GAN.html">GAN</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#adagan-algorithm">AdaGAN algorithm</a></li>
 <li><a href="#question">Question</a></li>
 <li><a href="#ideas">Ideas</a></li>
 <li><a href="#concreter-questions">Concreter questions</a></li>
 <li><a href="#ideas-2">Ideas 2</a></li>
 </ul> </div>

  <div class="blog-main">
    <p>See <a href="GANs.html#adagan-boosting-generative-models">GANs</a>.</p>
<h2 id="adagan-algorithm">AdaGAN algorithm</h2>
<p>Loop:</p>
<ul>
<li><span class="math inline">\(D\leftarrow DGAN(S_N,G_{t-1})\)</span>, <span class="math inline">\(S_N\)</span> is unweighted sample</li>
<li><span class="math inline">\(\la^*\leftarrow \la(\be_t,D)\)</span></li>
<li><span class="math inline">\(W_t^i \leftarrow ...\)</span> update weights</li>
<li><span class="math inline">\(G_t^c=GAN(S_N,W_t)\)</span></li>
<li><span class="math inline">\(G_t = (1-\be_t)G_{t-1} + \be_t G_t^c\)</span>.</li>
</ul>
<p>Here, assume the discriminator is good enough to force to get some multiple closer to distribution.</p>
<h2 id="question">Question</h2>
<p>Can you reanalyze this with a more stable version of GAN, not based on KL divergence, but</p>
<ul>
<li>Wasserstein distance?</li>
<li>Neural net MMD?</li>
</ul>
<h2 id="ideas">Ideas</h2>
<p>From known results: (see <a href="../multiplicative_weights.html">MW</a>)</p>
<ul>
<li>MU for game theory: maintain probability distribution, get best column response.
<ul>
<li>This means maintaining the probability distribution generated by G and doing MU on it. No!</li>
</ul></li>
<li>MU for boosting: keep weights on data points, response is weak learner.
<ul>
<li>Here, response is generator. At end, take mixture of generators, cf. weighted majority of experts.</li>
<li>How to compute the loss? Before, it was: just the probability of WL being wrong. Now: loss is itself a maximization over discriminator. (not some linear function!)</li>
<li>Weird because in the table, it isn’t that the row/columns are the player, but rather data and 1 player; other player is missing.</li>
<li>You can’t fix the discriminator for this step—ex. the part of the data that doesn’t seem to fool this discriminator, there might be another discriminator that isn’t fooled. (You might not want to include the first generator at all???)</li>
</ul></li>
<li>Dense model theorem, regularity theorems
<ul>
<li>Label with <span class="math inline">\((0,x\sim X)\)</span>, <span class="math inline">\((1,x\sim G)\)</span>. But this is the formulation for boosting the discriminator, not the generator.</li>
</ul></li>
</ul>
<p>Can you do better than simply mixture: ex. decide whether to regenerate according to some criterion, like <span class="math inline">\(\mathcal F_k \mathcal T\)</span> for a different class <span class="math inline">\(\mathcal F\)</span>?</p>
<p>Note MU/boosting doesn’t run into RPS problem if you mix/average.</p>
<h2 id="concreter-questions">Concreter questions</h2>
<ol type="1">
<li>Suppose you want to match <span class="math inline">\(f\)</span> using combination of functions in <span class="math inline">\(\mathcal H\)</span>. What is the right formulation of boosting here?
<ul>
<li>Convex combination - this is just projection to a polytope in a subspace.</li>
<li>What are interesting <span class="math inline">\(\mathcal F\)</span> here?</li>
</ul></li>
<li>In MU for GT: if column only plays <span class="math inline">\(\rc2+\ep\)</span> good strategy, do you get anything?</li>
<li>What is the guarantee of mixture of generators?</li>
</ol>
<p>We’re actually training to completion at each step… What does “good” mean? Analogue of “over half can’t be distinguished”? MMD is bounded away from 0.</p>
<h2 id="ideas-2">Ideas 2</h2>
<ol type="1">
<li>Simpler, boolean formulation. At step <span class="math inline">\(t\)</span>, have weights on data points, increase weight if it was successfully separated. (How did they calculate weights in AdaGAN?) At end, let <span class="math inline">\(D\)</span> be best discriminator against uniform. What’s <span class="math inline">\(\E D - \sumo tT \al_t \E D(G_t)\)</span>?</li>
<li>Is there something more sophisticated/suitable than simple mixture? Ex. pick a data point and then try to generate something close to it? (not this actually…) Something like, run generators together and pick the best point from them?</li>
</ol>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Multiplicative weights</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/multiplicative_weights.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/multiplicative_weights.html</id>
    <published>2017-02-24T00:00:00Z</published>
    <updated>2017-02-24T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Multiplicative weights</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-24 
          , Modified: 2017-02-24 
	</p>
      
       <p>Tags: <a href="/tags/boosting.html">boosting</a>, <a href="/tags/multiplicative%20weights.html">multiplicative weights</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#basic-algorithm-and-guarantees">Basic algorithm and guarantees</a><ul>
 <li><a href="#problem">Problem</a></li>
 </ul></li>
 <li><a href="#algorithm">Algorithm</a></li>
 <li><a href="#guarantees">Guarantees</a><ul>
 <li><a href="#questions">Questions</a></li>
 </ul></li>
 <li><a href="#applications">Applications</a><ul>
 <li><a href="#classification-with-margin">Classification with margin</a></li>
 <li><a href="#game-theory">Game theory</a></li>
 <li><a href="#boosting">Boosting</a></li>
 </ul></li>
 <li><a href="#bayesian-interpretation">Bayesian interpretation</a></li>
 </ul> </div>

  <div class="blog-main">
    <p>Ref:</p>
<ul>
<li>Arora Hazan Kale</li>
</ul>
<p>See also <a href="optimization/multiplicative_updates.md">Curse and blessing</a></p>
<h2 id="basic-algorithm-and-guarantees">Basic algorithm and guarantees</h2>
<h3 id="problem">Problem</h3>
<ul>
<li>Prediction: <span class="math inline">\(n\)</span> experts make predictions in <span class="math inline">\(\{0,1\}\)</span> at times <span class="math inline">\(1,\ldots, T\)</span>. After seeing predictions <span class="math inline">\(y_{t,1:n}\)</span>, you make a prediction. You want your total number of mistakes to be comparable to that of the best expert.</li>
<li>Losses/gains: At each time, you get some loss for choosing 0 or 1, <span class="math inline">\(l_t(0), l_t(1)\)</span>. (Assume losses are bounded.) You want your total loss (gain) to be comparable to that of the best expert.</li>
</ul>
<h2 id="algorithm">Algorithm</h2>
<ul>
<li>Vanilla: Let <span class="math inline">\(w_{t+1,i} = w_{t,i}\pa{1-\eta m_{t,i}}\)</span>.
<ul>
<li>Deterministic: at time <span class="math inline">\(t\)</span>, take weighted majority of experts with weights <span class="math inline">\(w_{t,i}\)</span>.</li>
<li>Random: at time <span class="math inline">\(t\)</span>, randomly choose <span class="math inline">\(i\)</span> with probability proportional to <span class="math inline">\(w_{t,i}\)</span>.</li>
</ul></li>
<li>Hedge: Let <span class="math inline">\(w_{t+1,i} = w_{t,i} e^{-\eta m_{t,i}}\)</span>.</li>
<li>MWU with restriction: <span class="math inline">\(p^{(t+1)} = \amin_{p\in \mathcal P} KL(p||\wh p^{(t)})\)</span>.</li>
</ul>
<p>For “counting” case, <span class="math inline">\(m_i=1\)</span> iff mistake. For “loss” case, <span class="math inline">\(m_i\)</span> is loss. Assume <span class="math inline">\(\eta\le \rc2\)</span>.</p>
<h2 id="guarantees">Guarantees</h2>
<ol type="1">
<li>Deterministic multiplicative weights attains <span class="math display">\[
M^{(T)} \le 2(1+\eta) m_i^{(T)} + \fc{2\ln n}{\eta}.
\]</span></li>
<li>Probabilistic multiplicative weights (let <span class="math inline">\(p^{(t)}=\fc{w^{(t)}}{\Phi^{(t)}}\)</span>)
<span class="math display">\[\begin{align}
\E M^{(T)} &amp;= \sumo tT m^{(t)}\cdot p^{(t)} \le \sumo iT m_i^{(t)} + \eta\sumo tT |m_i^{(t)}| + \fc{\ln n}{\eta} \\
&amp; \le (1+\eta) m_i^{(t)} + \fc{\ln n}{\eta} 
&amp; \text{if }m_i^{(t)}\ge0.
\end{align}\]</span>
<em>Proof</em>. 2 parts.
<ol type="1">
<li><span class="math inline">\(\Phi^{(t+1)} \le \Phi^{(t)} e^{-\eta m^{(t)}\cdot p^{(t)}}\)</span>. (If costs are large, this decreases a lot. <span class="math inline">\(p_i\)</span> are exactly the slice of the pie occupied by expert <span class="math inline">\(i\)</span>.) Look at pie occupied by all experts.</li>
<li><span class="math inline">\((1-\eta)^{\sum_{\ge 0}m_i(t)} (1+\eta)^{-\sum_{\le 0} m_i(t)}\le \Phi^{(t+1)}\)</span>. Look at slice occupied by <span class="math inline">\(i\)</span>th expert.</li>
</ol></li>
<li>Hedge attains <span class="math display">\[
\sumo tT m^{(t)}\cdot p^{(t)} \le \sumo tT m_i^{(t)} + \eta\sumo tT m_i^{(t)} + \eta\sumo tT (m^{(t)})^2 \cdot p^{(t)} + \fc{\ln n}{\eta}.
\]</span> (Note this bound depends on <span class="math inline">\(p\)</span> on the RHS.</li>
<li>For MWU with restrictions, <span class="math display">\[
\sumo tT m^{(t)} \cdot p^{(t)} \le \sumo tT (m^{(t)} + \eta |m^{(t)}|)\cdot p + \fc{KL(p||p^{(1)})}{\eta}.
\]</span> (The farther away <span class="math inline">\(p\)</span> is from <span class="math inline">\(p^{(1)}\)</span> the more loss you might incur.)</li>
</ol>
<h3 id="questions">Questions</h3>
<p>What if we replace a finite number of experts with an infinite number of experts with finite VC dimension? This is typically not tractable, but can still be analyzed. Is this like the online version of ERM? Bayesian version/version with uncertainty?</p>
<h2 id="applications">Applications</h2>
<h3 id="classification-with-margin">Classification with margin</h3>
Solve
<span class="math display">\[\begin{align}
a_j^T x &amp;\ge 0\\
\one^T x&amp;=1\\
x_i &amp;\ge 0
\end{align}\]</span>
<p>under the promise that there exists <span class="math inline">\(x^*\)</span> with <span class="math inline">\(a_j^Tx^*\ge \ep\)</span>. (More generally, can solve other LP’s with margin.) Let <span class="math inline">\(\rh = \max_j \ve{a_j}_\iy\)</span>.</p>
<p>Ideas:</p>
<ol type="1">
<li>The experts are the coordinates. They do nothing except existing. It is the <em>weighting</em> that is the solution we’re looking for. (In the original formulation, the default interpretations is that the experts are some different algorithms, and we seek an algorithm using them as black boxes that does well. Here, the experts are nothing but points, and we find an algorithm that classifies well—where the “algorithm” is restricted to be in the class of linear classifiers.)
<ul>
<li>The experts are not the points <span class="math inline">\(a_j\)</span>.</li>
</ul></li>
<li>The bulk of this comes from how we define the gains. These gains should be related to the points <span class="math inline">\(a_j\)</span>.</li>
<li>Note the right sign: we should reward a coordinate <span class="math inline">\(i\)</span> if <span class="math inline">\(a_{ij}\)</span> is large, because increasing <span class="math inline">\(x_i\)</span> would increase the dot product more. (cf. gradient - but this is projected back onto the simplex by scaling (what norm is this?)) The gain is <span class="math inline">\({a_{ji}}\)</span>. <!--shouldn't be a /\rh here because that's in $\eta$--></li>
<li>We are not going through the <span class="math inline">\(a_j\)</span> in order. Instead, at each step we pick an <span class="math inline">\(a_j\)</span> where <span class="math inline">\(a_j^Tx^{(t)}&lt;0\)</span>. (! For GAN, pick <span class="math inline">\(D\)</span> that is violated?)</li>
<li>To analyze this, we consider the total number of steps where there is some <span class="math inline">\(j\)</span> such that <span class="math inline">\(a_j^T x^{(t)}&lt;0\)</span>. Let <span class="math inline">\(T\)</span> be the largest step for which this the case.</li>
</ol>
<p>The inequality is <span class="math display">\[
0 &gt; \sumo tT m^{(t)}\cdot x^{(t)} \ge 
\sumo tT m^{(T)} \cdot x^* 
- \eta \fc{\sumo tT \one^T a_{j(t)}}{\rh}
- \fc{\ln n}{\eta} = 
\pa{\fc{\eta}{\rh} - \fc{\eta}{2\rh}}T + \fc{\ln n}{\eta/(2\rh)}.
\]</span> <!-- not 1-\eta formulation --> Solving, get <span class="math inline">\(T = \ce{\fc{4\rh^2\ln n}{\ep^2}}\)</span>.</p>
<p>Notes:</p>
<ol type="1">
<li>Thinking of the difference in margins as regret, this says that we get <span class="math inline">\(O\prc{\sqrt T}\)</span> regret.</li>
<li>We can think of this as a game, <span class="math inline">\(\max_x \min_j a_j^Tx\)</span> over probability vectors. At each step, the “max/column” player chooses a mixed strategy <span class="math inline">\(x\)</span>, and the “min/row” player plays the best response. Best response is not actually necessary, just some choice of <span class="math inline">\(j\)</span> such that <span class="math inline">\(a_j^Tx&lt;0\)</span> (since that’s what we’re aiming for).</li>
<li>This is logarithmic in <span class="math inline">\(n\)</span>. So if <span class="math inline">\(x\)</span> has super-many coordinates, a sparse solution is good enough! We can prove this existentially—that there exists a <span class="math inline">\(O(\rh^2\ln n/\ep^2)\)</span> sparse solution—existentially using sampling from <span class="math inline">\(x^*\)</span> and using Chernoff.</li>
</ol>
<p>This naturally generalizes!</p>
<h3 id="game-theory">Game theory</h3>
We want to solve a zero-sum game approximately: find <span class="math inline">\(\wt q\)</span> (column mixed strategy) and <span class="math inline">\(\wt p\)</span> (row mixed strategy) such that
<span class="math display">\[\begin{align}
\la^* - \ep &amp; \le \min_i e_i^TA\wt q\\
\la^* &amp;= \max_j \wt p A e_j \le \la^* + \ep
\end{align}\]</span>
<p>where <span class="math display">\[
\la^* = \min_p \max_j A(p,j) = \max_q \min_i A(i,q).
\]</span> Note <span class="math inline">\(\ge\)</span> is clear.</p>
<p>Result: Assume all entries of <span class="math inline">\(A\)</span> bounded in absolute value by 1. We can approximate <span class="math inline">\(\la^*\)</span> up to <span class="math inline">\(\ep\)</span> with <span class="math inline">\(O\pf{\ln n}{\ep^2}\)</span> calls to oracle and time <span class="math inline">\(O(n)\)</span> per call.</p>
<p><em>Proof</em>. T use the algorithm, we specify:</p>
<ol type="1">
<li>Experts: row coordinates. (We take row’s POV.)</li>
<li>Losses: column responds with best response <span class="math inline">\(j\)</span> at each step. The loss for <span class="math inline">\(i\)</span> is <span class="math inline">\((Ae_j)_i\)</span>.</li>
</ol>
For all distributions <span class="math inline">\(p\)</span>,
<span class="math display">\[\begin{align}
\sumo tT p^{(t)} Ae_j
&amp;\le\sumo tT p^* A e_{j(t)} + \eta \sumo tT p^* Ae_{j(t)}+ \fc{\ln n}{\eta}\\
&amp;\le \la^* + \eta\ve{A}_{\iy} + \fc{\ln n}{\eta}\\
&amp; \le \la^* T + \ub{2\sqrt{T\ln n}}{\ep}
\end{align}\]</span>
<p>with <span class="math inline">\(\eta = \sfc{\ln n}T\)</span>. Thus can take <span class="math inline">\(T=\ce{\fc{4\ln n}{\ep^2}}\)</span>.</p>
<p>Notes:</p>
<ol type="1">
<li>Suppose we didn’t know the minimax theorem. Then <span class="math inline">\(\la^*\)</span> should be defined as <span class="math inline">\(\min\max\)</span>. This goes through.</li>
<li>Does this give a strategy for the column player? We can let <span class="math inline">\(\wt q = \fc{\set{t}{j(t)=j}}{T}\)</span>. Then we get <span class="math display">\[
\ol p A \wt q \le p A \wt q + \ep.
\]</span> Note we can set <span class="math inline">\(p\)</span> to anything; we don’t need to choose <span class="math inline">\(p^*\)</span>. We have <span class="math display">\[
\la^{*} - \ep \le \ol p A\wt q \le p A \wt q
\]</span> the LHS because <span class="math inline">\(j(t)\)</span> is the best response. Thus we not only found a good <span class="math inline">\(\wt p\)</span>, we also found <span class="math inline">\(\wt q\)</span> which attains <span class="math inline">\(\ge \la^*-\ep\)</span> for any <span class="math inline">\(p\)</span>.</li>
<li>Alas, this does not prove the minimax theorem because the <span class="math inline">\(\ge\)</span> part is clear.</li>
</ol>
<h3 id="boosting">Boosting</h3>
<p>Again specify</p>
<ol type="1">
<li>Experts: experts are now the data points.</li>
<li>Loss: reward the experts (data points) for fooling the algorithm.</li>
</ol>
<p>The role of “algorithm” and “data point” is swapped from the initial interpretation of multiplicative weights as operating on “experts = algorithms” shown “data points = incur losses from mistaks”, and the sign is flipped: we get rewards for fooling the algorithm.</p>
<p>(The “linear classifier with margin” still had “data points” being shown. The data points there were also adversarial in order to get improvement. We were rewarding coordinates for doing well.)</p>
<p>MAKE A TABLE.</p>
<p>If there are <span class="math inline">\(\rc 2+\ga\)</span>-weak learners, then there is a <span class="math inline">\(1-\ep\)</span>-strong learner with <span class="math inline">\(T=\ce{\fc{2}{\ga^2}\ln \prc{\ep}}\)</span>. (To be more precise, talk about weak-learners on somewhat dense distributions…)</p>
<p><em>Proof</em>. Let <span class="math inline">\(m_x=1-|h(x)-c(x)|\)</span>: a data point is penalized for being correctly classified. WL means that at each step we force many mistakes, <span class="math inline">\(\rc2+\ga\)</span> proportion at each time step.</p>
<p>Now comes the tricky part. We want to bound the number of steps until the mistakes (wrt original, uniform distribution) is small. Thus, we want: when we can find a large set <span class="math inline">\(E\)</span> on which the algorithm misclassifies, then this forces <span class="math inline">\(T\)</span> to be small. Using the refined inequality with KL divergence and <span class="math inline">\(p\)</span> the uniform distribution on <span class="math inline">\(E\)</span>, (“counting in 2 ways”, noting that each row of <span class="math inline">\(x\in E\)</span> sums to at most <span class="math inline">\(\fc T2\)</span>) <span class="math display">\[
\pa{\rc 2 + \ga}T \le (1+\eta)\fc{T}{2} + \fc{\ln \pf{n}{|E|}}{\eta}.
\]</span> Note that it’s key that we get a ratio <span class="math inline">\(\fc{n}{|E|}\)</span>. We have <span class="math inline">\(\fc{|E|}{n}\le \ep\)</span>. We get <span class="math inline">\(T&lt; \fc{2}{\ga^2} \ln \prc{\ep}\)</span>, so for larger <span class="math inline">\(T\)</span>, we can’t find such a <span class="math inline">\(E\)</span>. The “majority vote” comes from <span class="math inline">\(\fc T2\)</span>.</p>
<p>(You can also probably penalize differently depending on how the weak learner does, getting different weights, and probably improved bounds depending on performance of weak learners.)</p>
<h2 id="bayesian-interpretation">Bayesian interpretation</h2>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Adversarial examples in neural networks</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/neural_nets/adversarial.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/neural_nets/adversarial.html</id>
    <published>2017-02-21T00:00:00Z</published>
    <updated>2017-02-21T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Adversarial examples in neural networks</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-21 
          , Modified: 2017-02-21 
	</p>
      
       <p>Tags: <a href="/tags/neural%20nets.html">neural nets</a>, <a href="/tags/uncertainty.html">uncertainty</a>, <a href="/tags/aaml.html">aaml</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#introduction">Introduction</a><ul>
 <li><a href="#statement">Statement</a></li>
 <li><a href="#literature">Literature</a></li>
 <li><a href="#experiments">Experiments</a></li>
 <li><a href="#theory">Theory</a></li>
 </ul></li>
 <li><a href="#lcls17-delving-into-transferable-adversarial-examples">[LCLS17] Delving into Transferable Adversarial Examples</a><ul>
 <li><a href="#experiments-1">Experiments</a></li>
 <li><a href="#ensemble-based-approaches">Ensemble-based approaches</a></li>
 <li><a href="#geometry">Geometry</a></li>
 </ul></li>
 <li><a href="#questions">Questions</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="introduction">Introduction</h2>
<h3 id="statement">Statement</h3>
<p>Neural networks can be easily fooled—ex. an adversary adding a small amount of noise can change the classification from “dog” to “cat” with high confidence. It can be fooled even by a weak adversary with just black-box access!</p>
<p>Related to making NN’s resistant: Have NN’s give a confidence bound.</p>
<p>Ideas:</p>
<ul>
<li>Use uncertainty quantification from statistics: Fisher information. See personal communication with Jacob.</li>
<li>Use an ensemble of neural nets. Train an ensemble in parallel, vs. train together against a discriminator.</li>
<li>Sleeping in NN</li>
<li>Use some kind of calibration. I have a suspicion that cross-entropy simply doesn’t generalize because losses are unbounded.</li>
<li>Active learning</li>
<li>Make Lipschitz/other regularization. Give noisy example with the kind of noise you want to be resistant against.</li>
<li>Boosting</li>
</ul>
<h3 id="literature">Literature</h3>
<ul>
<li>[SZSB14] Intriguing properties of neural networks <a href="https://arxiv.org/pdf/1312.6199.pdf?not-changed">paper</a></li>
<li>Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014.</li>
<li></li>
<li></li>
<li>[LCLS17] Delving into Transferable Adversarial Examples and Black-box Attacks</li>
</ul>
<h3 id="experiments">Experiments</h3>
<ul>
<li>Reproduce adversarial examples result on a simple dataset, e.g. MNIST.</li>
<li>Try training an ensemble of NN in parallel and compare to predictions of a single one.</li>
</ul>
<h3 id="theory">Theory</h3>
<ul>
<li>Think in terms of learning theory, VC dimension…</li>
</ul>
<h2 id="lcls17-delving-into-transferable-adversarial-examples">[LCLS17] Delving into Transferable Adversarial Examples</h2>
<ol type="1">
<li>Model, training data, training process, test label set unknown to attacker.</li>
<li>Large dataset (ImageNet)</li>
<li>Do not construct substitute model</li>
</ol>
<p>What is the difference between targeted and non-targeted transferability?</p>
<ol type="1">
<li>Non-targeted: <span class="math inline">\(x^*\approx x\)</span>, <span class="math inline">\(f_\te(x^*)\ne f_\te(x) = y\)</span>. (Constrain <span class="math inline">\(d(x,x^*)\le B\)</span>.)</li>
<li>Targeted: <span class="math inline">\(x^*\approx x\)</span>, <span class="math inline">\(f_\te(x^*)=y^*\)</span>.</li>
</ol>
<p>3 approaches: Suppose <span class="math inline">\(f = \max_i J_\te(x)_i\)</span>, where <span class="math inline">\(J_\te(x)\)</span> is vector of probabilities.</p>
<ol type="1">
<li>Optimization <span class="math inline">\(\amin_{x^*} \la d(x,x^*) - \ell(\one_y, J_\te(x^*))\)</span>. Ex. <span class="math inline">\(\ell(u,v) = \ln (1-u\cdot v)\)</span>.</li>
<li>Fast gradient <span class="math inline">\(x^* \leftarrow \text{clamp}(x+B\sign (\nb_x \ell(\one_y, J_\te(x))))\)</span>.</li>
<li>Fast gradient sign <span class="math inline">\(x^* \leftarrow \text{clamp}\pa{x+B\nv{\nb_x\ell(\one_y, J_\te(x))}}\)</span>.</li>
</ol>
<p>Approaches for targeted: Replace constraint with <span class="math inline">\(f_\te(x^*)=y^*\)</span></p>
<ol type="1">
<li>Optimization <span class="math inline">\(\amin_{x^*} \la d(x,x^*) \redd{+} \redd{\ell'(\one_{y^*}}, J_\te(x^*))\)</span>. Ex. <span class="math inline">\(\ell'(u,v) = \redd{-\sum_i u_i \lg v_i}\)</span>.</li>
<li>Fast gradient <span class="math inline">\(x^* \leftarrow \text{clamp}(x\redd{-}B\sign (\nb_x \redd{\ell'(\one_{y^*}}, J_\te(x))))\)</span>.</li>
<li>Fast gradient sign <span class="math inline">\(x^* \leftarrow \text{clamp}\pa{x\redd{-}B\nv{\nb_x\redd{\ell'(\one_y}, J_\te(x))}}\)</span>.</li>
</ol>
<h3 id="experiments-1">Experiments</h3>
<p>Choose 100 images (ILSVRC2012 dataset) which can be correctly classified by all 5 models.</p>
<p>Non-target transferability: accuracy = percentage of adversarial examples for one model correctly classified for the other. (For NN to be good, want this to be high)</p>
<p>Targeted transferability: matching rate = percentage of adversarial examples classified as target label by other model. (Want this to be low)</p>
<p>Root mean square deviation <span class="math inline">\(d(x^*,x) = \sfc{\sum_i (x_i^*-x_i^2)}{N}\)</span>.</p>
<p>Q: isn’t the optimizer using gradient information? (We can estimate it by sampling though!)</p>
<p>Use small learning rate to generate images with RMSD&lt;2. Actually can set <span class="math inline">\(\la=0\)</span>.</p>
<p>(Accuracy is low. But what is the confidence?)</p>
<ul>
<li>Optimization can mislead the models.</li>
<li>FG cannot fully mislead the models. A potential reason is that, FG can be viewed as approximating the optimization, but is tailored for speed over accuracy.</li>
</ul>
<p>Find the minimal transferable RMSD by linear search.</p>
<p>Note FGS minimizes distortion’s <span class="math inline">\(L_\iy\)</span> norm while FG minimizes <span class="math inline">\(L_2\)</span> norm.</p>
<p>Target labels do not transfer. Fast gradient-based approaches don’t do well because they only search in 1-D subspace.</p>
<h3 id="ensemble-based-approaches">Ensemble-based approaches</h3>
<p>These do better! If an adversarial image remains adversarial for multiple models, it is more likely to transfer to other models. <span class="math display">\[
\amin_{x^*} -\ln \pa{\pa{\sumo ik \al_i J_i(x^*)}\cdot \one_{y^*}} + \la d(x,x^*)
\]</span> For each of the five models, we treat it as the black-box model to attack, and generate adversarial images for the ensemble of the rest four, which is considered as white-box. This attack does well!</p>
<p>Non-targeted adversarial images have almost perfect transferability!</p>
<p>Fast gradient doesn’t work with ensemble.</p>
<h3 id="geometry">Geometry</h3>
<ul>
<li>The gradient directions of different models in our evaluation are almost orthogonal to each other. - this makes sense</li>
<li>Choose 2 orthogonal directions, one being a gradient direction. There are up to 21 different regions
<ul>
<li>Boundaries align well.</li>
<li>Boundary diameter along gradient direction smaller. (Even in the direction of increasing the prediction probability!)</li>
</ul></li>
</ul>
<h2 id="questions">Questions</h2>
<ul>
<li>Can you use adversarial examples to improve training?</li>
<li>What if you try denoising first?</li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Weekly summary 2017-02-25</title>
    <link href="http://holdenlee.github.io/notebook/posts/summaries/2017-02-25.html" />
    <id>http://holdenlee.github.io/notebook/posts/summaries/2017-02-25.html</id>
    <published>2017-02-21T00:00:00Z</published>
    <updated>2017-02-21T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Weekly summary 2017-02-25</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-21 
          , Modified: 2017-02-21 
	</p>
      
       <p>Tags: <a href="/tags/neural%20nets.html">neural nets</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#adversarial-examples-in-neural-networks">Adversarial examples in neural networks</a><ul>
 <li><a href="#statement">Statement</a></li>
 <li><a href="#literature">Literature</a></li>
 <li><a href="#experiments">Experiments</a></li>
 <li><a href="#theory">Theory</a></li>
 </ul></li>
 <li><a href="#diversity-in-ml">Diversity in ML</a><ul>
 <li><a href="#literature-1">Literature</a></li>
 </ul></li>
 <li><a href="#gans">GANs</a></li>
 <li><a href="#decision-theory-and-logical-induction">Decision theory and logical induction</a></li>
 <li><a href="#pomdp">POMDP</a></li>
 <li><a href="#alexa">Alexa</a></li>
 <li><a href="#logic-and-ml">Logic and ML</a></li>
 <li><a href="#meta">Meta</a></li>
 <li><a href="#blogging">Blogging</a></li>
 <li><a href="#learning">Learning</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="adversarial-examples-in-neural-networks">Adversarial examples in neural networks</h2>
<p><a href="/posts/tcs/machine_learning/neural_nets/adversarial.html">main page</a></p>
<h3 id="statement">Statement</h3>
<p>Neural networks can be easily fooled—ex. an adversary adding a small amount of noise can change the classification from “dog” to “cat” with high confidence. It can be fooled even by a weak adversary with just black-box access!</p>
<p>Related to making NN’s resistant: Have NN’s give a confidence bound.</p>
<p>Ideas:</p>
<ul>
<li>Use uncertainty quantification from statistics: Fisher information. See personal communication with Jacob.</li>
<li>Use an ensemble of neural nets. Train an ensemble in parallel, vs. train together against a discriminator.</li>
<li>Sleeping in NN</li>
<li>Use some kind of calibration</li>
<li>Active learning</li>
<li>Make Lipschitz/other regularization.</li>
<li>Boosting</li>
</ul>
<h3 id="literature">Literature</h3>
<ul>
<li>[SZSB14] Intriguing properties of neural networks <a href="https://arxiv.org/pdf/1312.6199.pdf?not-changed">paper</a></li>
<li>Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014.</li>
<li>Papernot 2016</li>
<li>[LCLS17] Delving into Transferable Adversarial Examples and Black-box Attacks</li>
</ul>
<h3 id="experiments">Experiments</h3>
<ul>
<li>Reproduce adversarial examples result on a simple dataset, e.g. MNIST.</li>
<li>Try training an ensemble of NN in parallel and compare to predictions of a single one.</li>
</ul>
<h3 id="theory">Theory</h3>
<ul>
<li>Think in terms of learning theory, VC dimension…</li>
</ul>
<h2 id="diversity-in-ml">Diversity in ML</h2>
<h3 id="literature-1">Literature</h3>
<ul>
<li>Putting Bayes to Sleep</li>
<li>[KPRV17] Overcoming catastrophic forgetting in neural networks</li>
</ul>
<h2 id="gans">GANs</h2>
<p>The original formulation of GANs is plagued by many mathematical problems. What are mathematically better alternatives?</p>
<ul>
<li>Wasserstein GAN</li>
<li>Neural net GAN</li>
</ul>
<h2 id="decision-theory-and-logical-induction">Decision theory and logical induction</h2>
<p>See page on decision/game theory.</p>
<ul>
<li>UDT</li>
<li>Reflective oracles</li>
<li>Background on logic and provability</li>
<li>Logical induction: the daemon (rocket) problem &lt;&gt; sleeping?</li>
</ul>
<h2 id="pomdp">POMDP</h2>
<p>Anchor POMDPs.</p>
<p>What are real-life problems involving POMDPs?</p>
<h2 id="alexa">Alexa</h2>
<ul>
<li>Entity extraction and feeding into knowledge graphs
<ul>
<li>Structured knowledge graphs?</li>
</ul></li>
<li>Recognize simple queries in a reflective manner - maybe building on AIML</li>
<li>Formalize modes of conversation</li>
<li>Look at semantic parsing literature</li>
<li>What kind of experiments could I run?</li>
<li>Look for examples of conversations on popular topics. Try to engage in them.</li>
<li>Do a web search with heuristics.</li>
</ul>
<h2 id="logic-and-ml">Logic and ML</h2>
<p>???</p>
<h2 id="meta">Meta</h2>
<p>What is good research?</p>
<h2 id="blogging">Blogging</h2>
<ul>
<li>Diversity series
<ul>
<li>Trees</li>
<li>Diversity in ML</li>
</ul></li>
<li>Boosting, etc.</li>
<li>Logical induction</li>
</ul>
<h2 id="learning">Learning</h2>
<ul>
<li>Boosting, etc.</li>
<li>RL</li>
<li>TF in Haskell!</li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Questions</title>
    <link href="http://holdenlee.github.io/notebook/posts/math/logic/questions.html" />
    <id>http://holdenlee.github.io/notebook/posts/math/logic/questions.html</id>
    <published>2017-02-19T00:00:00Z</published>
    <updated>2017-02-19T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Questions</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-19 
          , Modified: 2017-02-19 
	</p>
      
       <p>Tags: <a href="/tags/logic.html">logic</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"></div>

  <div class="blog-main">
    <p>Things I’m confused about.</p>
<ul>
<li>I’m uncomfortable with theorems in the meta-logic. How do you define the meta-logic without infinite recursion (meta-meta, etc.)? Godel incompleteness, etc. are NOT theorems in the logic, but the meta-logic—if you want them as theorems in the logic then you have to define the logic inside the logic—there’s no reflection, right? Because that would be <span class="math inline">\(\square A to A\)</span>.</li>
<li>What did I mean by reflection?</li>
<li>Nesting is unsatisfactory…</li>
<li>Is <span class="math inline">\(PA\vdash A\implies PA\vdash B \iff PA\vdash \square A \to \square B\)</span> a theorem in the meta-logic?</li>
<li>Is <span class="math inline">\(PA\vdash \square A\implies PA\vdash A\)</span> a theorem in the meta-logic? An axiom?</li>
<li>How do you define “truth” in the meta-logic?</li>
<li>Is <span class="math inline">\(\square \square A \to \square A\)</span> a theorem?</li>
<li>Is <span class="math inline">\(PA\vdash \square A \to \square B, PA\vdash A \implies PA\vdash B\)</span>? How about <span class="math inline">\(PA\vdash \square (\square A \to \square B)\wedge \square A \to \square B\)</span>?</li>
<li>Can you add quantifiers? Is it true that <span class="math inline">\(\forall x, \square P(x) \imples \square \forall x, P(x)\)</span>? My guess is not (at least, it can’t be proved). Should <span class="math inline">\(\square\)</span> be Bew here? I think you’re not allowed to use <span class="math inline">\(\square\)</span> here, but that’s ok, you can state it with Bew. <span class="math inline">\(\square\)</span> is interpreted as <span class="math inline">\(Bew(\ce{})\)</span> in PA, right?</li>
<li>Is <span class="math inline">\((\square A \to \square B) \to \square (A\to B)\)</span> a theorem?</li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>UDT</title>
    <link href="http://holdenlee.github.io/notebook/posts/cs/ai/control/udt.html" />
    <id>http://holdenlee.github.io/notebook/posts/cs/ai/control/udt.html</id>
    <published>2017-02-19T00:00:00Z</published>
    <updated>2017-02-19T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>UDT</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-19 
          , Modified: 2017-02-19 
	</p>
      
       <p>Tags: <a href="/tags/ai%20safety.html">ai safety</a>, <a href="/tags/game%20theory.html">game theory</a>, <a href="/tags/decision%20theory.html">decision theory</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"></div>

  <div class="blog-main">
    <p>Main notes <a href="game_theory.html">here</a>.</p>
<ul>
<li>It seems we don’t need to quine - we can just view A, U as functions of each other’s source codes. Just impose some halting criterion. Then just evaluate <span class="math inline">\(U(\ce{A})\)</span>… Oh, but how does U give A its own code?
<ul>
<li>External program runs them? I don’t like this.</li>
<li>I don’t like co-quining them because then I feel I lose the algorithmic interpretability - now I don’t feel like they’re programs anymore. For some reason I’m having trouble thinking about quines in terms of programs, I can think about them in terms of logic statements.</li>
<li>I think the programs should handle the quining themselves. Ah. If U doesn’t quine itself, it has no way of running A with its own source code. So U is a quine in the sense that it can give A its own source code. This solves things. Otherwise, U would not be able to run A. A also has incentive to quine itself, otherwise it cannot simulate U on A, or prove statements about itself.</li>
<li>Can a non-quined program be taken advantage of?</li>
<li>Wait, but writing the code I didn’t do any quining!</li>
<li>Oh, you can just assume U, A can run themselves. You assume they’re quined for convenience in reasoning about them, but you don’t actually need them to be quined themselves.</li>
<li>Quining is just the way in logic to get access to own source code - in programming you don’t need to do it explicitly because the source code is in the file.</li>
<li>Do you need to quine for corecursion?</li>
<li>I don’t think any of this is important–they’re all basically taken care of by the programming language.</li>
<li>! You can’t separate what the agent does from who it is: ex. why you can’t just feed all possible functions into something else, then let yourself be the best function. The other agent would act differently against that function vs. against you. Ex. playing against PrudentBot, PrudentBot defects against both <code>const c</code> and <code>const d</code>, if these are the only things you’re trying, you’ll just defect!</li>
<li>For U/A say the agent has fixed runtime, the universe has finite runtime (alternatively it can rely on the truth of logical statements). For A/A say both have fixed (large) runtime.</li>
</ul></li>
<li>What if we want U to have access to some oracle? How can we ensure that we can actually prove the output of U? Can this be made equivalent to the condition that U halts?</li>
<li>Is there a way to implement these agents without having them search for proofs? Ex. do “lazy evaluation?” I don’t see a way to do this.</li>
<li>If <code>fairBot x = (if x coopBot == c then c else d)</code> then</li>
<li>I want to say something like, there’s a sequence Bot1, Bot2,… with longer lookbacks, and Bot-k outperforms Bot-(k-1) by “pretending” to be something that Bot-(k-1) will cooperate with and then stabbing it in the back… this seems to be going the other way.</li>
<li>Why do we keep talking about “embedded” agents?</li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>The Blessing and the Curse of the Multiplicative Updates</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/optimization/multiplicative_update.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/optimization/multiplicative_update.html</id>
    <published>2017-02-12T00:00:00Z</published>
    <updated>2017-02-12T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>The Blessing and the Curse of the Multiplicative Updates</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-12 
          , Modified: 2017-02-12 
	</p>
      
       <p>Tags: <a href="/tags/multiplicative%20update.html">multiplicative update</a>, <a href="/tags/online%20learning.html">online learning</a>, <a href="/tags/biology.html">biology</a>, <a href="/tags/evolution.html">evolution</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#dispelling-the-curse">Dispelling the curse</a></li>
 <li><a href="#summary">Summary</a></li>
 </ul> </div>

  <div class="blog-main">
    <p>(Chapter by Manfred Warmuth)</p>
<p>Setting: online learning</p>
<p>Maintain weights where <span class="math inline">\(w_i\)</span> is the belief that the <span class="math inline">\(i\)</span>th expert is best. Prediction: weighted average.</p>
<p>Multiplicative updates motivated by minimum relative entropy principle. Simplest is Bayes’s rule for updating priors.</p>
<blockquote>
<p>The “blessing” of these updates is that they learn very fast in the short term because the good weights grow exponentially. However, their “curse” is that they learn too fast and wipe out other weights too quickly. This loss of variety can have a negative effect in the long term because adaptivity is required when there is a change in the process generating the data stream.</p>
</blockquote>
<blockquote>
<p>Surprisingly, some of Nature’s methods parallel the ones developed in machine learning, but Nature also has some additional tricks.</p>
</blockquote>
<p>Evolution on 2 scales:</p>
<ul>
<li>Short-term: mutation and selection (multiplicative update)</li>
<li>Long-term: stability - requires mechanism for preventing quick convergence to currently fittest strategy or gene.</li>
</ul>
<p><span class="math display">\[
\wt s_i = \fc{s_ie^{-\eta \text{loss}_i}}{Z}
= \amin_{r\in \R^n, \sum_i r_i=1} \sum_i KL(r||s) + \eta\sum_i r_il_i
\]</span> Relative entropy keeps <span class="math inline">\(\wt s\)</span> close to <span class="math inline">\(s\)</span>. <span class="math inline">\(\eta\)</span> is tradeoff parameter. <span class="math inline">\(W_i = e^{-\eta l_i}\)</span> is the fitness of strategy <span class="math inline">\(i\)</span>. Bayes Rule: expected log loss, <span class="math inline">\(\eta=1\)</span>.</p>
<p>(systematic way of deriving such updates by trading off a relative entropy between the new and old weight vector with a loss function that measures how well the weights did on the current instance vector)</p>
<p>Why multiplicative, not additive update? Converge quickly when data stream generating process is static.</p>
<p>Problem: data changes over time. MU loss of variety.</p>
<p>Use of MU: separate good/bad RNA, reamplify good. Loop. Use PCR.</p>
<p>Assumption: <span class="math inline">\(W_i\)</span> independent of share vector <span class="math inline">\(s\)</span>. (Otherwise: apostatic effects.) <span class="math inline">\(\wt s_i = \fc{w_iW_i}{\an{s,W}}\)</span>.</p>
<p>In-vitro selection: iterate Bayes with same data likelihoods.</p>
<blockquote>
<p>“brittle” because the gradients of the losses appear in the exponents of the update factors. This is problematic when there is noise in the data and the data-generating process changes over time</p>
</blockquote>
<p>Compounded: weights have constant precision.</p>
<p>Curse is extinctino in nature.</p>
<h3 id="dispelling-the-curse">Dispelling the curse</h3>
<p>Ex. Bacteria in nutriet solution separate into 3 niches, 3 species. Mixing kills all but one.</p>
<blockquote>
<p>three species of bacteria that play an RPS game. When started on a Petri dish, colonies of each species develop that slowly chase each other around the dish: R invades S’s colonies, S invades P, and P invades R</p>
</blockquote>
<ol type="1">
<li>Niche boundaries help prevent the curse. (Human: multiplicative update of meme shares causes loss of variety.)
<ul>
<li>Key problem 1 (that cannot be solved by MU alone): There are three strands of RNA in a tube and the goal is to amplify the mixture while keeping the percentages of the strands unchanged. This is to be done without sequencing the strands and determining their concentrations.
<ul>
<li>Solution: Translate to (double stranded) DNA and using an enzyme, add a specific short “end strand” to both ends of all strands in the tube. These end strands function as connectors between strands and make it possible to randomly ligate many strands together into long strands. Now separate out one long strand. With the help of an enzyme, add “primer strands” to both ends of that long strand. Apply PCR iteratively starting with the long selected strand, always making complete copies of the same original long strand that is located between the primers. Stop when you have the target amount of DNA. Now divide the long strands into their constituents by cutting them at the specific end strand that functioned as the connector. Finally, remove all short primer and end strands and convert back to RNA.</li>
<li>The long strand functions as a “chromosome.” Free floating genes in the nuclei of cells would compete.</li>
</ul></li>
</ul></li>
<li>Coupling preserves diversity.
<ul>
<li>Genes on chromosome selected for together; genes “cooperate” for sake of efficient copying.</li>
<li>What updates can be implemented with in-vitro selection/blind computation? Can you have negative weights?</li>
<li><span class="math inline">\(EG^{\pm}\)</span> algorithm: maintain 2 weight vectors <span class="math inline">\(s^+,s^-\in \R^n\)</span>. Label <span class="math inline">\((s^+-s^-)\cdot x\)</span>, loss <span class="math inline">\(L((s^+-s^-)\cdot x,y) = ((s^+-s^-_)\cdot x-y)^2\)</span> so that fitness is inverse.</li>
<li>Problem 2: find small set of RNA strands that can bind to <span class="math inline">\(q\)</span> different protein sheets. (Assume that among all strands in a 1-liter tube of RNA, there is a particular set of two strands such that for each of q proteins, at least one of the two has a high fraction of attachment. Can you use PCR to get <span class="math inline">\(\approx (0.5, 0.5, 0,\ldots)\)</span>?)
<ul>
<li>First idea: cycle through <span class="math inline">\(q\)</span> proteins and do in-vitro selection.</li>
<li>Problem: overselecting can kill off one.</li>
<li>ML problem: <span class="math inline">\(\exists u\)</span> with <span class="math inline">\(k\)</span> nonzeros of value <span class="math inline">\(\rc k\)</span>, <span class="math inline">\(u\cdot W_j\ge \rc k\)</span>. Find <span class="math inline">\(s\)</span> with <span class="math inline">\(s\cdot W_j \ge \rc{2k}\)</span>.</li>
<li>Normalized winnow algorithm: If <span class="math inline">\(s\cdot W_j\ge \rc{2k}\)</span>, then <span class="math inline">\(\wt s=s\)</span> (conservative update), else apply MU.</li>
</ul></li>
<li>ML 1: Prevent over-training by making the update conservative.</li>
<li>in the context of in-vitro selection this means that RNA strands that attached to the protein sheet are simply recombined into the tube without the PCR amplification step.</li>
<li>the amplification step occurs at most <span class="math inline">\(O(k\log \fc Nk)\)</span> times if there is a consistent k-literal disjunction and this is information theoretically optimal. Grows logarithmically in <span class="math inline">\(n\)</span>.</li>
<li>If select for <span class="math inline">\(\binom nk\)</span> combinations, not necessary to be conservative. But this is too large.</li>
<li>Coupling can be replaced by thresholding.</li>
<li>Cap shares/weight from above.</li>
</ul></li>
<li>Super (apex) predator.
<ul>
<li>Nibbles at the highest bar of the histogram of possible prey species. (Removing it causes this species to take over.) The more frequent a species, the more opportunity for a disease to spread and this can keep a species from taking over.</li>
<li>ML2: Cap the weights from above for the purpose of learning a set of experts.</li>
<li>After MU: all weights that exceed c are reduced to c and the total weight gained is redistributed among the remaining components that lie below c so that their ratios are preserved and the total weight still sums to one. (cf. exploration, <span class="math inline">\(\ep\)</span>-greedy.)</li>
<li>capping solves a constrained optimization problem.</li>
<li>Ex. constrain to be in convex hull of <span class="math inline">\(k\)</span>-corners. This still only needs <span class="math inline">\(n\)</span> weights.</li>
<li>In matrix MU, share vectors are density matrices - prob vector of eigenvalues</li>
<li>quantum relative entropy instead of the regular relative entropy</li>
<li>MMU with capping on eigenvalues: PCA. <span class="math inline">\(k\)</span> experts become <span class="math inline">\(k\)</span>-dim subspace. Capped density matrices are convex combs of <span class="math inline">\(k\)</span>-dim subspaces.</li>
<li>relating: lower bound shares.</li>
<li>keep a batch of the initial mixture in reserve. When too uniform, add some!</li>
<li>Disk spindown problem.</li>
<li><span class="math inline">\(\wt s = (1-\al) s^m + \al \rc N\one\)</span>.</li>
</ul></li>
<li>Mutations keep a base variety.
<ul>
<li>Data shifts once in a while and some are a return back to data seen previously. Need:</li>
<li>Capability to bring up shares quickly.</li>
<li>Remember experts that did well in past. (Sleeping)</li>
<li>ML4: Sleeping realizes long-term memory.</li>
<li>Keep track of average share vector, mix in <span class="math inline">\(\al\)</span> of <span class="math inline">\(r\)</span>.</li>
<li>Markov network with 2 tracks (tubes).</li>
<li>It is reasonable to expect that Nature makes use of the sleeping mechanism as well. (Seed sprouting.)</li>
</ul></li>
</ol>
<p>How is sleeping realized at genetic level. Junk DNA, sex?</p>
<h2 id="summary">Summary</h2>
<p>Machine Learning mechanisms:</p>
<ol type="1">
<li>conservative update for learning multiple goals</li>
<li>upper bounding weights for learning multiple goals</li>
<li>lower bounding weights for robustness against change</li>
<li>sleeping for realizing a long-term memory.</li>
</ol>
<p>Nature’s mechanisms:</p>
<ol type="1">
<li>coupling for preserving variety</li>
<li>boundaries for preserving variety</li>
<li>super-predators for preserving variety</li>
<li>mutations for keeping a base variety.</li>
</ol>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Game theory and decision theory</title>
    <link href="http://holdenlee.github.io/notebook/posts/cs/ai/control/game_theory.html" />
    <id>http://holdenlee.github.io/notebook/posts/cs/ai/control/game_theory.html</id>
    <published>2017-02-12T00:00:00Z</published>
    <updated>2017-02-12T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Game theory and decision theory</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-12 
          , Modified: 2017-02-12 
	</p>
      
       <p>Tags: <a href="/tags/ai%20safety.html">ai safety</a>, <a href="/tags/game%20theory.html">game theory</a>, <a href="/tags/decision%20theory.html">decision theory</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#references">References</a><ul>
 <li><a href="#online">Online</a></li>
 <li><a href="#books">Books</a></li>
 </ul></li>
 <li><a href="#towards-idealized-decision-theory">Towards idealized decision theory</a><ul>
 <li><a href="#problems-with-edt-cdt">Problems with EDT, CDT</a><ul>
 <li><a href="#why-not-recursively-improve-from-edtcdt">Why not recursively improve from EDT/CDT?</a></li>
 </ul></li>
 <li><a href="#policy-selection">Policy selection</a></li>
 <li><a href="#logical-counterfactuals">Logical counterfactuals</a><ul>
 <li><a href="#graphical-udt.">Graphical UDT.</a></li>
 <li><a href="#proof-based-udt">Proof-based UDT</a></li>
 </ul></li>
 </ul></li>
 <li><a href="#lobs-theorem-in-miri-research">Lob’s Theorem in MIRI Research</a><ul>
 <li><a href="#lob">Lob</a></li>
 <li><a href="#applications">Applications</a><ul>
 <li><a href="#lobstacle">Lobstacle</a></li>
 <li><a href="#lobian-cooperation">Lobian cooperation</a></li>
 <li><a href="#spurious-counterfactuals">3.3 Spurious counterfactuals</a></li>
 </ul></li>
 <li><a href="#model-theory">Model theory</a></li>
 <li><a href="#godel-lob-modal-logic">Godel-Lob Modal Logic</a></li>
 <li><a href="#fixed-points-of-modal-statements">Fixed points of modal statements</a></li>
 <li><a href="#applications-of-gl-modal-logic">Applications of GL modal logic</a></li>
 </ul></li>
 <li><a href="#reflective-oracles-as-foundation">Reflective oracles as foundation</a></li>
 <li><a href="#reflective-oracles-and-solomonoff-induction">Reflective oracles and Solomonoff induction</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="references">References</h2>
<p>Papers on game theory/decision theory:</p>
<ul>
<li>Andrew Critch. 2017. “Toward Negotiable Reinforcement Learning: Shifting Priorities in Pareto Optimal Sequential Decision-Making.” <a href="https://arxiv.org/abs/1608.04112">arXiv:1701.01302</a> [cs.AI].</li>
<li>Andrew Critch. 2016. “Parametric Bounded Lob’s Theorem and Robust Cooperation of Bounded Agents.” <a href="http://arxiv.org/abs/1602.04184">arXiv:1602.04184</a> [cs:GT].</li>
<li>Jan Leike, Jessica Taylor, and Benya Fallenstein. 2016. “<a href="http://www.auai.org/uai2016/proceedings/papers/87.pdf">A Formal Solution to the Grain of Truth Problem</a>.” Paper presented at the 32nd Conference on Uncertainty in Artificial Intelligence.</li>
<li>Benja Fallenstein, Jessica Taylor, and Paul Christiano. 2015. “Reflective Oracles: A Foundation for Classical Game Theory.” <a href="http://arxiv.org/abs/1508.04145">arXiv:1508.04145</a> [cs.AI]. Previously published as MIRI technical report 2015-7. Published in abridged form as “Reflective Oracles: A Foundation for Game Theory in Artificial Intelligence” in Proceedings of LORI 2015.</li>
<li>Nate Soares and Benja Fallenstein. 2015. “Toward Idealized Decision Theory.” <a href="http://arxiv.org/abs/1507.01986">arXiv:1507.01986</a> [cs.AI]. Previously published as MIRI technical report 2014-7. Published in abridged form as “Two Attempts to Formalize Counterpossible Reasoning in Deterministic Settings” in Proceedings of AGI 2015.</li>
<li>Mih’aly B’asr’asz, Paul Christiano, Benja Fallenstein, Marcello Herreshoff, Patrick LaVictoire, and Eliezer Yudkowsky. 2014. “Robust Cooperation on the Prisoner’s Dilemma: Program Equilibrium via Provability Logic.” <a href="http://arxiv.org/abs/1401.5577">arXiv:1401.5577</a> [cs.GT].</li>
<li>Tsvi Benson-Tilsen. 2014. “UDT with Known Search Order.” <a href="https://intelligence.org/files/UDTSearchOrder.pdf">MIRI technical report 2014-4</a></li>
<li>Patrick LaVictoire, Benja Fallenstein, Eliezer Yudkowsky, Mih’aly B’ar’asz, Paul Christiano and Marcello Herreshoff. 2014. “<a href="https://intelligence.org/files/ProgramEquilibrium.pdf">Program Equilibrium in the Prisoner’s Dilemma via Lob’s Theorem</a>.” Paper presented at the AAAI 2014 Multiagent Interaction without Prior Coordination Workshop.</li>
<li>Benja Fallenstein. 2013. “<a href="https://intelligence.org/files/TilingAgents510.pdf">The 5-and-10 Problem and the Tiling Agents Formalism.</a>” MIRI technical report 2013-9.</li>
<li><a href="https://intelligence.org/wp-content/uploads/2014/10/Hintze-Problem-Class-Dominance-In-Predictive-Dilemmas.pdf">Problem class dominance</a></li>
</ul>
<h3 id="online">Online</h3>
<ul>
<li>ADT</li>
<li><a href="https://agentfoundations.org/item?id=1279">Entangled Equilibria and the Twin Prisoners’ Dilemma</a></li>
<li><a href="http://lesswrong.com/lw/15m/towards_a_new_decision_theory/">UDT</a>
<ul>
<li><a href="https://dl.dropboxusercontent.com/u/34639481/Updateless_Decision_Theory.pdf">Formalization</a></li>
</ul></li>
<li><a href="https://intelligence.org/research-guide/#four">MIRI research guide</a></li>
<li><a href="http://lesswrong.com/lw/gu1/decision_theory_faq/">Decision theory FAQ</a></li>
<li><a href="http://lesswrong.com/lw/dbe/introduction_to_game_theory_sequence_guide/">Game thepory sequence</a></li>
<li><a href="http://lesswrong.com/lw/eaa/a_model_of_udt_with_a_concrete_prior_over_logical/">UDT with concrete prior over logical statements</a></li>
<li><a href="http://lesswrong.com/lw/b5t/an_example_of_selffulfilling_spurious_proofs_in/">Self-fulfilling spurious proofs</a></li>
<li><a href="https://agentfoundations.org/item?id=160">Forum digest</a></li>
<li><a href="https://agentfoundations.org/item?id=117">UDT in the land of probabilistic oracles</a></li>
<li><a href="https://agentfoundations.org/item?id=4">Using modal fixed points to formalize logical causality</a> <a href="http://scrible.com/s/2DR66">h</a></li>
<li><a href="https://agentfoundations.org/item?id=47">Evil decision problems</a> <a href="http://scrible.com/s/2LB66">h</a></li>
<li><a href="https://agentfoundations.org/item?id=1281">Are daemons a problem for ideal agents?</a> (a.k.a. the rocket problem)</li>
</ul>
<h3 id="books">Books</h3>
<ul>
<li>Game theory, Steven Tadelis</li>
<li>Algorithmic game theory, Tim Roughgarden <a href="http://theory.stanford.edu/~tim/books.html">page</a></li>
<li>Computability and Logic by Boolos, Burgess, and Jeffrey</li>
</ul>
<h2 id="towards-idealized-decision-theory">Towards idealized decision theory</h2>
<p>But what are the available actions? And what are the counterfactual universes correspond- ing to what “would happen” if an action “were taken”?</p>
<p>(A deterministic agent could only have taken one action.)</p>
<p>To fully describe the problem faced by intelligent agents making decisions, it is necessary to provide an idealized procedure which takes a description of an environment and one of the agents within, and identifies the best action available to that agent</p>
<h3 id="problems-with-edt-cdt">Problems with EDT, CDT</h3>
<p>Evidential blackmail: AI researcher knows whether the AI will lose $150 mil from an investment (scandal). If either is true, the AI researcher sends the info and asks for $100 mil:</p>
<ul>
<li>No scandal, will pay</li>
<li>Scandal, won’t pay</li>
</ul>
<p>Conditioned on refusing, loses $150 mil.</p>
<p>Counterfactual blackmail: Developer has developed computer virus which would cause both to lose $150 mil. Once deployed, only way to prevent activation 1 day later is to wire $100 mil. Researcher would only deploy if quite sure agent will pay.</p>
<h4 id="why-not-recursively-improve-from-edtcdt">Why not recursively improve from EDT/CDT?</h4>
<p>CDT prescribes that an agent resist certain attempts to improve its decision procedures.</p>
<p>Retro blackmail: AI researcher has access to original source code. Can self-modify after researcher acquires original source code but before researcher decides whether to deploy.</p>
<p>Self-modify to not give in to demands.</p>
<p>But CDT and any decision procedure to which CDT would self-modify would lose money.</p>
<h3 id="policy-selection">Policy selection</h3>
<p>CDT: Alas, the virus has been deployed. I would have preferred that the virus not be deployed, but since it has been, I must now decide whether or not to pay up. Paying up is bad, but refusing is worse, so I’ll pay up.</p>
<p>Policy selection: The optimal policy is to refuse to pay up upon observing that the virus has been deployed. I now observe that the virus has been deployed. Therefore, I refuse to pay.</p>
<h3 id="logical-counterfactuals">Logical counterfactuals</h3>
<p>Consider Prisoner’s dilemma when</p>
<ul>
<li>opponent’s action guaranteed to match your own. (dependent)</li>
<li>some probability <span class="math inline">\(p\)</span> opponent defects. (independent)</li>
</ul>
<p>However, CDT evaluates actions according to a physical counterfactual where the action is changed but everything causally separated from the action is held constant. It is not the physical output of the agent’s hardware which must be modified to construct a counterfactual, it is the logical output of the agent’s decision algorithm.</p>
<p>Cf. <span class="math inline">\(10 \E a - a\)</span>.</p>
<p>UDT chooses the best action according to a world-model which represents not only causal relationships in the world, but also the logical effects of algorithms upon the world.</p>
<h4 id="graphical-udt.">Graphical UDT.</h4>
<p>How to encode logical relations in graph? Underspecified: constructing graph is difficult. Graph for UDT further requires some ability to identify and separate “algorithms” from the physical processes that implement them. How is UDT supposed to recognize that the agent and its opponent implement the same algorithm?</p>
<p>To illustrate, consider UDT identify- ing the best action available to an agent playing a Pris- oner’s Dilemma against an opponent that does exactly the same thing as the agent 80% of the time, and takes the opposite action otherwise.</p>
<p>(Problem seems to be identifying what something is doing logically - it might be obfuscated. Also, graph loses info from algorithm.)</p>
<h4 id="proof-based-udt">Proof-based UDT</h4>
<p>Evaluate logical implications of the agent’s algorithm selecting the policy <span class="math inline">\(\pi\)</span>.</p>
<p>Graph is unnecessary: the environment itself is an algorithm.</p>
<p>evaluates policies by searching for formal proofs, using some mathematical theory such as Peano Arithmetic (PA), of how much utility is attained in the world-model if A() selects the policy <span class="math inline">\(\pi\)</span>.</p>
<p>But: requires halting oracle. can only identify the best policy if there exists a proof that ex- ecuting that policy leads to a good outcome</p>
<p>Problem in stochastic environments (? if can model prior, seems ok)</p>
<p>Ex. agent uses UDT, play game with human. If numbers written sum to <span class="math inline">\(\$10\)</span>, each paid, else 0.</p>
<p>UDT misidentifies best policy:</p>
<p>Human: I don’t quite know how UDT works, but I remember hearing that it’s a very powerful predictor. So if I decide to write down 9, then it will predict this, and it will decide to write 1. Therefore, I can write down 9 without fear.</p>
<p>But agent with superior predictive power loses to the dumber agent! Human’s lack of power to predict UDT gives an advantage!</p>
<p>Problem: not guaranteed to work. As soon as proof-based UDT proves that an agent will not take a certain policy, it concludes that taking that policy leads to the best possible outcome (because from a contradiction, anything follows).</p>
<p>(I don’t get this…) <span class="math display">\[
A() = UDT(\ce{E()}, \ce{A()}).
\]</span></p>
<p>(What is an embedding of an agent?)</p>
<h2 id="lobs-theorem-in-miri-research">Lob’s Theorem in MIRI Research</h2>
<p>Why Lob? The short answer is that this theorem illustrates the basickind of self-reference involved when an algorithm considers its own output as part of theuniverse, and it is thus germane to many kinds of research involving self-modifying agents,especially when formal verification is involved or when we want to cleanly prove things inmodel problems.</p>
<p>Problem: How can Deep Thought 1.0 build Deep Thought 2.0 with guarantee of good consequences?</p>
<p>DT1 can’t actually figure out what actions DT2 is going to take. Naively, it seems as if it should be enough for DT1 toknow that DT2 has the same goals as DT1, that DT2’s deductions are reliable, and that DT2 only takes actions that it deduces to have good consequences on balance.</p>
<p>If we tryand model DT1 and DT2 as proving statements in two formal systems (one stronger thanthe other), then the only way that DT1 can make such a statement about DT2’s reliability is if DT1 (and thus both) are in fact unreliable!</p>
<h3 id="lob">Lob</h3>
<p>One (anachronistic) way of stating Godel’s key insight is that you can use computer pro-grams to search for proofs, and you can prove statements about computer programs</p>
<p>This makes it more intuitive that we can embed self-reference in mathematics, because we can embed self-reference in computer code!</p>
<p>Quines: programs can be made which perform arbitrary tasks using their own source code we can have a program G which refers to itself in this way, and searches for proofs inarithmetic related to its own source code.</p>
<p>G searches for a proof of “G runs forever”. G never finds a proof, but we can never prove that G runs forever.</p>
<p>We can add “G never halts” or “G halts” as a new axiom.</p>
<p><strong>First incompleteness</strong>. If the theory of arithmetic is consistent, then there exist undecidable statements in the theory of arithmetic.</p>
<p>Lob’s Theorem:</p>
<ul>
<li><span class="math inline">\(X\)</span> logical statement</li>
<li>ProofSeeker(X) searches for proofs of <span class="math inline">\(X\)</span>.</li>
<li><span class="math inline">\(L(X)=\)</span>“if ProofSeeker(X) halts, then X”</li>
</ul>
<p>Intuition: if <span class="math inline">\(L(X)\)</span> were provable for every <span class="math inline">\(X\)</span>, you can prove consistency.</p>
<ol type="1">
<li>If <span class="math inline">\(X\)</span> is provable, ProofSeeker(X) halts, and <span class="math inline">\(L(X)\)</span> is true.</li>
<li>If <span class="math inline">\(X\)</span> is disprovable, then ProofSeeker(X) does not halt, but you can’t prove it—because that would be like proving consistency! (cf. second inconsistency. Lob implies 2nd inconsistency.)</li>
<li>If <span class="math inline">\(X\)</span> is neither provable nor disprovable, then does not halt. (Also can’t prove it.)</li>
</ol>
<p>Also a finite version of Lob’s theorem, controls length of proof of <span class="math inline">\(\phi\)</span> in terms of <span class="math inline">\(\square \phi\to \phi\)</span>.</p>
<h3 id="applications">Applications</h3>
<h4 id="lobstacle">Lobstacle</h4>
<p>DT1 trusts DT2: if the action is deduced to be good, then it must actually be good.</p>
<p>(It can’t even trust itself?)</p>
<p>a simple agent with a utility function will only create successors whose formal systems are strictly weaker thanits own, since only those are fully trusted by the current system.</p>
<p>References: Tiling Agents for Self-Modifying AI, and the Lobian Obstacle [18] and Problems of self-reference in self-improving space-time embedded intelligence [9].</p>
<h4 id="lobian-cooperation">Lobian cooperation</h4>
<p>algorithm and theirs get to read the opponent’s source code, calculate for as long as they like, and then play only once.</p>
<p>Cooperate iff source code identical: fragile.</p>
<p>FairBot: search through all proofs of length <span class="math inline">\(\le N\)</span> to see if valid proofs of <span class="math inline">\(X(FairBot)=C\)</span>. If yes, output <span class="math inline">\(C\)</span>.</p>
<p>Intuitively, it seems like both mutual cooperation and mutual defection are stable fixed points of the situation. However, a Lobian statement breaks the deadlock in favor of cooperation!</p>
<p>Proof: L(“FairBot(FairBot)=C”) follows. By Lob, there must be a proof of FairBot(FairBot=C). (! This is a case where Lob actually helps prove something!)</p>
<p>See Program Equilibrium in the Prisoner’s Dilemma via Lob’s Theorem.</p>
<h4 id="spurious-counterfactuals">3.3 Spurious counterfactuals</h4>
<p>Note on model:</p>
<ul>
<li>If universe was computable (with agent’s resources) and extensionally fair, then the problem is simple: A simply selects the function that maximizes its expected utility. (Suppose A has a time limit it must halt by.)</li>
<li>Problem: Nesting - what if they keep calling one another? (I think this is not an issue if you enforce time limit.)</li>
<li>Problem: It doesn’t make sense for agent to have enough computing power to simulate the universe. In general we want to allow the universe to have more computing power. “Agent simulates universe” is not the shape of things we want.</li>
<li>Problem: May examine source code.</li>
</ul>
<p>When agent and universe are quined, you can’t “run the universe” on <span class="math inline">\(A\)</span> or <span class="math inline">\(A'\)</span>. You search for proofs of <span class="math inline">\(A()=x\to U()=c\)</span>. Problem: ordering matters. If you prove <span class="math inline">\(x\)</span> is better you choose <span class="math inline">\(x\)</span>, even though it could be worse, because <span class="math inline">\(A()=\neg x\to U()=c\)</span> is true for any <span class="math inline">\(c\)</span>.</p>
<p>(Why can’t extensional work? Search for proofs in universe quined with <span class="math inline">\(A'\)</span>, then choose <span class="math inline">\(A'\)</span>.)</p>
<p>careful ordering of which proofs it pays attention to, and that agent can be shown to make thecorrect decisions (given enough deductive power). The idea was originally due to Benja Fal-lenstein; Tsvi Benson-Tilson’s paper UDT with Known Search Order</p>
<h3 id="model-theory">Model theory</h3>
<p>the same theory can have many models, some of them not at all what you were thinking of when you made the axioms. Notes: to get Peano Arithmetic need</p>
<ul>
<li><span class="math inline">\(\forall x\in \N, Sx\ne O\)</span> to avoid mod <span class="math inline">\(n\)</span>.</li>
<li>But what about <span class="math inline">\(\N\cup \{\text{Bob}\}\)</span>? In order to express induction in the language (which doesn’t have variables for properties, only for numbers), we must resort to an infinite family of new axioms.</li>
</ul>
<p>There are models of Peano arithmetic where G holds, and other models where G fails to hold. In Robinson arithmetic “Bob” might satisfy the formula G is checking. In PA nonstandard models are weirder.</p>
<p>The key to understanding these is that G never halts at any finite number, but we can’t actually define in our formal language what “finite” means. Thenonstandard models of Peano Arithmetic are those which have all the usual numbers butalso lots of extra numbers that are “too large” to ever be written as lots of S’s followed by an O, but which nonetheless are swept along in any inductive statement.</p>
<p>Remark: nonstandard analysis</p>
<p>Ponder for a moment the formal system which has all the axioms of PA, plus the axiom that PA is consistent, plus the axiom that “the systemwhich has all the axioms of PA, plus the axiom that PA is consistent” is inconsistent. As it turns out, this is a perfectly consistent system (What happens if you take the recursively axiomatizable “consistency<span class="math inline">\({}^n\)</span>, <span class="math inline">\(n\in \N\)</span>?)</p>
<p>We might want to endorse some particular model as the “true” one (for instance, our standard model of the natural numbers, without all of those weird nonstandard numbers), and say that logical statements are true if they hold in that model and false if they don’t. This truth predicate exists outside the language, and so the logical statements can’t talk about the truth predicate, only about weaker notions like provability.</p>
<p>The trouble comes when we try to construct a language that contains its own truth predicate such that <span class="math inline">\(T(\phi)\lra \phi\)</span>. <span class="math inline">\(T(X)\lra T(\neg X)\)</span>.</p>
<p>if P isn’t allowed to make exact statements about its own values, but only arbitrarily precise approximations, then everything can work out consistently.</p>
<p>P can’t rule out the possibility that reciprocals of nonstandard natural numbers (infinitesimals) exist.</p>
<p>followup paper by Christiano on computationally tractable approxima-tions of probabilistic logic: Non-Omniscience, Probabilistic Inference, and Metamathematics</p>
<h3 id="godel-lob-modal-logic">Godel-Lob Modal Logic</h3>
<p>We’re interested in a particular modal logic that constitutes a reflection of Lobian phenomena in PA, etc.</p>
<p>GL axiom: <span class="math inline">\(\square (\square A \to A)\to \square A\)</span>.</p>
<p>(What about things like <span class="math inline">\(\forall x, \square P(x)\)</span>?)</p>
<p>some special cases where there are efficient algorithms for deducing provability in GL.</p>
<h3 id="fixed-points-of-modal-statements">Fixed points of modal statements</h3>
<p>All sorts of formulas that refer to themselves and each other by quining. Formulas <span class="math inline">\(p\lra \phi(p,q_1,\ldots, q_k)\)</span> modalized in <span class="math inline">\(p\)</span>: every <span class="math inline">\(p\)</span> in <span class="math inline">\(\phi\)</span> is in scope of some <span class="math inline">\(\square\)</span>.</p>
<p>When <span class="math inline">\(p\)</span> equivalent to formula modalized in <span class="math inline">\(p\)</span>, then <span class="math inline">\(p\)</span> is equivalent to something which doesn’t use <span class="math inline">\(p\)</span>. Godel statement <span class="math inline">\(\lra\)</span> inconsistency of arithmetic <span class="math inline">\(\square (p\lra \square \neg p) \lra \square (p\lra \square \perp)\)</span>.</p>
<p>formula is provable in the modal logic if and only if a corresponding property holds for every Kripke frame in that class.</p>
<h3 id="applications-of-gl-modal-logic">Applications of GL modal logic</h3>
<p>Robust Cooperation in the Prisoner’s Dilemma: Program Equilibrium via Provability Logic.</p>
<p>One embarrassing thing about FairBot is that it doesn’t check whether its potential cooperation would actually make any difference. (ex. it cooperates against a rock.)</p>
<p>Ex. PrudentBot</p>
<p>if we assume infinite computational power (i.e. the ability to consult a halting oracle about proof searches in Peano Arithmetic), then they can be written out as simple statements in modal logic</p>
<p>Find what happens using efficient algorithm!</p>
<p>Modal agents of rank 0: <span class="math inline">\(p\lra \phi(p,q)\)</span>, modalized in both <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> (don’t run, only prove). Equivalent to something <span class="math inline">\(p\lra \phi(q)\)</span>.</p>
<h2 id="reflective-oracles-as-foundation">Reflective oracles as foundation</h2>
<h2 id="reflective-oracles-and-solomonoff-induction">Reflective oracles and Solomonoff induction</h2>
<p><a href="https://en.wikipedia.org/wiki/AIXI">AIXI</a></p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Neural net separation</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/neural_nets/separation.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/neural_nets/separation.html</id>
    <published>2017-02-09T00:00:00Z</published>
    <updated>2017-02-09T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Neural net separation</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-09 
          , Modified: 2017-02-09 
	</p>
      
       <p>Tags: <a href="/tags/neural%20nets.html">neural nets</a>, <a href="/tags/circuit%20complexity.html">circuit complexity</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#k-vs.k1">k vs. k+1</a><ul>
 <li><a href="#relate-to-arithmetic-circuits">Relate to arithmetic circuits</a><ul>
 <li><a href="#problem-1-approximation">Problem 1: Approximation</a></li>
 <li><a href="#problem-2-arithmetic-question">Problem 2: Arithmetic question</a></li>
 </ul></li>
 </ul></li>
 </ul> </div>

  <div class="blog-main">
    <p><a href="https://www.dropbox.com/s/d68tepx2x5h13at/representation.pdf?dl=0">Notes</a> (See section 2.)</p>
<h2 id="k-vs.k1">k vs. k+1</h2>
<p>One idea:</p>
<h3 id="relate-to-arithmetic-circuits">Relate to arithmetic circuits</h3>
<p>Cf. CSS16.</p>
<p>Idea: write out everything as power series. Perhaps fix a probability measure such as Gaussian.</p>
<p>The circuit model is <span class="math inline">\(\sum P \sum P...\)</span> where <span class="math inline">\(P\)</span> is any univariate power series. We hope that it can be approximated by its first few terms, so that we get a polynomial.</p>
<p>Restrict the <span class="math inline">\(k+1\)</span>-depth circuits to be somewhat smooth, so they can be approximated by the first few terms of the power series.</p>
<h4 id="problem-1-approximation">Problem 1: Approximation</h4>
<p>We can find pairs of functions which differ very much on the first few terms of their power series but that are arbitrarily close on <span class="math inline">\(L^2(\mu)\)</span>.</p>
<p>The natural thing to do is to look at families of orthogonal polynomials on <span class="math inline">\(\mu\)</span>. But these</p>
<ul>
<li>don’t distribute nicely (ex. we can write <span class="math inline">\((x+y)^n\)</span> as a sum of <span class="math inline">\(n+1\)</span> terms, but not <span class="math inline">\(He_n(x+y)\)</span>) - I don’t think this is such a big deal though.</li>
<li>letting <span class="math inline">\(\Pi_d\)</span> be projection to degree <span class="math inline">\(\le d\)</span> part, we don’t have <span class="math inline">\(\Pi_d\circ P \circ \Pi_d = \Pi_d \circ P\)</span>. So it’s very hard to argue composition.</li>
</ul>
<p>Can we require our approximating function to also be somewhat smooth? Then e.g. we can use compactness (Arzela-Ascoli) - arbitrarily close approximation means expressible, otherwise you can’t get closer than <span class="math inline">\(\ep\)</span>. But <span class="math inline">\(\ep\)</span> might depend on <span class="math inline">\(n\)</span>… (Ex. with certain bounds on coefficients, and a requirement that your power series starts with <span class="math inline">\(p(x)\)</span>, what is the minimial <span class="math inline">\(L^2(\mu)\)</span> norm it has?)</p>
<p>Order of quantifiers?</p>
<h4 id="problem-2-arithmetic-question">Problem 2: Arithmetic question</h4>
<p>The circuit model is <span class="math inline">\(\sum P \sum P...\)</span> where <span class="math inline">\(P\)</span> is any univariate power series/polynomial. Find a polynomial that is attainable by the degree <span class="math inline">\(\le d\)</span> portion of a depth <span class="math inline">\(k+1\)</span> circuit (depth <span class="math inline">\(k+1\)</span> means <span class="math inline">\(\sum (P\sum)^{k}\)</span>) that is not attainable by the degree <span class="math inline">\(\le d\)</span> portion of any depth <span class="math inline">\(k\)</span> circuit of subexponential size.</p>
<p><strong>What are separation results for normal arithmetic circuits?</strong></p>
<p>Look at constant-depth circuits: keep <span class="math inline">\(k\)</span> fixed; you’re allowed to take <span class="math inline">\(n\to \iy\)</span>.</p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Boosting</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/boosting.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/boosting.html</id>
    <published>2017-02-08T00:00:00Z</published>
    <updated>2017-02-08T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Boosting</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2017-02-08 
          , Modified: 2017-02-08 
	</p>
      
       <p>Tags: <a href="/tags/Boosting.html">Boosting</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#weak-learnability">Weak learnability</a></li>
 <li><a href="#boosting-problem">Boosting problem</a></li>
 <li><a href="#adaboost">AdaBoost</a></li>
 </ul> </div>

  <div class="blog-main">
    <p>Ref:</p>
<ul>
<li>Ch. 10 of <a href="http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning">Machine learning theory and algorithms</a></li>
<li><a href="http://cseweb.ucsd.edu/~yfreund/papers/IntroToBoosting.pdf">notes</a></li>
<li>0306 and 0311 in COS511 lectures</li>
</ul>
<p>Generalization of linear predictors to address 2 issues</p>
<ul>
<li>bias-complexity tradeoff (smooth control)</li>
<li>computational complexity of learning (amplify accuracy of weak learner - ERM can be hard)</li>
</ul>
<p>AdaBoost relies on the family of hypothesis classes obtained by composing a linear predictor on top of simple classes.</p>
<h2 id="weak-learnability">Weak learnability</h2>
<p><span class="math inline">\(C\)</span> is strongly PAC-learnable by <span class="math inline">\(A\)</span> if:</p>
<ul>
<li><span class="math inline">\(\forall\)</span> distribution <span class="math inline">\(D\)</span> over <span class="math inline">\(X\)</span>,</li>
<li><span class="math inline">\(\forall c\in C\)</span></li>
<li><span class="math inline">\(\forall \ep&gt;0\)</span></li>
<li><span class="math inline">\(\forall \de&gt;0\)</span>,</li>
<li><span class="math inline">\(A\)</span>, given <span class="math inline">\(m=\poly(\rc\ep,\rc \de)\)</span> examples, computes <span class="math inline">\(h\)</span> with <span class="math inline">\(\Pj[err(h)\le \ep] \ge 1-\de\)</span>.</li>
</ul>
<p><span class="math inline">\(C\)</span> is weakly PAC-learnable by <span class="math inline">\(A\)</span> if:</p>
<ul>
<li><span class="math inline">\(\exists \ga &gt;0\)</span></li>
<li><span class="math inline">\(\forall\)</span> distribution <span class="math inline">\(D\)</span> over <span class="math inline">\(X\)</span>,</li>
<li><span class="math inline">\(\forall c\in C\)</span></li>
<li><span class="math inline">\(\forall \de&gt;0\)</span></li>
<li><span class="math inline">\(A\)</span>, given <span class="math inline">\(m=\poly(\rc\de)\)</span> examples, computes <span class="math inline">\(h\)</span> with <span class="math inline">\(\Pj[err(h)\le \rc2-\ga] \ge 1-\de\)</span>.</li>
</ul>
<p>[Q: what is an explicit example of a provable weak learner?]</p>
<p>Q: Is weak learning equivalent to strong learning?</p>
<p>A: Yes if you increase the hypothesis class.</p>
<h2 id="boosting-problem">Boosting problem</h2>
<p>Given <span class="math inline">\((x_i,y_i)\)</span> with <span class="math inline">\(y_i\in \{-1,+1\}\)</span> and access to a weak learner <span class="math inline">\(A\)</span>, find <span class="math inline">\(H\)</span> such <span class="math inline">\(\Pj(err_D(H)\le \ep)\ge 1-\de\)</span> (learn strongly).</p>
<h2 id="adaboost">AdaBoost</h2>
<p>Idea: produce different distributions <span class="math inline">\(D\)</span> from <span class="math inline">\(\mathcal D\)</span>. Pick distributions at each round that provide info about points that are hard to learn.</p>
<ul>
<li>At each step, run weak learner on <span class="math inline">\(D_t\)</span>. Suppose error is <span class="math display">\[err_{D_t}(h_t) = \rc2-\ga_t=\ep_t.\]</span></li>
<li>Set <span class="math inline">\(\al_t=\ln \pf{1-\ep_t}{\ep_t}\)</span>. (If error is close to <span class="math inline">\(\rc2\)</span>, this is small.)</li>
<li>Update distribution:
<span class="math display">\[\begin{align}
D_1(i) &amp;=\rc m\\
D_{t+1}(i) &amp;= \fc{D_t(i)}{Z_t}e^{\one_{h_t(x_i)=y_i}\al_t}
\end{align}\]</span></li>
<li>Return <span class="math inline">\(H(x) = \sgn \pa{\sumo tT \al_t h_t(x)}\)</span>.</li>
</ul>
<p>Q: Can we unify this with multiplicative weights? This seems like some kind of dual. (Check multiplicative weights paper?)</p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>

</feed>
