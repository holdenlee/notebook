<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Research Notebook</title>
    <link href="http://holdenlee.github.io/notebook/atom.xml" rel="self" />
    <link href="http://holdenlee.github.io/notebook" />
    <id>http://holdenlee.github.io/notebook/atom.xml</id>
    <author>
        <name>Holden Lee</name>
        <email>oldheneel@gmail.com</email>
    </author>
    <updated>2016-10-19T00:00:00Z</updated>
    <entry>
    <title>Weekly summary 2016-10-22</title>
    <link href="http://holdenlee.github.io/notebook/posts/summaries/2016-10-22.html" />
    <id>http://holdenlee.github.io/notebook/posts/summaries/2016-10-22.html</id>
    <published>2016-10-19T00:00:00Z</published>
    <updated>2016-10-19T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Weekly summary 2016-10-22</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-10-19 
          , Modified: 2016-10-19 
	</p>
      
       <p>Tags: <a href="/tags/none.html">none</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#threads">Threads</a></li>
 <li><a href="#other-papers">Other papers</a></li>
 <li><a href="#talk-with-arora-1019-wed">Talk with Arora 10/19 (Wed)</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="threads">Threads</h2>
<ul>
<li>PMI - get some results!</li>
<li>SoS - chapters 2 and 3</li>
<li>DL: do experiments suggested in <a href="/posts/tcs/machine_learning/matrices/DL_generalization.html">DL generalization</a> (Mon, Tue)
<ul>
<li>(*) NN learns DL. (Mon, Tue) - Wrote up progress so far, where I am stuck.</li>
</ul></li>
<li>Papers
<ul>
<li>[HM16] on unsupervised learning (went through 1st half, Tue)</li>
<li>[HMR16] on dynamical system learning (read <a href="http://www.offconvex.org/2016/10/13/gradient-descent-learns-dynamical-systems/">blog post</a> Tue)</li>
</ul></li>
<li>Come up with a class of MDPs on exponential space that is interesting and tractable. <a href="/posts/tcs/machine_learning/reinforcement_learning/exponential.html">Thoughts</a>
<ul>
<li>Understand provable guarantees on MDP’s first</li>
</ul></li>
<li>Alexa <a href="https://docs.google.com/document/d/1OtvefjviKSSWH2gzOtYo8T_DVEwPEsI2n0kdrC8WlZI/edit">references</a></li>
</ul>
<p>Analyze Arora and Ge’s NMF algorithm in the presence of noise. Exactly how much noise can it tolerate?</p>
<h2 id="other-papers">Other papers</h2>
<ul>
<li>TODO Read this paper: [CFP16] Assessing significance in a Markov chain without mixing</li>
</ul>
<h2 id="talk-with-arora-1019-wed">Talk with Arora 10/19 (Wed)</h2>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>DL experiments</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/matrices/dl_experiments.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/matrices/dl_experiments.html</id>
    <published>2016-10-17T00:00:00Z</published>
    <updated>2016-10-17T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>DL experiments</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-10-17 
          , Modified: 2016-10-17 
	</p>
      
       <p>Tags: <a href="/tags/dictionary%20learning.html">dictionary learning</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#experiments">Experiments</a></li>
 <li><a href="#results">Results</a><ul>
 <li><a href="#first-observations">First observations</a></li>
 </ul></li>
 <li><a href="#evaluation">Evaluation</a></li>
 </ul> </div>

  <div class="blog-main">
    <p>What are convergence guarantees for dictionary learning? Consider the settings</p>
<ul>
<li>AGMM15 (Alternating minimization)</li>
<li>2-layer NN
<ul>
<li>With <span class="math inline">\(b^Ty\)</span></li>
<li>With <span class="math inline">\(\sgn(b^Ty)\)</span></li>
</ul></li>
</ul>
<!--
Sanjeev told me you did some experiments, so I wanted to check with you.

Experimentally, does dictionary learning converge to the right dictionary under random initialization? What if we randomly initialize with samples drawn from $x=Ah$? What about for the neural net (backprop) model you showed me last time - does random initialization (with samples) converge to the dictionary? If you have code for experiments, please send it to me.

I've done a lot of the calculations for neural nets learning dictionaries, and am getting stuck on the following: it appears that the gradient of the entire matrix is correlated with the right direction, but individual rows may not be (so a row may get far away until it no longer decodes correctly). Did you encounter something like this? If you have the bandwidth I'd be interested in working with you on this.

-->
<h2 id="experiments">Experiments</h2>
<p>Code is in <code>dl_convergence.py</code>. Run on ionic.</p>
<h2 id="results">Results</h2>
<!--1218589: -->
<ul>
<li>s = 3</li>
<li>m = 50 # hidden vector</li>
<li>n = 25 # observed vector</li>
<li>q = s/m</li>
<li>alpha = .01</li>
<li>batchsize = 1024</li>
<li>vary sigma (how close initialization is) <!-- * Approximate convergence for sigma = .05, .1; not 0.5--></li>
</ul>
<p>Next,</p>
<ul>
<li>add random initialization - check</li>
<li>vary (s,m,n)</li>
<li>check sparsity of learned vectors (do thresholding too) - check</li>
<li>add initialization from samples - check
<ul>
<li>try overcomplete initialization from samples - check</li>
</ul></li>
</ul>
<h3 id="first-observations">First observations</h3>
<p>See <code>am_dl_3_50_25.txt</code> and <code>slurm-1218768.out</code></p>
<ul>
<li>Converges when close enough (as in AGMM15). For this, even 0.5 is close enough. Note it doesn’t converge to <span class="math inline">\(A\)</span> - it converges to something that has columns <span class="math inline">\(\approx 0.1\)</span> away from <span class="math inline">\(A\)</span>, consistant bias. (This makes sense.)</li>
<li>Random initialization does not converge to global optimum. Initialization with samples seems to do slightly better.</li>
</ul>
<h2 id="evaluation">Evaluation</h2>
<p>How to evaluate?</p>
<ul>
<li>Closeness of columns.</li>
<li>Loss: how much sparsity, and how far away. (Reconstruction error)
<ul>
<li>How does reconstruction error compare to SVD? (Make dimensions comparable.)</li>
</ul></li>
<li>Put in random SVM on top. Can it learn the SVM well?</li>
<li>Check framework in [HM16].</li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>MDP's with continuous state space</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/reinforcement_learning/continuous.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/reinforcement_learning/continuous.html</id>
    <published>2016-10-14T00:00:00Z</published>
    <updated>2016-10-14T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>MDP's with continuous state space</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-10-14 
          , Modified: 2016-10-14 
	</p>
      
       <p>Tags: <a href="/tags/none.html">none</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#starting-points">Starting points</a></li>
 <li><a href="#model">Model</a><ul>
 <li><a href="#first-try">First try</a></li>
 <li><a href="#second-try">Second try</a></li>
 </ul></li>
 <li><a href="#references">References</a><ul>
 <li><a href="#online">Online</a></li>
 <li><a href="#books">Books</a></li>
 <li><a href="#papers">Papers</a></li>
 </ul></li>
 <li><a href="#misc">Misc</a></li>
 </ul> </div>

  <div class="blog-main">
    <p><a href="https://en.wikipedia.org/wiki/Kalman_filter">Kalman filter</a></p>
<p>Come up with a class of MDPs on exponentially large/continuous space that is interesting and tractable. Think of generalizing from contextual bandits * Basically we want a reasonable model of a MDP with a very large (exponential or continuous) state space and be able to do something with it. Wanted to include some dynamics like in Kalman filters but we weren’t sure whether Kalman filters are tractable * Todo: learn about Kalman filters</p>
<h2 id="starting-points">Starting points</h2>
<ol type="1">
<li>HMM’s have discrete state space. What happens with continuous state space? Suppose there are some dynamics as in Kalman filters. Infer the hidden state. References
<ul>
<li>Continuous HMM paper (RKHS)</li>
<li>Kalman filters (see examples)</li>
<li>Grad descent learning dynamical systems.</li>
</ul></li>
<li>Contextual bandits + MDP’s. Don’t assume there’s a hidden state here, just that next state depends, say, linearly on action and noise.</li>
<li>Context vector/random walk model for documents: transition probabilities <span class="math inline">\(\propto \exp(-\an{c_1,c_2})\)</span> and observation probabilities <span class="math inline">\(\propto \exp(-\an{c_1,x})\)</span>.</li>
</ol>
<h2 id="model">Model</h2>
<h3 id="first-try">First try</h3>
<ul>
<li>Stochastic setting.</li>
<li><span class="math inline">\(c_t\)</span> is context at time <span class="math inline">\(t\)</span>.</li>
<li>Set of actions <span class="math inline">\(A\)</span>. (For example, <span class="math inline">\(A=\{e_1,\ldots, e_n\}\)</span>.)</li>
<li>Next context <span class="math inline">\(c_{t+1}=\)</span> (Here <span class="math inline">\(w_t\)</span> is noise.)
<ul>
<li><span class="math inline">\(F_a c_t + w_t\)</span>. (Transformation depends on action.)</li>
<li><span class="math inline">\(F c_t + B a + w_t\)</span>. (Action is a forcing term. This matches Kalman formulation. More reasonable?) (*)</li>
</ul></li>
<li>Payoff depends on context and actions in some way.
<ul>
<li>Model 1: depends only on context <span class="math inline">\(\te^T c_t\)</span>. (*)</li>
<li>Model 2: depends on context and action <span class="math inline">\(\te^T[c_t;a]\)</span>.</li>
<li>? Some probability?</li>
</ul></li>
</ul>
<p>This setting looks like reinforcement learning + control theory. Prior work? How is RL used in continuous systems right now? Basic control theory background?</p>
<p>Need the model to be a generalization of regular MDP.</p>
<p>(*) may be interesting from control theory perspective, but doesn’t generalize discrete MDP. (Seems like best to learn the dynamics, and then do optimal thing from there…)</p>
<h3 id="second-try">Second try</h3>
<ul>
<li>Finite number of actions</li>
<li><span class="math inline">\(c_{t+1} = F_a c_t + w_t\)</span>. (Only probability is noise.)</li>
<li>Payout <span class="math inline">\(\te_^T c_t\)</span>.</li>
</ul>
<p>Captures deterministic MDP, but not probabilistic, by letting <span class="math inline">\(A=\{e_i\}\)</span>.</p>
<h2 id="references">References</h2>
<h3 id="online">Online</h3>
<ul>
<li><a href="http://castlelab.princeton.edu/">CASTLE Labs</a>
<ul>
<li><a href="http://optimallearning.princeton.edu/">Optimal learning</a></li>
<li><a href="http://adp.princeton.edu/">Approximate dynamic programming</a>
<ul>
<li><a href="http://adp.princeton.edu/adpIntros.htm">Intros</a></li>
</ul></li>
<li><a href="http://castlelab.princeton.edu/jungle.htm#unifiedframework">Unified framework</a></li>
</ul></li>
<li><a href="https://github.com/andrewliao11/Deep-Reinforcement-Learning-Survey/blob/master/Reinforcement-Learning-Papers.md">Deep RL</a></li>
</ul>
<h3 id="books">Books</h3>
<ul>
<li><a href="https://books.google.com/books?id=VvBjBAAAQBAJ&amp;printsec=frontcover&amp;dq=continuous+markov+decision+processes&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjo3OLywOnPAhVHWD4KHXzgDWUQ6AEIKTAC#v=onepage&amp;q=continuous%20markov%20decision%20processes&amp;f=false">Puterman14</a></li>
<li><a href="https://books.google.com/books?id=-6RiQgAACAAJ&amp;dq=Dynamic+Programming:+Deterministic+and+Stochastic+Models&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjc0pfAyefPAhUGFz4KHaVIDecQ6AEIHjAA">Bertsekas87</a></li>
</ul>
<h3 id="papers">Papers</h3>
<ul>
<li>[AAKMR02] A Note on the Representational Incompatibility of Function Approximation and Factored Dynamics.pdf
<ul>
<li>Barrier to solving factored MDP’s is not just computational, it is representational (there is no succinct policy)</li>
<li>DBN-MDP (factored MDP): transition law <span class="math inline">\(\de\)</span> is dynamic Bayes net. The first layer are the variables (and action) at time <span class="math inline">\(t\)</span>, the second layer are the variables at time <span class="math inline">\(t+1\)</span>, the graph is directed, the indegree of each second-layer node is at most constant.</li>
<li>Rewards are linear.</li>
<li>Connection with AM-games: V’s state corresponds to state, P implements policy.</li>
<li>If PSPACE is not contained in P/POLY, then there is a family of DBN-MDPs, such that for any two polynomials <span class="math inline">\(s,a\)</span>, there exist infinitely many <span class="math inline">\(n\)</span> such that no circuit <span class="math inline">\(C\)</span> of size <span class="math inline">\(s(n)\)</span> can compute a policy having expected reward greater than <span class="math inline">\(\rc{a(n)}\)</span> times the optimum.</li>
<li>(This is the policy optimization part. Can you learn Bayes nets? <span class="citation" data-cites="Andrej">@Andrej</span>)</li>
<li>(Note that the “drifting context vector (RANDWALK)” model can be represented by a model with <span class="math inline">\(1\to 1', 2\to 2',\ldots\)</span>.)</li>
<li>What if you only compared to the best policy in a class of policies? (cf. EXP4)</li>
</ul></li>
<li>(*) [ALA16] Reinforcement Learning of POMDPs using Spectral Methods.pdf</li>
<li>[G] Reinforcement learning - a Tutorial Survey and Recent Advances.pdf</li>
<li>[HSMM15] Off-policy Model-based Learning under Unknown Factored Dynamics.pdf
<ul>
<li>Under 3 assumptions, using a greedy approach to finding parents, estimate the transition function (parameters to Bayes net) (compre with prob models literature?)</li>
<li>This is for off-policy evaluation; it doesn’t tell us how to find the optimal policy.</li>
<li>(Is the model learning and policy evaluation coupled or not?)</li>
<li>(It seems to be learning the Bayes net rather than evaluating <span class="math inline">\(\pi\)</span>. Ah, once you learn the Bayes net then you can evaluate just by sampling.)</li>
<li>The difference from simpling learning a Bayes net is that the samples aren’t independent—they were from following a certain policy. Assumptions will ensure that you can still learn the model even if you only have samples from that policy.</li>
</ul></li>
<li>[KAL16] Contextual-MDPs for PAC-Reinforcement Learning with Rich Observations.pdf</li>
<li>[KLM96] Reinforcement Learning - A Survey.pdf</li>
<li>(*) [P14] Clearing the Jungle of Stochastic Optimization.pdf</li>
<li>[P14] Energy and Uncertainty - models and algorithms for complex energy systems.pdf</li>
<li>(*) [P16] A Unified Framework for Optimization under Uncertainty.pdf</li>
<li>[PB79] On the convergence of policy iteration in stationary dynamic programming.pdf</li>
<li>(*) [SR04] Convergence properties of policy iteration.pdf</li>
<li>(*) [WD92] Q-learning.pdf</li>
</ul>
<h2 id="misc">Misc</h2>
<p>Do as well as best Bayes net? Actions in some class. Finite set of actions, vs. exponential/continuous set of actions. In latter case, will depend on optimizability of that set…</p>
<!--Definitely need something stronger than: there exist something that works! if can encode crypto -->

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Finite model theory</title>
    <link href="http://holdenlee.github.io/notebook/posts/math/logic/finite_model_theory.html" />
    <id>http://holdenlee.github.io/notebook/posts/math/logic/finite_model_theory.html</id>
    <published>2016-10-14T00:00:00Z</published>
    <updated>2016-10-14T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Finite model theory</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-10-14 
          , Modified: 2016-10-14 
	</p>
      
       <p>Tags: <a href="/tags/model%20theory.html">model theory</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#definability-and-undefinability">1 Definability and undefinability</a><ul>
 <li><a href="#expressive-power">Expressive power</a></li>
 </ul></li>
 </ul> </div>

  <div class="blog-main">
    <p><a href="https://simons.berkeley.edu/talks/finite-and-algorithmic-model-theory">Link</a></p>
<h2 id="definability-and-undefinability">1 Definability and undefinability</h2>
<ul>
<li>Expressive power of logics on class of finite structures.</li>
<li>Problems in computer science (complexity theory, database theory) are naturally questions about expressive power of logics.</li>
</ul>
<p><span class="math display">\[Mod(\ph) = \set{\mathbb A}{ \mathbb A \vDash \ph}.\]</span> Here <span class="math inline">\(\mathbb A\)</span> ranges over finite relational structures.</p>
<p>What classes of structures are definable? (Set of possible <span class="math inline">\(Mod(\ph)\)</span>’s for <span class="math inline">\(\ph\)</span> in logic <span class="math inline">\(\mathcal L\)</span>.)</p>
<ul>
<li>Syntactic restrictions on <span class="math inline">\(\ph\)</span> vs. semantic restrictions on <span class="math inline">\(Mod(\ph)\)</span>.</li>
<li>Computational complexity of <span class="math inline">\(Mod(\ph)\)</span> vs. syntactic complexity of <span class="math inline">\(\ph\)</span>.</li>
</ul>
<h3 id="expressive-power">Expressive power</h3>
<p>Relational vocabulary: finite set <span class="math inline">\(A\)</span> with relations <span class="math inline">\(R_1,\ldots, R_m\)</span> and constants <span class="math inline">\(c_1,\ldots, c_n\)</span>.</p>
<p>A property of finite structures is any isomorphism-closed class of structures. (Morphisms are permutations. Ex. graph ismomorphisms.) Given logic, for which properties <span class="math inline">\(P\)</span> is there a sentence <span class="math inline">\(\ph\)</span> such that <span class="math inline">\(\mathbb A\in P\iff A\vDash \ph\)</span>.</p>
<p>Ex. colored graphs: one binary relation <span class="math inline">\(E^2\)</span> and some unary relations <span class="math inline">\(C_i^1\)</span>. First-order logic formulas involve these relations and <span class="math inline">\(\wedge, \vee, \neg, \exists, \forall\)</span>.</p>
<ul>
<li>Vertex cover of size at most <span class="math inline">\(k\)</span>. (<span class="math inline">\(k\)</span> fixed)</li>
<li>3-colorability when allow quantification over sets of vertices.</li>
</ul>
<p>Compactness, completeness, preservation fail. (What are these exactly?)</p>
<p>Methods:</p>
<ul>
<li>Ehrenfeucht-Fraisse Games and related model-comparison games</li>
<li>Locality Theorems</li>
<li>Automata-based methods</li>
<li>Complexity</li>
<li>Asymptotic Combinatorics</li>
</ul>
<p>Equivalence means satisfying the same statements in the logic. On finite structures, two structures are equivalent iff they are isomorphic.</p>
<p>Quantifier rank:</p>
<ol type="1">
<li>For atoms, <span class="math inline">\(qr(\ph)=0\)</span>.</li>
<li><span class="math inline">\(qr(\neg \psi) = qr(\psi)\)</span>.</li>
<li><span class="math inline">\(qr(\psi_1\wedge/\vee \psi_2) = \max_i(qr(\psi_i))\)</span>.</li>
<li><span class="math inline">\(qr(\exists/\forall x \psi) = qr(\psi)+1\)</span>.</li>
</ol>
<p><span class="math inline">\(\mathbb A\equiv_p \mathbb B\)</span> iff for all <span class="math inline">\(qr(\ph)\le p\)</span>, <span class="math inline">\(A\vDash \ph\iff B\vDash \ph\)</span>.</p>
<p><span class="math inline">\(S\)</span> is definable by first order sentence iff <span class="math inline">\(S\)</span> is closed under <span class="math inline">\(\equiv_p\)</span> for some <span class="math inline">\(p\)</span>. (13) ?? (Is <span class="math inline">\(S\)</span> on finite set? What does “finite relational vocab” mean?) (Is this trivial by taking <span class="math inline">\(p=|A|\)</span>?) (NO: <span class="math inline">\(A\)</span> is of arbitrary finite size!)</p>
<p>Ex. I think connectedness is not first-order!</p>
<p>Define <strong>partial isomorphism</strong>.</p>
<p>Ehrenfeucht-Fraisse game:</p>
<p>For <span class="math inline">\(p\)</span> rounds:</p>
<ul>
<li>Spoiler choose one structure and an element of that structure.</li>
<li>Duplicator responds with element of other structure <span class="math inline">\(a_i\)</span>.</li>
</ul>
<p>After <span class="math inline">\(p\)</span> rounds, Duplicator wins if <span class="math inline">\(a_i\mapsto b_i\)</span> is partial iso. Duplicator has winning strategy iff <span class="math inline">\(\mathbb A\equiv_p \mathbb B\)</span>.</p>
<p>Proof: choose the witnesses of existence, going to the other structure for a <span class="math inline">\(\forall\)</span> because negated <span class="math inline">\(\forall\)</span> gives <span class="math inline">\(\exists\)</span>.</p>
<p>So to show not definable, for every <span class="math inline">\(p\)</span> produce <span class="math inline">\(\mathbb A_p\)</span>, <span class="math inline">\(\mathbb B_p\)</span> such that one is in <span class="math inline">\(S\)</span>, and duplicator wins.</p>
<p>Ex. Not definable: 2-colorability, even cardinality, connectivity.</p>
<p>(Duplicator’s strategy is to ensure that after r moves, the distance between corresponding pairs of pebbles is either equal or <span class="math inline">\(2p^r\)</span>.)</p>
<p>Alternative: stratify by number of free variables (in any sub-formula), <span class="math inline">\(\equiv^k\)</span>. <span class="math inline">\(\equiv^k\implies \equiv_k\)</span>.</p>
<p>Connectivity and 2-colorability are axiomatizable in <span class="math inline">\(L^k\)</span> (define <span class="math inline">\(path_{\le l}\)</span>, <span class="math inline">\(disconnect_l\)</span>); even cardinality is not. (I’m confused… why can we reuse variables?? 21)</p>
<p><span class="math inline">\(\equiv_p, \equiv^k\)</span> have finitely/infinitely many equivalence classes.</p>
<p>How is the pebble game different?? 23</p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Language games</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/nlp/language_games.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/nlp/language_games.html</id>
    <published>2016-10-13T00:00:00Z</published>
    <updated>2016-10-13T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Language games</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-10-13 
          , Modified: 2016-10-13 
	</p>
      
       <p>Tags: <a href="/tags/nlp.html">nlp</a>, <a href="/tags/language.html">language</a>, <a href="/tags/evolution.html">evolution</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#wlm16-learning-language-games-through-interaction">[WLM16] Learning Language Games through Interaction</a></li>
 <li><a href="#fafw16-learning-to-communicate-with-deep-multi-agent-reinforcement-learning">[FAFW16] Learning to Communicate with Deep Multi-Agent Reinforcement Learning</a><ul>
 <li><a href="#task">Task</a></li>
 <li><a href="#model">Model</a></li>
 <li><a href="#conclusions">Conclusions</a></li>
 </ul></li>
 </ul> </div>

  <div class="blog-main">
    <p>How does language develop?</p>
<p>How to learn a language from scratch?</p>
<p>Wittgenstein’s “language games”.</p>
<h2 id="wlm16-learning-language-games-through-interaction">[WLM16] Learning Language Games through Interaction</h2>
<p>See ML seminar notes.</p>
<h2 id="fafw16-learning-to-communicate-with-deep-multi-agent-reinforcement-learning">[FAFW16] Learning to Communicate with Deep Multi-Agent Reinforcement Learning</h2>
<p>Cooperative learning of communication protocols.</p>
<p>see also Kasai [8].</p>
<h3 id="task">Task</h3>
<p>Multiple agents in fully cooperative, partially observable, sequential multi-agent decisiom-making problems. Each gets a private observation of the Markov state.</p>
<ul>
<li>Centralized learning (unrestricted communication)</li>
<li>Decentralized execution (communicate only by discrete limited-bandwidth channel)</li>
</ul>
<p>Actual tasks</p>
<ul>
<li>Switch riddle
<ul>
<li>DIAL &gt; RIAL &gt; Baseline</li>
</ul></li>
<li>MNIST games: see 2 MNIST digits of some color. Reward depends on action, color, and parity. Send 1 bit of info. Agree to send either color or parity (parity better). (DIAL seems to get optimal here. RIAL fails.)</li>
</ul>
<h3 id="model">Model</h3>
<ul>
<li>Reinforced inter-agent learning (RIAL)
<ul>
<li>Deep Q-learning</li>
<li>Independent Q-learning: learn own network parameters, treat other agents as part of environment.</li>
<li>Deep recurrent Q-network. [17]
<ul>
<li><ul>
<li>independent Q-learning = RIAL.</li>
</ul></li>
<li>Disable experience replay (experience obsolete and misleading)</li>
</ul></li>
</ul></li>
<li>Differentiable inter-agent learning (DIAL)
<ul>
<li>Takes advantage of centralized learning.</li>
<li>RIAL is only end-to-end within agent.</li>
<li>Allows real-value messages to pass.</li>
<li>(This is not realistic between agents in terms of evolution. But it can make sense within agents - ex. different brain parts)</li>
<li>During centralized learning, communication replaced with direct connections between output of one agent’s network and input of another’s.</li>
</ul></li>
</ul>
<p>Difficulty: positive rewards are sparse, arising only when sending and interpreting are properly coordinated.</p>
<h3 id="conclusions">Conclusions</h3>
<p>Why is language discrete? Noise forces messages into 2 different modes.</p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Alexa</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/nlp/alexa.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/nlp/alexa.html</id>
    <published>2016-10-13T00:00:00Z</published>
    <updated>2016-10-13T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Alexa</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-10-13 
          , Modified: 2016-10-13 
	</p>
      
       <p>Tags: <a href="/tags/nlp.html">nlp</a>, <a href="/tags/dialogue.html">dialogue</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#questions">Questions</a></li>
 </ul> </div>

  <div class="blog-main">
    <p><a href="https://docs.google.com/document/d/1OtvefjviKSSWH2gzOtYo8T_DVEwPEsI2n0kdrC8WlZI/edit">References</a></p>
<ul>
<li>Dialogue
<ul>
<li>[LMRG16] Deep reinforcement learning for dialogue generation <a href="https://arxiv.org/pdf/1606.01541.pdf">paper</a></li>
<li>[DGZB16] EVALUATING PREREQUISITE QUALITIES FOR LEARNING END-TO-END DIALOG SYSTEMS <a href="https://arxiv.org/pdf/1511.06931v6.pdf">paper</a></li>
<li>[VL15] A Neural Conversational Model <a href="https://arxiv.org/pdf/1506.05869.pdf">paper</a></li>
</ul></li>
<li>Neural nets
<ul>
<li>[SSWF15] End-To-End Memory Networks
<ul>
<li>Architecture
<ul>
<li>Input <span class="math inline">\(x_i\)</span></li>
<li>Convert input into memory <span class="math inline">\(m_i = A x_i\)</span>, <span class="math inline">\(A\in \R^{d\times V}\)</span></li>
<li>Output vecor <span class="math inline">\(c_i = C x_i\)</span>.</li>
<li>Query <span class="math inline">\(q\)</span></li>
<li>Embedded query <span class="math inline">\(u=Bq\)</span>.</li>
<li>Match between queries and memory <span class="math inline">\(p_i = \text{softmax}(u^Tm_i)\)</span>.</li>
<li>Response is weighted sum <span class="math inline">\(o = \sum_i p_ic_i\)</span>.</li>
<li>Predicted answer <span class="math inline">\(\wh a = \text{softmax}(W(o+u))\)</span>.</li>
</ul></li>
<li>For multiple layers, <span class="math inline">\(u^{k+1}=u^k + o^k\)</span>. Each layer has <span class="math inline">\(A^k,C^k\)</span> to embed inputs.
<ul>
<li>Two types of weight tying
<ul>
<li>output = input above, <span class="math inline">\(A^{k+1}=C^k\)</span>.</li>
<li>RNN: <span class="math inline">\(A^k =A, C^k=C\)</span>, and modify <span class="math inline">\(u^{k+1} = H u^k + o^k\)</span>.</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li>OpenSubtitles
<ul>
<li><a href="http://www.opensubtitles.org/en/search">Main page</a></li>
<li><a href="https://datahub.io/dataset/opus/resource/e5a441a7-73d5-4f8c-a4b5-4bab42a739f2">?</a></li>
</ul></li>
</ul>
<h2 id="questions">Questions</h2>
<p>How does the beam search actually work? Do we just have <span class="math inline">\(\Pj(w_1)\Pj(w_2|w_1)\Pj(w_3|w_2,w_1)\)</span> or is there some more complicated energy-based model? (Don’t normalize?)</p>
<p>How to promote consistency in answers? Hidden state.</p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Interpretable neural nets</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/neural_nets/interpretability.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/neural_nets/interpretability.html</id>
    <published>2016-10-12T00:00:00Z</published>
    <updated>2016-10-12T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Interpretable neural nets</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-10-12 
          , Modified: 2016-10-12 
	</p>
      
       <p>Tags: <a href="/tags/neural%20nets.html">neural nets</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"></div>

  <div class="blog-main">
    <p>Enforce sparsity or nonnegativity.</p>
<ul>
<li>[NTPV13] Learning Parts-based Representations with Nonnegative Restricted Boltzmann Machine <a href="http://www.jmlr.org/proceedings/papers/v33/min14.pdf">paper</a>
<ul>
<li>Enforce nonnegativity in RBM by having a regularizer that’s a quadratic barrier function <span class="math inline">\(\min(0,x)^2\)</span>.</li>
</ul></li>
<li>[MNCG14] Interpretable Sparse High-Order Boltzmann Machines <a href="http://jmlr.org/proceedings/papers/v29/Nguyen13.pdf">paper</a></li>
<li>[KV16] Increasing the Interpretability of Recurrent Neural Networks Using Hidden Markov Models <a href="https://arxiv.org/abs/1606.05320">paper</a></li>
</ul>
<p>link to an article on extracting interpretable features out of deep nets? I forget the authors. Maybe Salakhutdinov was one of them.</p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Hidden Markov Models</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/probabilistic/hmm.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/probabilistic/hmm.html</id>
    <published>2016-10-11T00:00:00Z</published>
    <updated>2016-10-11T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Hidden Markov Models</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-10-11 
          , Modified: 2016-10-11 
	</p>
      
       <p>Tags: <a href="/tags/none.html">none</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#sch16-unsupervised-part-of-speech-tagging-with-anchor-hidden-markov-models">[SCH16] Unsupervised Part-Of-Speech Tagging with Anchor Hidden Markov Models</a></li>
 <li><a href="#misc">Misc</a></li>
 </ul> </div>

  <div class="blog-main">
    <ul>
<li>[HKZ12] A spectral algorithm for learning Hidden Markov Models</li>
<li>Continuous HMM [LBGS10] [paper](http://repository.cmu.edu/cgi/viewcontent.cgi?article=1057&amp;context=machine_learning)</li>
</ul>
<p><strong>Question</strong>: how robust to noise are these?</p>
<h2 id="sch16-unsupervised-part-of-speech-tagging-with-anchor-hidden-markov-models">[SCH16] Unsupervised Part-Of-Speech Tagging with Anchor Hidden Markov Models</h2>
<p>Reduce anchor-HMM to separable NMF. In anchor-HMM for every hidden state, there is an observed state that can only come from that hidden state. The anchor observations for <span class="math inline">\(h\)</span> are <span class="math display">\[
A(h) = \set{x\in [n]}{o(x|h)&gt;0\wedge o(x|h')=0\forall h'\ne h}.
\]</span> Let <span class="math inline">\(T_{h'h} = t(h'|h)\)</span> denote transition probabilities and <span class="math inline">\(O_{xj}=o(x|h)\)</span> denote observation probabilities.</p>
<p>The key is to define random variables <span class="math inline">\(Y_I\)</span> depending on <span class="math inline">\(H_I\)</span> (nontrivially) so that <span class="math inline">\(\Pj(Y_I|H_I,X_I) = \Pj(Y_I|H_I)\)</span>. We can take <span class="math inline">\(Y_I=X_{I+1}\)</span>! (More accurately, it’s a vector, <span class="math inline">\([Y_I]_{x'} = (X_{I+1}=x')\)</span>.)</p>
<p>Let <span class="math inline">\(\wt O_{xh} = \Pj(h|x)\)</span>, <span class="math inline">\((\Om_X)_{yx} = \Pj(Y_I=y|X_I=x)\)</span>, <span class="math inline">\(\Te_{hy} = \EE(Y_I=y|H_I=h)\)</span>. Then <span class="math display">\[\Om = \wt O \Te\]</span> is a separable NMF.</p>
<p>Brown model is an especially nice A-HMM where the anchors partition the set of all observations.</p>
<h2 id="misc">Misc</h2>
<p>The unsupervised log-linear model described in Berg-Kirkpatrick et al. (2010).</p>
<p>Agnostic HMM? Can spectral methods work?</p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Bandit convex optimization</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/optimization/bco.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/optimization/bco.html</id>
    <published>2016-10-11T00:00:00Z</published>
    <updated>2016-10-11T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Bandit convex optimization</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-10-11 
          , Modified: 2016-10-11 
	</p>
      
       <p>Tags: <a href="/tags/convex%20optimization.html">convex optimization</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#multi-armed-bandit">Multi-armed bandit</a><ul>
 <li><a href="#de-greedy-algorithm"><span class="math inline">$\de$</span>-greedy algorithm</a></li>
 <li><a href="#exp3">EXP3</a></li>
 <li><a href="#ucb1">UCB1</a></li>
 </ul></li>
 <li><a href="#blo">BLO</a><ul>
 <li><a href="#scrible">SCRIBLE</a></li>
 </ul></li>
 <li><a href="#bco">BCO</a><ul>
 <li><a href="#fkm">FKM</a></li>
 </ul></li>
 <li><a href="#contextual-bandits">Contextual bandits</a></li>
 </ul> </div>

  <div class="blog-main">
    <p>Settings of increasing complexity:</p>
<ul>
<li>Multi-armed bandit</li>
<li>Bandit linear optimization</li>
<li>Bandit convex optimization</li>
</ul>
<h2 id="multi-armed-bandit">Multi-armed bandit</h2>
<ul>
<li><span class="math inline">\(\de\)</span>-greedy algorithm: Balancing exploitation which gives <span class="math inline">\(O(\sqrt T)\)</span> regret and exploration which gives <span class="math inline">\(O(T^{\fc 34} \sqrt n)\)</span> regret.</li>
</ul>
<h3 id="de-greedy-algorithm"><span class="math inline">\(\de\)</span>-greedy algorithm</h3>
<ul>
<li>With probability <span class="math inline">\(\de\)</span>, explore.
<ul>
<li>Play <span class="math inline">\(i_t\sim U_n\)</span>.</li>
<li><span class="math inline">\(\wh f_t(x) = \wh \ell_t^T x\)</span>.</li>
<li><span class="math inline">\(\wh \ell_t = \fc{n}{\de}\ell_t(i_t)e_{i_t}\)</span>.</li>
</ul></li>
<li>With probability <span class="math inline">\(1-\de\)</span>, exploit.
<ul>
<li>Play <span class="math inline">\(i_t\sim x_t\)</span>.</li>
<li><span class="math inline">\(\wh f_t(x) = 0\)</span>. (We can’t use information here because it wasn’t uniformly generated.)</li>
</ul></li>
<li>Update using a bandit algorithm <span class="math inline">\(x_{t+1} = A(\wh f_1,\ldots, \wh f_t)\)</span>.</li>
</ul>
<p>The <span class="math inline">\(\wh \ell_t\)</span> were chosen so <span class="math display">\[ \E \wh \ell_t(i) = \ell_t(i).\]</span> We have <span class="math display">\[\E R_T \le 3 GD\sqrt T + \de T,\]</span> where <span class="math inline">\(G\le \fc n\de\)</span>.</p>
<h3 id="exp3">EXP3</h3>
<p>Exponential weights for exploration and exploitation</p>
<p>Adversarial setting.</p>
<p><a href="https://jeremykun.com/2013/11/08/adversarial-bandits-and-the-exp3-algorithm/">Blog post</a>.</p>
<p>We can explore and exploit at the same time if we (a) keep track of a probability distribution and update it, and (b) if we reweight the loss functions to make the expected value correct.</p>
<p>Idea: Use the MWU (hedge) algorithm.</p>
Updates
\begin{align}
y_{t+1}(i) &amp; = x_t(i) e^{\ep \wh\ell_t(i)}\\
x_{t+1}&amp;= \pa{1-\rc{\sqrt T}} \fc{y_{t+1}}{\ve{y_{t+1}}_1} + \rc{n \sqrt T}\one.
\end{align}
<p><strong>Question</strong>: wht’s the purpose of the <span class="math inline">\(x_t\)</span> update? To make sure every arm is played at least with some probability? (E.g. will be played infinitely many times.)</p>
<p>Get <span class="math inline">\(R_T\le O(\sqrt{Tn \ln n})\)</span>.</p>
<h3 id="ucb1">UCB1</h3>
<p>Stochastic setting.</p>
<p>“Optimism in the face of uncertainty.”</p>
<p><a href="https://jeremykun.com/2013/10/28/optimism-in-the-face-of-uncertainty-the-ucb1-algorithm/">Blog post</a>.</p>
<p>Algorithm: first play each once; then at each step play the action with highest upper confidence bound <span class="math display">\[j = \amax_j \ol x_j + \ub{\sfc{2\ln T}{n_j}}{a(n_j, T)}.
\]</span></p>
<p>UCB on MAB with <span class="math inline">\(K\)</span> actions where <span class="math inline">\(X_{i,t}\in [0,1], X_{i,t}\sim D_i\)</span> are independent, has expected cumulative regret, <span class="math inline">\(\ol x_{i,s}\)</span> the empirical mean after playing <span class="math inline">\(i\)</span> <span class="math inline">\(s\)</span> times, <span class="math display">\[ \E R(T) = O(\sqrt{KT \ln T}). \]</span></p>
<p><em>Proof.</em></p>
<ol type="1">
<li>Let <span class="math inline">\(\De_i = \mu^*-\mu_i\)</span>, <span class="math inline">\(P_i(T)\)</span> be the number of times <span class="math inline">\(i\)</span> is picked by time <span class="math inline">\(T\)</span>, <span class="math inline">\(I_t\)</span> be the <span class="math inline">\(t\)</span>th choice, <span class="math inline">\(a(s,t)\)</span> be the width of the CI at time <span class="math inline">\(t\)</span> after <span class="math inline">\(s\)</span> observations. Then
\begin{align}
\E G_A(T) &amp;= \sum_i \mu_i \E P_i(T)\\
\E P_i(T) &amp;= 1+\sum_{t=K}^T (I_t=i)\\
&amp;\le m + \sum_{t=K}^T (I_t=i\wedge P_i(t-1)\ge m)\\
&amp;\le m + \sum_{t=K}^T (U_i(t-1) \ge U^*(t-1), P_i(t-1)\ge m)\\
&amp;\le m + \sumo t{\iy} \sum_{s=m}^{t-1}\sum_{s'=1}^{t-1} (\ol x_{i,s} + a(s,t-1) \ge \ol x_{s'}^* + a(s',t-1))\\
&amp;\le \ff{8\ln T}{\De_i^2} + \sumo t{\iy} \sum_{s=m}^t \sum_{s'=1}^t 2t^{-4} = \fc{8\ln T}{\De_i^2} + 1 + \fc{\pi^2}{3}.
\end{align}
We chose <span class="math inline">\(m\)</span> so that <span class="math inline">\(\mu^* \ge \mu_i +2a(m,t)\)</span>. This implies either
\begin{align}
\ol x_{s'}^* &amp;\le \mu^* - a(s',t)\\
\ol x_{i,s} &amp; \ge \mu_i + a(s,t)
\end{align}
which happen with probabilities <span class="math inline">\(t^{-4}\)</span>.</li>
<li>This gives regret <span class="math display">\[\E R(T) \le \min(8 \sum_{i:\mu_i &lt;\mu^*} \fc{\ln T}{\De_i} + \pa{1+\fc{\pi^2}3}\pa{\sumo jK\De_j}, \max \De_i T).\]</span></li>
<li>Optimizing gives <span class="math inline">\(\De_i = O(\sqrt{\ln T})\)</span>.</li>
</ol>
<p>The idea is to upper bound by events that cover and we can better estimate. This involves summing over all <span class="math inline">\((s,s')\)</span>. The <span class="math inline">\(m\)</span> is introduced so that at that time <span class="math inline">\(\mu^*\)</span> and <span class="math inline">\(\mu_i\)</span> will be far enough apart.</p>
<h2 id="blo">BLO</h2>
<h3 id="scrible">SCRIBLE</h3>
<p>Attains <span class="math inline">\(O(\sqrt T\ln T)\)</span> regret.</p>
<h2 id="bco">BCO</h2>
<ul>
<li>[BE16] [paper](https://arxiv.org/pdf/1507.06580v1.pdf) <a href="http://www.jmlr.org/proceedings/papers/v49/bubeck16.pdf">JMLR version</a> - inefficient, <span class="math inline">\(\wt O(\poly(n)\sqrt T)\)</span>-regret algorithm.</li>
<li>[BEL16] [paper](https://arxiv.org/pdf/1607.03084.pdf) - <span class="math inline">\(\wt O(\poly(n)\sqrt T)\)</span>-regret and <span class="math inline">\(\poly(T)\)</span>-time algorithm.</li>
</ul>
<h3 id="fkm">FKM</h3>
<p>Generic reduction from BCO to (first-order) OCO by using gradient estimators. FKM is an instantiation of the algorithm with regret <span class="math inline">\(O(T^{\fc 34})\)</span>.</p>
<h2 id="contextual-bandits">Contextual bandits</h2>
<ul>
<li>EXP4 (adversarial) - Exponential weights for exploration and exploitation with expert advice. Do MWU with the experts. (Where does it use the context?)</li>
<li>[LCLS10] A Contextual-Bandit Approach to Personalized News Article Recommendation
<ul>
<li>Model: stochastic setting, at time <span class="math inline">\(t\)</span>, expected payoff of <span class="math inline">\(a\)</span> is linear in feature <span class="math inline">\(x_{t,a}\)</span> (given for all <span class="math inline">\(a\)</span>, in the simplest case they are equal over all <span class="math inline">\(a\)</span>), (<span class="math inline">\(\te_a^*\)</span> is the unknown coefficient vector) <span class="math display">\[ \E[r_{t,a}|x_{t,a}] = x_{t,a}^T\te_a^*.\]</span></li>
<li>Assume iid context and reward vectors. <!--(Did LCLS10 assume iid context?)--></li>
<li>Algorithm: LinUCB attains regret <span class="math inline">\(\wt O(\sqrt{KdT})\)</span>. Combine UCB with linear regression. (Think of linear functions as the “policy space”.)</li>
<li>Requires time at least linear in the number of arms.</li>
</ul></li>
<li>[DHKK] Efficient Optimal Learning for Contextual Bandits
<ul>
<li>Compare not to the best fixed policy (choosing the same arm), but best policy in some space <span class="math inline">\(\Pi\)</span>. (<strong>Question</strong>: what about comparing to best policy for other bandit problems? Ex. what’s the algorithm for vanilla MAB?)</li>
<li>Solves the contextual bandit problem for large policy spaces (in tie <span class="math inline">\(\poly\log(N)\)</span>, <span class="math inline">\(K\)</span> the number of arms, and achieves regret <span class="math inline">\(O(\sqrt{TK\ln N})\)</span>). (Complexity analysis assumes existence of argmax oracle (AMO) which gives <span class="math inline">\(\amax_{\pi\in \Pi} \sumo{t'}t r_{t'}(\pi(x_{t'}))\)</span>.</li>
<li>Idea:
<ul>
<li>Policy elimination (intractable)
<ul>
<li>Choose a distribution over the remaining experts that minimizes some kind of maximum variance.</li>
<li>Eliminate bad experts: all policies that are suboptimal by more than <span class="math inline">\(2b_t\)</span>. (NTS: whp the best policy remains, <span class="math inline">\(\pi_{\max}\in \Pi_t\)</span>, and remaing policies are good, <span class="math inline">\(\eta_D(\pi_{\max}) - \eta_D(\pi) \le 4b_t\)</span>.</li>
<li>Unbiased estimator of policy values <span class="math inline">\(\eta_t(\pi) = \rc{t} \sum \fc{r \one(\pi(x) = a)}{p}\)</span>.</li>
</ul></li>
<li>Randomized UCB (tractable given AMO; frequency of choosing, confidence bound determined by estimated regret)
<ul>
<li>Approximately minimize a certain variance. (Do this optimization problem with the argmax oracle. How?)</li>
<li>Smooth out distribution and play according to it.</li>
<li>No elimination here.</li>
</ul></li>
</ul></li>
<li><strong>Question</strong>: how about nonfinite sets - ex. VC dimension, Rademacher complexity?</li>
</ul></li>
</ul>
<p>Concrete Q: In the MAB setting, what if you compare to the best policy in a given set? I’m confused: can the policies have memory (depending on past results)? In this case, you can’t start following a policy midway. Let’s say they don’t. Now some policies may recommend the same action and some actions may not be recommended so scale accordingly.</p>
<p>A: Yes. See [ACFS02]; they get regret <span class="math inline">\(O((\ln N)^{\rc 2}\sqrt{T})\)</span> where <span class="math inline">\(N\)</span> is the number of strategies.</p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Generalization of neural nets</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/optimization/generalization.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/optimization/generalization.html</id>
    <published>2016-10-10T00:00:00Z</published>
    <updated>2016-10-10T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Generalization of neural nets</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-10-10 
          , Modified: 2016-10-10 
	</p>
      
       <p>Tags: <a href="/tags/neural%20nets.html">neural nets</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#rademacher-complexity">Rademacher complexity</a></li>
 <li><a href="#local-minima-generalization">Local minima generalization</a></li>
 <li><a href="#email">Email</a></li>
 </ul> </div>

  <div class="blog-main">
    <p>How can we show generalization error of neural networks is small?</p>
<h2 id="rademacher-complexity">Rademacher complexity</h2>
<p>The natural way to proceed is to calculate the Rademacher complexity of the neural net.</p>
<p><a href="http://www.jmlr.org/papers/volume3/bartlett02a/bartlett02a.pdf">BM02</a> give generalization bounds for 2-layer NN and say that it generalizes to more layers, but I’m not sure how. (There’s a “trivial” way of doing it with Lipschitzness which seems to grow exponentially with depth; I feel there may be a more natural way to do it with “composition”.)</p>
<p>Given the dimension of each layer, a Lipschitz sigmoid/threshold function, and a bound on the size of the coefficients, what are the bounds we get from Rademacher complexity? How are they unsatisfactory? (Ex. in practical cases, is the sample size too small? Is it, e.g., a difference between a sample of polynomial size and linear size, or something larger?)</p>
<h2 id="local-minima-generalization">Local minima generalization</h2>
<p>I thought a bit about whether local optima would generalize. Do you have any intuitions regarding why? This is meaningful if it generalizes with fewer samples than one would calculate from e.g. Rademacher complexity. (My first thought is that having derivative 0 in all directions (and also nonnegative Hessian) is much less likely to happen by chance than the value being small.)</p>
<p>Also, is the right statement “under xx conditions whp all local optima generalize”? Given that there may be many local optima it seems there’s likely to be some (most) local optima that generalize well and some that don’t; perhaps it takes much fewer samples to have “most” local minima generalize. However, this seems a much more difficult statement to work with (ex. of the type people have been trying to get intuition from statistical physics). Perhaps we also need to tie it to the SGD algorithm in some way.</p>
<h2 id="email">Email</h2>
<p>I thought a bit about your suggestion that local optima would generalize. Do you have any intuitions regarding why or what a statement of this would be like?</p>
<p>Here are some preliminary thoughts/questions I had.</p>
<ul>
<li>Focusing on neural networks: Rademacher complexity would give a baseline for generalization. Given the dimension of each layer, a Lipschitz sigmoid/threshold function, and a bound on the size of the coefficients, what are the bounds we get from Rademacher complexity? How are they unsatisfactory? (Ex. in practical cases, is the sample size too small? Is it, e.g., a difference between a sample of polynomial size and linear size, or something larger?) <a href="http://www.jmlr.org/papers/volume3/bartlett02a/bartlett02a.pdf">BM02</a></li>
<li>Saying that local min generalizes is significant if it generalizes with fewer samples than one would calculate from e.g. Rademacher complexity.</li>
<li>Is the right statement “under xx conditions whp all local optima generalize”? Given that there may be many local optima it seems there’s likely to be some (most) local optima that generalize well and some that don’t; perhaps it takes much fewer samples to have “most” local minima generalize. However, this seems a much more difficult statement to work with (ex. of the type people have been trying to get intuition from statistical physics). Perhaps we need to tie it to the SGD algorithm in some way.</li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>

</feed>
