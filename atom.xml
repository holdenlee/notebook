<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Research Notebook</title>
    <link href="http://holdenlee.github.io/notebook/atom.xml" rel="self" />
    <link href="http://holdenlee.github.io/notebook" />
    <id>http://holdenlee.github.io/notebook/atom.xml</id>
    <author>
        <name>Holden Lee</name>
        <email>oldheneel@gmail.com</email>
    </author>
    <updated>2016-09-30T00:00:00Z</updated>
    <entry>
    <title>[WJ08] Graphical Models, Exponential Families, and Variational Inference</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/probabilistic/graphical_models.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/probabilistic/graphical_models.html</id>
    <published>2016-09-30T00:00:00Z</published>
    <updated>2016-09-30T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>[WJ08] Graphical Models, Exponential Families, and Variational Inference</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-09-30 
          , Modified: 2016-09-30 
	</p>
      
       <p>Tags: <a href="/tags/probabilistic%20models.html">probabilistic models</a>, <a href="/tags/graphical%20models.html">graphical models</a>, <a href="/tags/exponential%20families.html">exponential families</a>, <a href="/tags/variational%20inference.html">variational inference</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#introduction">1 Introduction</a></li>
 <li><a href="#graphical-models">2 Graphical models</a></li>
 <li><a href="#exponential-families">3 Exponential families</a></li>
 <li><a href="#bethe-approximation-and-sum-product-algorithm">4 Bethe approximation and sum-product algorithm</a></li>
 <li><a href="#mean-field-methods">5 Mean field methods</a></li>
 <li><a href="#variational-methods-in-parameter-estimation">6 Variational methods in parameter estimation</a></li>
 <li><a href="#variational-methods-based-on-convex-relaxations">7 Variational methods based on convex relaxations</a></li>
 <li><a href="#mode-computation">8 Mode computation</a></li>
 <li><a href="#conic-programming-relaxations">9 Conic programming relaxations</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="introduction">1 Introduction</h2>
<p>Inference: computing marginal probabilities.</p>
<h2 id="graphical-models">2 Graphical models</h2>
<h2 id="exponential-families">3 Exponential families</h2>
<h2 id="bethe-approximation-and-sum-product-algorithm">4 Bethe approximation and sum-product algorithm</h2>
<h2 id="mean-field-methods">5 Mean field methods</h2>
<h2 id="variational-methods-in-parameter-estimation">6 Variational methods in parameter estimation</h2>
<h2 id="variational-methods-based-on-convex-relaxations">7 Variational methods based on convex relaxations</h2>
<h2 id="mode-computation">8 Mode computation</h2>
<h2 id="conic-programming-relaxations">9 Conic programming relaxations</h2>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Reinforcement learning</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/reinforcement_learning/rl.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/reinforcement_learning/rl.html</id>
    <published>2016-09-28T00:00:00Z</published>
    <updated>2016-09-28T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Reinforcement learning</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-09-28 
          , Modified: 2016-09-28 
	</p>
      
       <p>Tags: <a href="/tags/reinforcement%20learning.html">reinforcement learning</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#references">References</a></li>
 <li><a href="#section">3</a></li>
 <li><a href="#dynamic-programming">4 Dynamic programming</a></li>
 <li><a href="#monte-carlo-methods">5 Monte Carlo methods</a></li>
 <li><a href="#temporal-difference-learning">6 Temporal-difference learning</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="references">References</h2>
<ul>
<li>Barton, Sutto.</li>
<li>Algorithms course Lecture 8</li>
<li>…</li>
</ul>
<h2 id="section">3</h2>
<p>Bellman optimality equations</p>
\begin{align}
v_*(s) &amp;= \max_\pi v_\pi(s)\\
q_*(s,a) &amp;= \max_\pi q_\pi(s,a)\\
v_*(s)&amp;= \max_{a\in \mathcal A(s)} \sum_{s'} p(s'|s,a) [r(s,a,s') + \ga v_*(s')\\
q_*(s) &amp;= \sum_{s'} p(s'|s,a) [r(s,a,s') +\ga \max q_*(s',a')].
\end{align}
<p>3 assumptions that are rarely all true in practice:</p>
<ol type="1">
<li>Know dynamics of environment</li>
<li>Have enough computational resources</li>
<li>Markov property</li>
</ol>
<p>Many decision-making methods attempt to approximately solve the Bellman optimal equations.</p>
<p>A RL algorithm puts more effort into learning good decisions for frequently encountered states.</p>
<h2 id="dynamic-programming">4 Dynamic programming</h2>
<p>Three classes of methods for solving MDP’s.</p>
<ol type="1">
<li>Dynamic programming
<ul>
<li>Well-developed mathematically</li>
<li>Require complete, accurate model of environment</li>
</ul></li>
<li>Monte Carlo methods
<ul>
<li>Don’t require model, conceptually simple</li>
<li>Not suitable for incremental computation</li>
</ul></li>
<li>Temporal-difference learning
<ul>
<li>Don’t require model, fully incremental</li>
<li>Complex to analyze</li>
</ul></li>
</ol>
<p>Think of other methods as attempts to achieve the same effect as DP with less computation and without a perfect model.</p>
<p>Use value functions to organize the search for good policies.</p>
<p>Iterative <strong>policy evaluation</strong>: (make value function consistent with current policy) <span class="math display">\[
v_{k+1}(s) = \sum_a \pi(a|s) \sum_{s'} p(s'|s,a) [r(s,a,s') + \ga v_k(s')].
\]</span> This is a full backup because we calculate <span class="math inline">\(v_k(s)\)</span> for all <span class="math inline">\(s\)</span> in each stage. (TODO: prove convergence.) Stop when maximum difference <span class="math inline">\(\max_{s\in S}|v_{k-1}(s)-v_k(s)|&lt;\te\)</span>.</p>
<p>(Can also update in-place. Then update order makes a difference.)</p>
<p><strong>Policy improvement theorem</strong>. If <span class="math inline">\(\pi,\pi'\)</span> are deterministic policies such that for all <span class="math inline">\(s\in S\)</span>, <span class="math display">\[q_\pi(s,\pi'(s))\ge v_\pi(s),\]</span> then <span class="math inline">\(\pi'\)</span> is at least as good as <span class="math inline">\(\pi\)</span>, <span class="math inline">\(v_{\pi'}(s) \ge v_\pi(s)\)</span>.</p>
<p><em>Proof</em>. Unfold and note convergence.</p>
<p>This shows that iterative policy improvement can only help: <span class="math display">\[
\pi'(s) = \amax_a \sum_{s'} p(s'|s,a) [r(s,a,s') + \ga v_\pi(s')].
\]</span> If it stops improving, then <span class="math inline">\(\pi'\)</span> is optimal.</p>
<p>Policy iteration: <span class="math inline">\(\pi_k\xra E v_{\pi_k} \xra I \pi_{k+1}\)</span>. Alternately evaluate and improve.</p>
<!-- assuming we know p's-->
<!-- Value iteration is when policy evaluation is stopped after one sweep.-->
<p>Above, to evaluate, we have to keep doing policy iterations until convergence. For speed, we just do one (or a few) step of policy evaluation. Combining the improvement and evaluation steps: <span class="math display">\[v_{k+1} := \max_a \sum_{s'} p(s'|s,a)[r(s,a,s') + \ga v_k(s')].\]</span> (cf. EM/AM?)</p>
<!-- Q: if this stabilizes, does it mean we have converged? p. 100-->
<p>Asynchronous DP: back up values of states in any order, using whatever values of other states are available. Can do with value iteration and policy iteration. Helps intermix computation with interaction (actually experiencing MDP—apply backups as agent visits states).</p>
<p>The time that DP methods take is polynomial in number of states and actions. LP can be used to solve MDP’s but become impractical at smaller number of states than DP.</p>
<!-- can such iterative methods solve LP? -->
<h2 id="monte-carlo-methods">5 Monte Carlo methods</h2>
<p>Don’t assume complete knowledge of the environment. Learn from online and simulated experience. The model only needs to generate sample transitions rather than give a complete probability distribution.</p>
<p>MC assumes experience is divided into episodes.</p>
<p>Each occurrence of a state in an episode is a <em>visit</em>.</p>
<ul>
<li>Every-visit MC: estimate <span class="math inline">\(v_\pi(s)\)</span> as the average of returns following all visits to <span class="math inline">\(s\)</span></li>
<li>First-visit MC: average just returns following first visits (in an episode) to <span class="math inline">\(s\)</span>.</li>
</ul>
<p>DP shows all possible transitions but the MC diagram only shows those sampled on one episode.</p>
<p>(Ex. of finding bubble surface given wire frame. Iterative = compute surface iteratively by averaging at each point. MC = take a random walk from each point; expected height at boundary is approximation of height. This is more efficient if we are interested in a small number of points.)</p>
<p>If the model is not available, it’s mre useful to estimate action than state values. (From the action-value function <span class="math inline">\(q\)</span> we can directly construct the greedy policy.)</p>
<p>Problem: if you follow a deterministic policy, you will only observe one action from each state.</p>
<p>Solution: Explore! Assume each state-action pair has a nonzero probability of being selected at the start of an episode (exploring starts). More realistic: consider policies that are stochastic with nonzero probability of selecting all actions.</p>
<p>This works assuming:</p>
<ol type="1">
<li>episodes have exploring starts</li>
<li>policy evaluation can be done with infinitely many episodes.
<ul>
<li>Instead: approximate and keep track of error bounds. But this requires many episodes.</li>
<li>Forgo policy evaluation: move value function toward <span class="math inline">\(q_{\pi_k}\)</span>.</li>
</ul></li>
</ol>
<p>MC ES cannot converge to any suboptimal policy (if it did, the value function converges to the value function for that policy, and the policy changes). <em>Open question</em>: does it always converge? [Tsitsiklis02]</p>
<p>5.4 On-policy MC control</p>
<p>Improve the policy used to make decisions.</p>
<p>Soft policy: <span class="math inline">\(\forall s,a\in \mathcal A(s), \pi(a|s)&gt;0\)</span>. <span class="math inline">\(\ep\)</span>-soft: <span class="math inline">\(\ge \fc{\ep}{|\mathcal A(s)|}\)</span>.</p>
<p>Policy iterations works for <span class="math inline">\(\ep\)</span>-soft policies.</p>
<ol type="1">
<li>The policy improvement theorem shows that for any <span class="math inline">\(\ep\)</span>-soft <span class="math inline">\(\pi\)</span>, the <span class="math inline">\(\ep\)</span>-greedy policy wrt <span class="math inline">\(q_\pi\)</span> is at least as good as <span class="math inline">\(\pi\)</span>.</li>
<li>Equality only when both <span class="math inline">\(\pi,pi'\)</span> are optimal among <span class="math inline">\(\ep\)</span>-soft. Use optimality for all policies, under the modified environment where an action is chosen randomly with probability <span class="math inline">\(\ep\)</span>.</li>
</ol>
<p>5.5 Evaluating One PolicyWhile Following An-other (Off-policy Policy Evaluation)</p>
<p>What if we have episodes generated from a different policy?</p>
<ul>
<li><span class="math inline">\(\mu\)</span> behavior policy</li>
<li><span class="math inline">\(\pi\)</span> target policy.</li>
</ul>
Require ratio <span class="math inline">\(\pi/\mu\)</span> not be too large. Weight episodes by this ratio.
\begin{align}
V(s) &amp;= \fc{\sumo i{n_s} \fc{p_i(s)}{p_i'(s)}G_i(s)}{\sumo i{n_s} \fc{p_i(s)}{p_i'(s)}}\\
\fc{p_i(S_t)}{p_i'(S_t)}&amp;=\prod_{k=t}^{T_i(S_t)-1} \fc{\pi(A_k|S_k)}{\mu(A_k|S_k)}.
\end{align}
<p>5.6 Off-policy MC control</p>
<p>Ex. estimation policy may be deterministic while behavior policy samples all possible actions.</p>
<p>To do this, after generating an episode, look at the last time where <span class="math inline">\(A_\tau \ne \pi(S_\tau)\)</span>, and update <span class="math inline">\(Q\)</span> using pairs <span class="math inline">\((s,a)\)</span> appearing after that time.</p>
<p>Note: only learns from tails of episodes. Learning is slow if nongreedy actions are frequent.</p>
<p>5.7 Incremental implementation</p>
For <span class="math inline">\(V_n=\fc{\sumo k{n-1}W_kG_k}{\sumo k{n-1}W_k}\)</span> is
\begin{align}
V_{n+1} &amp;=V_n+\fc{W_n}{C_n} (G_n-V_n)\\
C_{n+1} &amp;=C_n+W_{n+1}.
\end{align}
<p>Advantages of MC:</p>
<ol type="1">
<li>learn optimal behavior directly from interaction without model</li>
<li>used with simulation</li>
<li>focus MC on small subset of states</li>
<li>less harmed by violations of Markov property.</li>
</ol>
<p>Maintaining sufficient exploration is an issue.</p>
<p>MC uses experience and does not bootstrap (update value based on other value estimates) (instead MC waits for a bunch of samples), unlike DP.</p>
<p>Next chapter: experience + bootstrap.</p>
<h2 id="temporal-difference-learning">6 Temporal-difference learning</h2>
<p>MC methods can incrementally update <span class="math inline">\(V\)</span>, after waiting to get the actual return, <span class="math display">\[V(S_t) \mapsfrom V(S_t) + \al [G_t-V(S_t)].\]</span> (n.b. <span class="math inline">\(S_t\)</span> is the state at time <span class="math inline">\(t\)</span>, not the state labeled <span class="math inline">\(t\)</span>.) TD methods only wait until the next time step. <span class="math display">\[V(S_t) \mapsfrom V(S_t) + \al [R_{t+1} + \ga V(S_{t+1})-V(S_t)].
\]</span> I.e., it uses the estimate of <span class="math inline">\(v_\pi = \EE_\pi [R_{t+1}+\ga v_\pi(S_{t+1})|S_t=s]\)</span> as a target.</p>
<p>TD samples expected values and uses the current estimate <span class="math inline">\(V\)</span> instead of <span class="math inline">\(v_\pi\)</span>.</p>
<p>Ech estimate is shifted towards the estimate that immediately follows it.</p>
<p>p. 133: driving home example.</p>
<p>In practice, TD methods converge faster than constant-<span class="math inline">\(\al\)</span> MC methods on stochastic tasks.</p>
<p>6.3 Optimality of TD(0)</p>
<p>Finite amount of experience: present it repeatedly until method converges. (cf. SGD?) Do batch updates.</p>
<p>Ex. p.139 example is enlightening.</p>
<p>Batch Monte Carlo methods always find the estimates that minimize mean-squared error on the training set, whereas batch TD(0) always finds the estimates that would be exactly correct for the maximum-likelihood model of the Markov process.</p>
<!-- ? certainty-equivalence estimate-->
<p>6.4 Sarsa: On-policy TD control</p>
<p>For state-action pairs: <span class="math display">\[Q(S_t,A_t) \mapsfrom Q(S_t,A_t) + \al [R_{t+1} + \ga Q(S_{t+1}, A_{t+1})-Q(S_t,A_t)].
\]</span> (<span class="math inline">\(A_{t+1}\)</span> is the action chosen by the (<span class="math inline">\(\ep\)</span>-greedy?<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>) policy on <span class="math inline">\(S_{t+1}\)</span>.) SARSA refers to <span class="math inline">\((S_t,A_t,R_{t+1},S_{t+1},A_{t+1})\)</span>.</p>
<p>(Convergence guarantees: p. 142)</p>
<p>SARSA can learn during the episode!</p>
<p>6.5 Q-learning: Off-policy TD control</p>
<p>One-step Q-learning</p>
<p><span class="math display">\[
Q(S_t,A_t)\leftarrow Q(S_t,A_t) + \al [R_{t+1} + \ga \max_a Q(S_{t+1},a) - Q(S_t,A_t)].
\]</span></p>
<p><span class="math inline">\(Q\)</span> approximates the optimal <span class="math inline">\(q_*\)</span> <em>independently of the policy being followed</em>!</p>
<p>TODO: prove this. [Watkins Dayan 1992] [JJS94] [T94]</p>
<p>Ex. cliff</p>
<ul>
<li>SARSA learns the safe path steering clear of the cliff (because it takes account the <span class="math inline">\(\ep\)</span>-greedy exploration).</li>
<li>Q-learning learns the short path at the edge of the cliff (the optimal).</li>
</ul>
<p>6.6 Games</p>
<p>A conventional state-value function evaluates states in which the agent has the option of selecting an action (arrived at <span class="math inline">\(s'\)</span> where you will select a new <span class="math inline">\(a'\)</span>), but the state-value function in games of perfect information evaluates the board after the agent has mades its move—afterstates.</p>
<p>This is more efficient: many position-move pairs produce the same resulting position.</p>
<p>Often it’s useful to break the environment’s dynamics into</p>
<ul>
<li>immediate effect of action (deterministic) and</li>
<li>unknown random processes.</li>
</ul>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Why not greedy?<a href="#fnref1">↩</a></p></li>
</ol>
</section>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>[PMDH16] Convolutional Patch Representations for Image Retrieval - an Unsupervised Approach</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/neural_nets/PMDH16.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/neural_nets/PMDH16.html</id>
    <published>2016-09-26T00:00:00Z</published>
    <updated>2016-09-26T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>[PMDH16] Convolutional Patch Representations for Image Retrieval - an Unsupervised Approach</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-09-26 
          , Modified: 2016-09-26 
	</p>
      
       <p>Tags: <a href="/tags/neural%20net.html">neural net</a>, <a href="/tags/vision.html">vision</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#background">Background</a></li>
 </ul> </div>

  <div class="blog-main">
    <p>We write things in the continuous limit. In actuality we have to discretize.</p>
Define the kernel <span class="math inline">\(K:(\Om \to \R)\times (\Om\to \R) \to \R\)</span> by
\begin{align}
K(M,M') = \sum_{z,z'\in \Om} e^{-\rc{2\be^2}\ve{z-z'}^2} \ka (P_z, P_{z'}')\\
\ka(P_z,P_{z'}') &amp; = \ve{P_z}\ve{P_{z'}'} e^{-\rc{2\al^2} \ve{\wt P_z - \wt P_{z'}^2}^2
\end{align}
<p>where <span class="math inline">\(P_z =M_{z+[0,e)\times [0,e)\times [0,d)}\)</span>.</p>
<h2 id="background">Background</h2>
<p>A <a href="https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space">reproducing kernel Hilbert space (RKHS)</a> is a Hilbert space of functions <span class="math inline">\(X\to \R\)</span> in which point evaluation <span class="math inline">\(L_x[f] = f(x)\)</span> is a continuous linear functional. (Equivalently, it is bounded, <span class="math inline">\(f(x)\le M_x\ve{f}_H\)</span>.</p>
<ul>
<li><span class="math inline">\(L^2\)</span> is not a RKHS—it consists of equivalence classes of functions.</li>
<li><span class="math inline">\(H=\set{f\in L_2(\R)}{\Supp(\phi)\subeq [-a,a]}\)</span> is RKHS. Here <span class="math inline">\(K_x(y) = \fc{\sin(a(y-x))}{\pi(y-x)}\)</span> (bandlimited Dirac delta).</li>
</ul>
<p><strong>Theorem</strong> A Hilbert space of functions is a RKHS iff for every <span class="math inline">\(x\in X\)</span>, there exists <span class="math inline">\(K_x\)</span> such that <span class="math inline">\(g(x) = \an{g, K_x}\)</span>.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<p><em>Proof</em>. <span class="math inline">\(\Leftarrow\)</span>: inner product is continuous. <span class="math inline">\(\Rightarrow\)</span>: Riesz representation.</p>
<p>Note <span class="math inline">\(K_x(y) = \an{K_x,K_y}=:K(x,y)\)</span>. <span class="math inline">\(K\)</span> is symmetric and positive definite. (Think of <span class="math inline">\(K\)</span> as <span class="math inline">\(X_0^\R\times X_0^\R\to \R\)</span> where <span class="math inline">\(X_0^\R\)</span> is the set of functions <span class="math inline">\(X\to \R\)</span> nonzero only at a finite number of <span class="math inline">\(x\)</span>’s. I.e. formal span of <span class="math inline">\(X\)</span>.)</p>
<p><a href="https://en.wikipedia.org/wiki/Representer_theorem">Representer theorem</a> states that every function in an RKHS that minimises an empirical risk function can be written as a linear combination of the kernel function evaluated at the training points</p>
<p><strong>Theorem (Moore-Aronszajn)</strong>. Suppose <span class="math inline">\(K\)</span> is a symmetric, positive definite kernel on a set <span class="math inline">\(X\)</span>. Then there is a unique Hilbert space of functions on <span class="math inline">\(X\)</span> for which <span class="math inline">\(K\)</span> is a reproducing kernel.</p>
<p><em>Proof</em>. Extend <span class="math inline">\(K\)</span> by bilinearity to <span class="math inline">\(\spn(X)\)</span>. Take the completion. (Extend to functions <span class="math inline">\(f=\sumo i{\iy} a_i K_{x_i}(x)\)</span> where <span class="math inline">\(\sumo i{\iy} a_i^2 K(x_i,x_i)\)</span>.</p>
<p>(Question: how to realize this inner product as an integral?)</p>
<p>See also: Mercer’s theorem</p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Letting <span class="math inline">\(f_x=\delta_x\)</span> is cheating—we want actual functions, not distributions.<a href="#fnref1">↩</a></p></li>
</ol>
</section>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Weekly summary 2016-10-01</title>
    <link href="http://holdenlee.github.io/notebook/posts/summaries/2016-10-08.html" />
    <id>http://holdenlee.github.io/notebook/posts/summaries/2016-10-08.html</id>
    <published>2016-09-26T00:00:00Z</published>
    <updated>2016-09-26T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Weekly summary 2016-10-01</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-09-26 
          , Modified: 2016-09-26 
	</p>
      
       <p>Tags: <a href="/tags/none.html">none</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#threads">Threads</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="threads">Threads</h2>
<ul>
<li>PMI - get some results!</li>
<li>SoS - lectures 2 and 3</li>
<li>DL: do experiments suggested in <a href="/posts/tcs/machine_learning/matrices/DL_generalization.html">DL generalization</a>
<ul>
<li>(*) NN learns DL.</li>
<li>DL generalizations.</li>
</ul></li>
<li>Papers
<ul>
<li><a href="http://www.research.rutgers.edu/~lihong/pub/Li10Contextual.pdf">LCLS10 A Contextual-Bandit Approach to Personalized News Article Recommendation</a></li>
<li><a href="http://www.cs.columbia.edu/~djhsu/papers/amo.pdf">DHKK Efficient Optimal Learning for Contextual Bandits</a></li>
<li><a href="http://www.cs.columbia.edu/~djhsu/papers/poshmm-tacl.pdf">SCH Unsupervised Part-Of-Speech Tagging with Anchor Hidden Markov Models</a></li>
<li><a href="http://www.cs.columbia.edu/~djhsu/papers/hmm-jcss-final.pdf">A spectral algorithm for learning Hidden Markov Models</a></li>
</ul></li>
<li>Stability of SGD
<ul>
<li>@Elad: do local minima generalize?</li>
</ul></li>
<li>Graphical models reading</li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Weekly summary 2016-10-01</title>
    <link href="http://holdenlee.github.io/notebook/posts/summaries/2016-10-01.html" />
    <id>http://holdenlee.github.io/notebook/posts/summaries/2016-10-01.html</id>
    <published>2016-09-26T00:00:00Z</published>
    <updated>2016-09-26T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Weekly summary 2016-10-01</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-09-26 
          , Modified: 2016-09-26 
	</p>
      
       <p>Tags: <a href="/tags/none.html">none</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#threads">Threads</a></li>
 <li><a href="#meeting-with-arora">Meeting with Arora</a></li>
 <li><a href="#thoughts-about-pmi">Thoughts about PMI</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="threads">Threads</h2>
<ul>
<li>PMI - get some results!</li>
<li>CKN - understood theory, RKHS (9/26)</li>
<li>SoS - lectures 2 and 3</li>
<li>DL: do experiments suggested in <a href="/posts/tcs/machine_learning/matrices/DL_generalization.html">DL generalization</a>
<ul>
<li>NN learns DL? Preliminary calculations.</li>
</ul></li>
<li>Stability of SGD
<ul>
<li>@Elad: do local minima generalize?</li>
</ul></li>
<li>RL and cousins: see below. <a href="/posts/tcs/machine_learning/reinforcement_learning/rl.html">Notes</a></li>
</ul>
<h2 id="meeting-with-arora">Meeting with Arora</h2>
<p>Directions</p>
<ul>
<li>Learning noisy or-nets with 3-tensors (<span class="math inline">\(n^4\)</span> time) (<span class="citation" data-cites="Andrej">@Andrej</span>, <span class="citation" data-cites="Tengyu">@Tengyu</span>)</li>
<li>Matrix factorization assuming separability</li>
<li>Mike Collins NLP. Words as features.
<ul>
<li>Logliear/NN</li>
<li>For bigram classifiers, it’s fine to use word embeddings. (<span class="citation" data-cites="Tengyu">@Tengyu</span>)</li>
</ul></li>
<li>Systems with memory
<ul>
<li>Learning HMM’s with tensor methods</li>
<li>Reinforcement learning (MDP’s)
<ul>
<li>Theoretical algorithms are polynomial in state size and mixing time.</li>
<li>What if we have a succinct reprsentation? <span class="citation" data-cites="Mengdi">@Mengdi</span> Wang. Vector in <span class="math inline">\(\R^n\)</span>.
<ul>
<li>Stochastic Primal-Dual Methods and Sample Complexity of Markov Decision Process. (recent results on learning in MDPs via a primal-dual approach, and new ideas on finding compact representations of MDPs via low-rank approximation.)</li>
</ul></li>
</ul></li>
<li>cf. contextual bandits (<span class="citation" data-cites="Elad">@Elad</span>, <span class="citation" data-cites="Karan">@Karan</span>)
<ul>
<li><a href="http://www.research.rutgers.edu/~lihong/pub/Li10Contextual.pdf">LCLS10 A Contextual-Bandit Approach to Personalized News Article Recommendation</a></li>
<li><a href="http://www.cs.columbia.edu/~djhsu/papers/amo.pdf">DHKK Efficient Optimal Learning for Contextual Bandits</a></li>
<li><a href="http://www.cs.columbia.edu/~djhsu/papers/poshmm-tacl.pdf">SCH Unsupervised Part-Of-Speech Tagging with Anchor Hidden Markov Models</a></li>
<li><a href="http://www.cs.columbia.edu/~djhsu/papers/hmm-jcss-final.pdf">A spectral algorithm for learning Hidden Markov Models</a></li>
</ul></li>
</ul></li>
<li>Representation learning
<ul>
<li>Is PCA/SVD “complete” for classification? <a href="https://www.quora.com/How-can-PCA-be-used-as-a-pre-processing-step-for-classification">PCA as preprocessing for classification</a></li>
</ul></li>
<li>PMI for images
<ul>
<li>How is it NMF? (<span class="citation" data-cites="Tengyu">@Tengyu</span>)</li>
</ul></li>
<li>Dictionary learning
<ul>
<li>Relax incoherence. Only correlated with <span class="math inline">\(n^\de\)</span> others.</li>
<li>@Elad: Training on top of improperly learned dictionary.</li>
</ul></li>
</ul>
<h2 id="thoughts-about-pmi">Thoughts about PMI</h2>
<p>(9/28)</p>
<p>In the CKN, given that one layer is <span class="math inline">\(x\)</span>, the next layer (before pooling) is computed as <span class="math inline">\(y_i=(e^{v_i^x+b_i})_i\)</span> for some <span class="math inline">\(v_i,b_i\)</span>. We have that the dimension of <span class="math inline">\(y\)</span> is larger than the dimension of <span class="math inline">\(x\)</span>.</p>
<p>This looks very much like in PMI for word vectors, where the probability of word with vector <span class="math inline">\(v\)</span> given context <span class="math inline">\(x\)</span> is <span class="math inline">\(e^{-v^Tx}\)</span>, and the low-rank approximation to the PMI matrix recovers the <span class="math inline">\(v\)</span>’s.</p>
<p>But does that mean applying weighted SVD for PMI for the CKN feature vectors is somehow just trying to recover the <span class="math inline">\(v_i\)</span>? In that case the dimension reduction would just be going from <span class="math inline">\(y\)</span> back to <span class="math inline">\(x\)</span>, which doesn’t help classification.</p>
<p>(This doesn’t take into account the Gaussian pooling though.)</p>
<p>What would be the “test” for interpretability? For word embeddings, the test was analogy completion.</p>
<p>If the PMI matrix is low-rank, then what do we get beyond the fact that the feature vectors (7200-dim) came from a lower-dimensional (28x28) space? (In what sense would we expect the dimension-reduced feature vectors to be more interpretable than the original image?)</p>
<p>TODO:</p>
<ul>
<li>Try thresholding + WSVD + SVM.</li>
<li>Do pipeline (data exploration) with other MNIST and CIFAR architectures.</li>
<li>Think about the interpretability test above.</li>
<li><span class="citation" data-cites="Tengyu">@Tengyu</span> on interpreting CKN as NMF.</li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Semantic shared response</title>
    <link href="http://holdenlee.github.io/notebook/posts/cs/semantic_shared_response.html" />
    <id>http://holdenlee.github.io/notebook/posts/cs/semantic_shared_response.html</id>
    <published>2016-09-24T00:00:00Z</published>
    <updated>2016-09-24T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Semantic shared response</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-09-24 
          , Modified: 2016-09-24 
	</p>
      
       <p>Tags: <a href="/tags/neuroscience.html">neuroscience</a></p> 
    </div>
    
  </div>
  <!--/div-->

  

  <div class="blog-main">
    <p>fMRI: <span class="math inline">\(10^5\)</span> <span class="math inline">\((3mm)^3\)</span> voxels, measuring blood flow.</p>
<h2 id="prior-work">Prior work</h2>
<ul>
<li>Mitchell 08: pictures of concrete nouns</li>
<li>Naselaris 09: images of scenes</li>
<li>Pereira 11: generating words</li>
<li>N11: reconstruct movie images</li>
<li>Wehbe 14: chapter of Harry Potter (cf. speed reading)</li>
<li>Huth 16: auditory stories</li>
</ul>
<h2 id="goal">Goal</h2>
<ul>
<li>Decode fMRI response semantics. Match fMRI responses to annotations
<ul>
<li>Sherlock scenes annotated. 2000 scenes.</li>
</ul></li>
<li>Leverage multiple subject views to extract better semantics. (16 subjects)</li>
</ul>
<h2 id="methods">Methods</h2>
<ul>
<li>Pick a few brain regions to focus on. Ex. default node network (2006): related to narrative.
<ul>
<li>Hypothesis: this region does the best.</li>
<li><span class="math inline">\(\approx 2000\)</span> voxels for each mask. (Masks are a small part of <span class="math inline">\(10^5\)</span>.)</li>
</ul></li>
<li>Shared response model <span class="math display">\[\amin_{W^TW = I;S} \sumo ik \ve{X_i-W_iS}_F.\]</span> (Columns of <span class="math inline">\(W\)</span> orthogonal. voxels<span class="math inline">\(\times\)</span>features (<span class="math inline">\(2000 \times 20\)</span>)) <!-- features x times -->
<ul>
<li>Probabilistic model <span class="math inline">\(s_t\sim N(0,\Si_s)\)</span>. <span class="math inline">\(x_{it}|s_t\sim N(W_is_t+\mu_i, \rh_i^2I)\)</span>.</li>
</ul></li>
</ul>
<p>Distributional hypothesis of meaning: meaning comes from co-occurrence.</p>
<p>We have multiple words in each annotation. Approaches:</p>
<ul>
<li>Unweighted: Averaging</li>
<li>Weighted: By inverse of frequency</li>
</ul>
<p>(Note: words have different meanings. Use DL to split up words into atoms. Ignores polysemy.)</p>
<p>Let <span class="math inline">\(A=\)</span>fMRI, <span class="math inline">\(B=\)</span>text. We learn a linear map <span class="math inline">\(\Om A\approx B\)</span>. We can vary the way we constrain the maps.</p>
<!--OLS-->
<ol type="1">
<li><span class="math inline">\(\Om\)</span> orthogonal.</li>
<li><p>Ridge regression (penalizes by norm of columns).</p></li>
<li>20 dimensional SRM vs. averaging</li>
<li>Weighted vs. unweighted</li>
<li>Procrustes vs. ridge</li>
<li><p>Temporal average subtraction vs. not.</p></li>
</ol>
<p>Annotation vectors 1000-dimensional.</p>
<p>Is true chunk in top 5? (See table in paper.)</p>
<!--
| Mask | Performance |
|---|---|
|DMN| -->
<p>Average, else correlated</p>
<!--
Cathy - Cog neuro, Ken Norman
Zach - Implementation, why does wordvec work?
Howard - combine word vecs to word sequence vectors.
Julie - translate scenes into numbers, word vectors.
Shefali

Learning relations from text.
-->
<p>Model</p>
<ol type="1">
<li>Unweighted <span class="math inline">\(\Pj(w|c) = \fc{\exp(v_w^T c)}{Z}\)</span>.</li>
<li>Weighted <span class="math inline">\(\Pj(w|c) = \al p(w) + (1-\al) \fc{\exp(v_w^T c)}{Z}\)</span>, <span class="math inline">\(\al\in [0,1]\)</span>. (Ex. more accurate for common words.)</li>
</ol>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Weekly summary 2016-09-24</title>
    <link href="http://holdenlee.github.io/notebook/posts/summaries/2016-09-24.html" />
    <id>http://holdenlee.github.io/notebook/posts/summaries/2016-09-24.html</id>
    <published>2016-09-23T00:00:00Z</published>
    <updated>2016-09-23T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Weekly summary 2016-09-24</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-09-23 
          , Modified: 2016-09-23 
	</p>
      
       <p>Tags: <a href="/tags/none.html">none</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#threads">Threads</a></li>
 </ul> </div>

  <div class="blog-main">
    <p><a href="2016-09-17.html">Last week</a>.</p>
<h2 id="threads">Threads</h2>
<ul>
<li>PMI: WSVD + DL/NMF. <a href="/posts/tcs/machine_learning/neural_nets/pmi_images.html">PMI for images</a>
<ul>
<li>Used NMF code from <a href="http://www.ee.columbia.edu/~grindlay/code.html">here</a>.</li>
</ul></li>
<li><a href="/posts/tcs/machine_learning/matrices/DL_generalization.html">DL generalization</a>
<ul>
<li>Can we tackle NMF using similar algorithm as DL—trying to isolate a column of A by looking at samples which are close to a pair of samples? Before, closeness was inner product; now use another kernel? Ex. TV distance, or KL, or some kind of regularized KL. Ex.
<ul>
<li>In what sense is this important? I would still rely on a distributional assumption on the <span class="math inline">\(x\)</span>’s. (DL algorithm required this: sparsity and some kind of independence.) But topic modeling already solves this.</li>
<li>Why can’t we solve NMF using the topic modeling, saying that the distribution is simply the samples that we get?</li>
</ul></li>
</ul></li>
<li>SoS</li>
</ul>
<p>TODO: run again with 1800-dimensional.</p>
<p>TODO: Review polysemy paper, and understand CKN paper well to rederive equations.</p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>DL generalization</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/matrices/DL_generalization.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/matrices/DL_generalization.html</id>
    <published>2016-09-19T00:00:00Z</published>
    <updated>2016-09-19T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>DL generalization</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-09-19 
          , Modified: 2016-09-19 
	</p>
      
       <p>Tags: <a href="/tags/dictionary%20learning.html">dictionary learning</a>, <a href="/tags/sparse%20coding.html">sparse coding</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#group-sparsity">Group sparsity</a><ul>
 <li><a href="#from-subspaces-to-vectors">From subspaces to vectors</a><ul>
 <li><a href="#try-1">Try 1</a></li>
 <li><a href="#try-2">Try 2</a></li>
 </ul></li>
 </ul></li>
 <li><a href="#big-picture">Big picture</a><ul>
 <li><a href="#dl-experiments">DL experiments</a></li>
 </ul></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="group-sparsity">Group sparsity</h2>
<p>Suppose that we have group sparsity with partition <span class="math inline">\(\bigsqcup S_i\)</span>.</p>
<p>In AGMM15, we get instead <span class="math inline">\(\ve{E_1+E_2+E_3}\le O^*\pa{\fc{\mu k^2 \ln^2 n}{m\sqrt n}\max |S_i|^2}\)</span>. For example, if <span class="math inline">\(\max|S_i|^2\)</span> is a constant, the bound is still the same. As long as this is <span class="math inline">\(\le O^*\pf{k}{m\ln m}\)</span>, the bound is still OK.</p>
<p>(Basically we get larger terms in <span class="math inline">\(E_2,E_3\)</span>: In <span class="math inline">\(E_2\)</span> we have <span class="math inline">\(\sum_{i,j\in S_k, i\ne j} q_i \be_i\be_i' A_jA_j^T\)</span>—this is larger because <span class="math inline">\(i,j\)</span> cooccur, we have <span class="math inline">\(q_i\)</span> rather than <span class="math inline">\(q_{i,j}\)</span>, <span class="math inline">\(q_i\)</span> is <span class="math inline">\(\Te\pf km\)</span> not <span class="math inline">\(\Te \pf{k^2}{m^2}\)</span>. Lump these terms into the 1st sum. Ditto for <span class="math inline">\(E_3\)</span>.)</p>
<p>See notebook 15 (end) for details.</p>
<p>Rely on <a href="/posts/math/algebra/linear/matrix_analysis/perturbation.html">modification of Davis-Kahan</a>.</p>
<p>Take <span class="math inline">\(u,v\)</span> and estimate <span class="math inline">\(M_{u,v} = \E \an{u,Ax}\an{v,Ax}(Ax)(Ax)^T\)</span>. Instead of taking the largest singular vector, take the subspace spanned by all singular values of size <span class="math inline">\(\ge C_1 \fc{k}{m}\)</span>. What is the angle between this subspace and the projection of this onto the space of <span class="math inline">\(A_{\cdot i}\)</span> where <span class="math inline">\(i\in \Supp(u)\cap \Supp(v)\)</span>? By generalized Davis-Kahan, <span class="math inline">\(\fc{C_0\fc km - C_1\fc km}{C_2 \fc{k}{m\ln m}} = \fc{C_3}{\ln m}\)</span>.</p>
<p>Now iteratively refine the set of subspaces <span class="math inline">\(\mathcal S\)</span>. Start with a subspace <span class="math inline">\(V\)</span>, and set of atoms <span class="math inline">\(\mathcal A=\phi\)</span>. Let <span class="math inline">\(\ep = \fc{C}{\ln m}\)</span>.</p>
<h3 id="from-subspaces-to-vectors">From subspaces to vectors</h3>
<h4 id="try-1">Try 1</h4>
<p>Do a DFS.</p>
<ul>
<li>If the angle between <span class="math inline">\(V\)</span> and any other subspace in <span class="math inline">\(\mathcal S\)</span> is <span class="math inline">\(&gt;\ep\)</span>, not counting subspaces where all canonical angles between <span class="math inline">\(V\)</span> and it are <span class="math inline">\(&lt;\ep\)</span>, then find the orthogonal complement of atoms that are close to being in <span class="math inline">\(V\)</span>, and let that be an atomic subspace. Now go upwards in the tree.</li>
<li>Otherwise, approximately intersect <span class="math inline">\(V\)</span> with a subspace making it smaller, to get <span class="math inline">\(W\)</span>. Draw <span class="math inline">\(V\to W\)</span>. Repeat with <span class="math inline">\(W\)</span>.</li>
</ul>
<p>NO: These subspaces aren’t spanned by the vectors!</p>
<h4 id="try-2">Try 2</h4>
<p>This seems difficult if we don’t make assumptions.</p>
<p>Let’s suppose for each vector, it is in a small subset of things that cooccur. (Make this more precise.) Ex. constant size.</p>
<p>The issue is that some subspaces/vectors will be inside a <span class="math inline">\(S_i\)</span> (one of the groups in group sparsity) completely—if we can get all the vectors inside a <span class="math inline">\(S_i\)</span> all we have to do is get a basis, good—but others will be inside <span class="math inline">\(\spn(S_i,S_j)\)</span>, or more, and we have to tell them apart.</p>
<p>Idea: do a best-first search, adding subspaces until <span class="math inline">\(\si_{C+1}\)</span> is too large, in which case discard it. (Singular value may not be the right measure here. Maybe: max perpendicular to span of <span class="math inline">\(v_1,\ldots, v_C\)</span>?) The large subsets we get will be inside a <span class="math inline">\(S_i\)</span>.</p>
<p>(Or some kind of clustering?)</p>
<h2 id="big-picture">Big picture</h2>
<p>What are we trying to do here?</p>
<ul>
<li>Generalize the settings under which we have provable DL.</li>
<li>Define agnostic DL as something worth studying and approachable.
<ul>
<li>Idea that neural nets are easier to train if you have more nodes. More opportunities to converge to columns of <span class="math inline">\(A\)</span>.
<ul>
<li>Look at convergene in easy case?</li>
</ul></li>
<li>Have <em>any</em> provable result on agnostic DL.
<ul>
<li>Why we would have agnostic rather than normal: some features are correlated, so the basis could rotate within the subspace of correlated vectors.</li>
</ul></li>
</ul></li>
</ul>
<p>We already have practical DL algorithms that just rely on AM and adding sparsity penalty. How could theory improve this? (AGM14, AGMM15 don’t look like they are used in practice.) Are there theoretical guarantees for AM with sparsity penalty? (There are theoretical guarantees for AM w/ decoding.)</p>
<p>What’s a better model in practice: DL with sparsity or <span class="math inline">\(L^1\)</span>? (And how does ICA compare?)</p>
<p>TODO: program DL and look at empirical performance.</p>
<p>TODO: 2-layer NN learning dictionary?</p>
<p>Dual view between <span class="math inline">\(x=Ah\)</span> and <span class="math inline">\(h=A^Tx\)</span>?</p>
<p>Sparse recovery has this thing where <span class="math inline">\(\ved_1\)</span> actually optimizes <span class="math inline">\(\ved_0\)</span>. Not true of sparse coding?</p>
<h3 id="dl-experiments">DL experiments</h3>
<p>What to try?</p>
<ul>
<li>Program classic AM DL with <span class="math inline">\(L^1\)</span> sparsity penalty.</li>
<li>Program AGMM15 DL.</li>
<li>ICA.</li>
</ul>
<p>Test sets</p>
<ul>
<li>Image patches</li>
<li>Words embeddings</li>
<li>Artificial data (sparse, Laplace, etc. <span class="citation" data-cites="Bianca">@Bianca</span>)</li>
<li>Artificial group-sparse data, or data correlated in some way (ex. geometrically).</li>
</ul>
<p>How to evaluate?</p>
<ul>
<li>Closeness of columns.</li>
<li>Loss: how much sparsity, and how far away. (Reconstruction error)
<ul>
<li>How does reconstruction error compare to SVD? (Make dimensions comparable.)</li>
</ul></li>
<li>Put in random SVM on top. Can it learn the SVM well?</li>
</ul>
<p>Experiments with NN</p>
<ul>
<li>Top-<span class="math inline">\(k\)</span> thresholding to enforce <span class="math inline">\(k\)</span>-sparsity. Autoencoder?</li>
<li>Try group-sparse penalty/architecture.</li>
<li>Does adding more nodes improve things (cf. agnostic DL)?</li>
</ul>
<p>I think sparseness helps interpretability. Does convergence become quicker if we have sparsity?</p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Weekly summary 2016-09-17</title>
    <link href="http://holdenlee.github.io/notebook/posts/summaries/2016-09-17.html" />
    <id>http://holdenlee.github.io/notebook/posts/summaries/2016-09-17.html</id>
    <published>2016-09-19T00:00:00Z</published>
    <updated>2016-09-19T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Weekly summary 2016-09-17</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-09-19 
          , Modified: 2016-09-19 
	</p>
      
       <p>Tags: <a href="/tags/none.html">none</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#threads">Threads</a></li>
 </ul> </div>

  <div class="blog-main">
    <p><a href="2016-09-10.html">Last week</a>.</p>
<h2 id="threads">Threads</h2>
<ul>
<li>Wrote up <a href="/posts/tcs/machine_learning/neural_nets/pmi_images.html">PMI summary</a>.</li>
<li>Conversation with Arora: incorporate 2nd paper into PMI experiments.</li>
<li>Learned <a href="/posts/math/algebra/linear/matrix_analysis/perturbation.html">matrix perturbation theory</a> and applied to <a href="/posts/tcs/machine_learning/matrices/DL_generalization.html">DL assuming group sparsity</a>.</li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>PCANet: A simple deep learning baseline for image classification?</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/neural_nets/pcanet.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/neural_nets/pcanet.html</id>
    <published>2016-09-10T00:00:00Z</published>
    <updated>2016-09-10T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>PCANet: A simple deep learning baseline for image classification?</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-09-10 
          , Modified: 2016-09-10 
	</p>
      
       <p>Tags: <a href="/tags/pca.html">pca</a>, <a href="/tags/neural%20net.html">neural net</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#pcanet-a-simple-deep-learning-baseline-for-image-classification">PCANet: A simple deep learning baseline for image classification?</a></li>
 <li><a href="#architecture">Architecture</a><ul>
 <li><a href="#variations">Variations</a></li>
 </ul></li>
 <li><a href="#experiments">Experiments</a></li>
 <li><a href="#questions">Questions</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="pcanet-a-simple-deep-learning-baseline-for-image-classification">PCANet: A simple deep learning baseline for image classification?</h2>
<p>Each stage in a CNN consists of 3 layers:</p>
<ul>
<li>convolutional filter bank</li>
<li>nonlinear processing</li>
<li>feature pooling</li>
</ul>
<p>Replace these:</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">CNN</th>
<th style="text-align: left;">PCANet</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">convolutional filter bank</td>
<td style="text-align: left;">PCA filter</td>
</tr>
<tr class="even">
<td style="text-align: left;">nonlinear processing</td>
<td style="text-align: left;">binary quantization (hashing)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">feature pooling</td>
<td style="text-align: left;">block-wise histograms of binary codes</td>
</tr>
</tbody>
</table>
<p>Lesson: Deep learning has a lot of hype, but in fact simpler, better theoretically justifiable architectures can do just as well or better! In particular, one weakness of DL is that it depends on parameter tuning expertise and <em>ad hoc</em> tricks.</p>
<p>Examples:</p>
<ul>
<li>ScatNet (wavelet scattering network): filters are wavelet operators, so no learning is needed. (These don’t work so well when there is intra-class variability with illumination change and corruption.)</li>
<li>PCANet cf. OPCA.</li>
</ul>
<p>Motivations:</p>
<ol type="1">
<li>design a simple deep learning network which should be very easy, even trivial, to train and to adapt to different data and tasks.</li>
<li>such a basic network could serve as a good baseline for people to empirically justify the use of more advanced processing components or more sophisticated architectures for their deep learning networks.</li>
</ol>
<h2 id="architecture">Architecture</h2>
<p>Input: <span class="math inline">\(N\)</span> training images <span class="math inline">\(\{I_i\}_{i=1}^N\)</span> of size <span class="math inline">\(m\times n\)</span>.</p>
<ol type="1">
<li><p>Learn PCA: Vectorize all <span class="math inline">\(k_1\times k_2\)</span> patches, mean-center and put them all in a matrix <span class="math inline">\(X\in \R^{k_1k_2\times Nmn}\)</span><a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. Do rank <span class="math inline">\(L_1\)</span> PCA on <span class="math inline">\(X\)</span>. The <span class="math inline">\(l\)</span>th filter (<span class="math inline">\(l\in [L_1]\)</span>) is <span class="math display">\[ W_l^1 := mat_{k_1,k_2}(q_l(XX^T))\]</span> where <span class="math inline">\(mat_{k_1,k_2}\)</span> maps <span class="math inline">\(\R^{k_1k_2}\to \R^{k_1\times k_2}\)</span> and <span class="math inline">\(q_l\)</span> is the <span class="math inline">\(l\)</span> largest eigenvectors.</p>
<p>Now let <span class="math inline">\(I_i^l = I_i * W_l^1\)</span>. (Zero-pad <span class="math inline">\(I_i\)</span> so that <span class="math inline">\(I_i^l\)</span> has the same size.)</p>
You can apply this multiple times. Suppose we apply it twice to get <span class="math inline">\(I_i^{l_1, l_2}\)</span>.</li>
<li>Hashing: Binarize the outputs to get <span class="math display">\[\{b_{l_1,l_2} = H(I_i^{l_1,l_2})\}\]</span> where <span class="math inline">\(H\)</span> is Heaviside function. Let <span class="math display">\[T_i^{l_1} := \sumo{l_2}{L_2} 2^{l_2-1} b_{l_1,l_2}.\]</span> (I.e., treat <span class="math inline">\((b_{l_1,l_2})_{l_2=1}^{L_2}\)</span> categorically.)</li>
<li><p>Histogram: Express histogram with <span class="math inline">\(L_2\)</span> bins as a vector <span class="math inline">\(Bhist(T_i^l)\)</span>. The feature vector of <span class="math inline">\(I_i\)</span> is <span class="math display">\[f_i := \text{map Bhist }[T_i^{1:L_1}]\in \R^{2^{L_2}L_1B}.\]</span></p></li>
</ol>
<p><strong>On many layers</strong>: Note that we DON’T stack by repeating 1-3. Instead, 2-3 happen only once at the end. The stacking happens within 1—doing PCA multiple times.</p>
<p>Note:</p>
<ul>
<li>Nonoverlapping blocks are suitable for faces.</li>
<li>Overlapping blacks are useful for digits, textures, and objects.</li>
<li>Histogram gives some translation invariance (why??).</li>
<li>Model parameters <span class="math inline">\(k_1,k_2,L_1,L_2\)</span>. Ex. <span class="math inline">\(L_1=L_2=8\)</span>.</li>
<li>Two-stage PCANet is good.</li>
<li>PCANet with absolute rectification layer (??) after the first stage doesn’t help.</li>
<li>The overall process is linear. ?? Combining two stages. Two stages works better. Two-stage PCA filters have a low-rank factorization. It has <span class="math inline">\(L_1k_1^2 + L_2k_2^2\)</span> rather than $L_1L_2(k_1+k_2-1)^2 $ variables.</li>
</ul>
<h3 id="variations">Variations</h3>
<ul>
<li>RandNet: use random filters (from standard Gaussian)</li>
<li>LDANet: Use multi-class linear discriminant analysis. (Think: supervised version of PCA.) <a href="../tcs/machine_learning/matrices/lda.html">LDA</a></li>
</ul>
<p>(Does this mean LDANet will fail on things like concentric circles?)</p>
<h2 id="experiments">Experiments</h2>
<p>Face recognition, MNIST.</p>
<p>MNIST: basic (10000-2000-50000), rot, noise bg, image bg, etc.</p>
<h2 id="questions">Questions</h2>
<ul>
<li>What is “block size”? (vs. filter, image size)</li>
<li>How do you classify using PCANet? (ex. do you train a SVM on top?)</li>
<li>How about stacking?
<ul>
<li>An intriguing research direction will then be how to construct a more complicated (say more sophisticated filters possibly with discriminative learning) or deeper (more number of stages) PCANet.</li>
<li>Some preprocessing of pose alignment and scale normalization might be needed for good performance guarantee. The current bottleneck that keeps PCANet from growing deeper (e.g., more than two stages) is that the dimension of the resulted feature would increase exponentially with the number of stages.</li>
</ul></li>
</ul>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Or <span class="math inline">\(N(m-k_1+1)(n-k_1+1)\)</span> if you don’t go past the border.<a href="#fnref1">↩</a></p></li>
</ol>
</section>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>

</feed>
