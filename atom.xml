<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Research Notebook</title>
    <link href="http://holdenlee.github.io/notebook/atom.xml" rel="self" />
    <link href="http://holdenlee.github.io/notebook" />
    <id>http://holdenlee.github.io/notebook/atom.xml</id>
    <author>
        <name>Holden Lee</name>
        <email>oldheneel@gmail.com</email>
    </author>
    <updated>2016-03-04T00:00:00Z</updated>
    <entry>
    <title>SDP duality</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/optimization/sdp-duality.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/optimization/sdp-duality.html</id>
    <published>2016-03-04T00:00:00Z</published>
    <updated>2016-03-04T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>SDP duality</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-03-04 
          , Modified: 2016-03-04 
	</p>
      
       <p>Tags: <a href="/tags/SDP.html">SDP</a>, <a href="/tags/duality.html">duality</a></p> 
    </div>
    
  </div>
  <!--/div-->

  

  <div class="blog-main">
    <p><a href="duality.html">Duality</a></p>
<h2 id="summary">Summary</h2>
<p>The following SDP’s are dual: <span class="math display">\[
\max_{X\succeq 0,\an{A_i,X}=b_i}\an{C,X} \lra \min_{\nu, \sum \nu_iA_i\succeq C} \nu^Tb.
\]</span> (When are they equal? When there is a strictly feasible point.)</p>
<h2 id="derivation">Derivation</h2>
<ol type="1">
<li>First write as a convex program. Replace the condition <span class="math inline">\(X\succeq 0\)</span> by <span class="math display">\[
 \la_{\min}(X)=\min_{\Tr(A)=1, A\succeq 0}\an{A,X}\ge 0.
 \]</span> (Use (2) in <a href="duality.html">duality</a>.)</li>
<li>Simplify, using minimax as a key step.
\begin{align}
 g(\la,\nu) &amp;= \max_X(\an{C,X} + \la \min_{\Tr(A)=1, A\succeq 0}\an{A,X} - \sum \nu_i (\an{A_i,X}-b_i)\\
 &amp;=\max_X\min_{\Tr(A)=1}\an{\ub{C-\sum \nu_iA_i}{Z}+\la A,X} + \nu^Tb\\
 &amp;=\max_X\min_{\Tr(A)=\la}\an{Z + A,X} + \nu^Tb\\
 &amp;= \min_{\Tr(A)=\la}\max_X \an{Z+A,X}\\
 &amp;=\pa{\begin{cases}
 0,&amp;\Tr(Z)=-\la, Z\preceq 0\\
 \iy,&amp;\text{else.}
 \end{cases}}-\nu^Tb
 \end{align}
using minimax, then noting the inside <span class="math inline">\(\max\)</span> forces the condition <span class="math inline">\(Z=-A\)</span>.</li>
<li>Taking <span class="math inline">\(\min\)</span> of this, <span class="math inline">\(Z\preceq 0\)</span> turns into a constraint.</li>
</ol>
<p>See <a href="http://www.eecs.berkeley.edu/~wainwrig/ee227a/SDP_Duality.pdf">notes</a>.</p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Duality</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/optimization/duality.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/optimization/duality.html</id>
    <published>2016-03-04T00:00:00Z</published>
    <updated>2016-03-04T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Duality</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-03-04 
          , Modified: 2016-03-04 
	</p>
      
       <p>Tags: <a href="/tags/duality.html">duality</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#summary">Summary</a><ul>
 <li><a href="#duality">Duality</a></li>
 <li><a href="#kkt-conditions">KKT conditions</a></li>
 </ul></li>
 <li><a href="#questions">Questions</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="summary">Summary</h2>
<h3 id="duality">Duality</h3>
These problems are dual.
\begin{align}
\min_{f_i\le 0, Ax=b} f &amp; \lra \max_{\la \ge 0,\nu} \ub{\min_x \ub{f+\la^T\vec{f} + \nu^T (Ax-b)}{\cal L(x,\la,\nu)}}{g(\la,\nu)}\\
\max_{f_i\ge 0, Ax=b} f &amp; \lra \min_{\la \ge 0,\nu} \ub{\max_x \ub{f+\la^T\vec{f} - \nu^T (Ax-b)}{\cal L(x,\la,\nu)}}{g(\la,\nu)}
\end{align}
<p>In (1) the <span class="math inline">\(f_i\)</span> are convex; in (2) they are concave.</p>
<p><strong>Slater’s constraints</strong>: Equality holds if the problem is strictly feasible: there exists <span class="math inline">\(x\)</span> such that <span class="math inline">\(f_i(x)&lt;0, Ax=b\)</span>.</p>
<h3 id="kkt-conditions">KKT conditions</h3>
<p>The KKT conditions are (here <span class="math inline">\(h=Ax-b\)</span>)</p>
<ol type="1">
<li>(derivative 0) <span class="math inline">\(\nb f+\sum \la_i \nb f_i + \nu^TA=0\)</span>.</li>
<li>(constraints satisfied) <span class="math inline">\(\la \ge 0, f_i\le 0, h_i=0\)</span>.</li>
<li>(complementary slackness) <span class="math inline">\(\la f_i=0\)</span>.</li>
</ol>
<p>Interpretation:</p>
<ul>
<li>If <span class="math inline">\(x,\la,\nu\)</span> satisfy the conditions, then <span class="math inline">\(x\)</span> and <span class="math inline">\((\la,\nu)\)</span> are primal and dual optimal and the optimal values are equal.</li>
<li>if Slater’s condition is satisfied, <span class="math inline">\(x\)</span> is optimal if and only if there exist, <span class="math inline">\(\la,\nu\)</span> that satisfy KKT conditions</li>
</ul>
<h2 id="questions">Questions</h2>
<p>If <span class="math inline">\(x\)</span> is a primal optimal, is there necessarily a <span class="math inline">\((\la,\nu)\)</span> that satisfies the equations? I think if <span class="math inline">\(x\)</span> is primal optimal and <span class="math inline">\((\la,\nu)\)</span> is dual optimal, <span class="math inline">\((x,\la,\nu)\)</span> does not necessarily satisfy. Check this.</p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Convex optimization</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/optimization/convex_optimization.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/optimization/convex_optimization.html</id>
    <published>2016-03-04T00:00:00Z</published>
    <updated>2016-03-04T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Convex optimization</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-03-04 
          , Modified: 2016-03-04 
	</p>
      
       <p>Tags: <a href="/tags/convex%20optimization.html">convex optimization</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"></div>

  <div class="blog-main">
    <p>Notes:</p>
<ul>
<li><a href="duality.html">Duality</a></li>
<li></li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Gradient descent</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/optimization/GD.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/optimization/GD.html</id>
    <published>2016-03-04T00:00:00Z</published>
    <updated>2016-03-04T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Gradient descent</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-03-04 
          , Modified: 2016-03-04 
	</p>
      
       <p>Tags: <a href="/tags/gradient.html">gradient</a></p> 
    </div>
    
  </div>
  <!--/div-->

  

  <div class="blog-main">
    <p>(See 10/15 notebook for detailed notes.)</p>
<h2 id="summary">Summary</h2>
<table style="width:25%;">
<colgroup>
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
<col style="width: 5%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Algorithm</th>
<th style="text-align: left;">General</th>
<th style="text-align: left;"><span class="math inline">\(\al\)</span>-strongly convex</th>
<th style="text-align: left;"><span class="math inline">\(\be\)</span>-smooth</th>
<th style="text-align: left;"><span class="math inline">\(\ga\)</span>-convex</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Gradient descent</td>
<td style="text-align: left;"><span class="math inline">\(\rc{\sqrt{T}}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\rc{\al T}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\fc{\be}T\)</span></td>
<td style="text-align: left;"><span class="math inline">\(e^{-\ga T}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Accelerated gradient descent</td>
<td style="text-align: left;"><span class="math inline">\(\fc{d}{T}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\rc{\al T^2}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(\fc{\be}{T^2}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(e^{-\sqrt{\ga} T}\)</span></td>
</tr>
</tbody>
</table>
<h3 id="gradient-descent-main-points">Gradient descent main points</h3>
<ul>
<li>What is the general framework?
<ol type="1">
<li>Pick a descent direction <span class="math inline">\(\De x\)</span>.</li>
<li>Choose a step size <span class="math inline">\(\tau&gt;0\)</span>: <span class="math display">\[x^{(t+1)} \leftarrow x+\tau \De x.\]</span></li>
<li>Continue until stop criterion.</li>
</ol></li>
<li>What is vanilla (one shot) gradient descent?
<ul>
<li>Gradient descent lemma: Suppose <span class="math inline">\(f\)</span> is convex and <span class="math inline">\(L\)</span>-smooth, <span class="math inline">\(\ve{\nb f(x)-\nb f(y)}\le L\ve{x-y}\)</span>.
\begin{align}
 x':&amp;=x-\rc L \nb f(x)\\
 \implies f(x')&amp;\le f(x) - \rc{2L}\ve{\nb f(x)}^2.
 \end{align}</li>
<li>There’s no guarantee on smoothness unless we assume <span class="math inline">\(f\)</span> is <span class="math inline">\(l\)</span>-strongly convex, <span class="math inline">\(\ve{\nb f(x)-\nb f(y)}\le l\ve{x-y}\)</span>. Let <span class="math inline">\(\ka=\fc{L}{l}, t = \fc{2}{L+l}\)</span>.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> Then linear convergence holds:
\begin{align}
 \ve{x_{k+1}-x^*} \le \pf{\ka-1}{\ka+1} \ve{x_k-x^*}
 \end{align}</li>
</ul></li>
<li>What is gradient descent with backtracking?
<ul>
<li>Parameters <span class="math inline">\(\al\in (0,0.5)\)</span>, step size, <span class="math inline">\(\be\in (0,1)\)</span> scaling factor.</li>
<li>Choose <span class="math inline">\(\De x=\nb f(x)\)</span>.</li>
<li>Choose <span class="math inline">\(\tau\)</span> by backtracking: Set <span class="math inline">\(t=1\)</span>. While <span class="math inline">\(f(x+t\De x)&gt;f(x)+\al \nb f^T\De x\)</span>, <span class="math display">\[\De x\leftarrow \al \De x.\]</span></li>
<li>Lemma: suppose <span class="math inline">\(mI \preceq \nb^2 f \preceq MI\)</span>. Then <span class="math display">\[\fc{f(x_t)-f(p^*)}{f(x_{t-1})-f(p^*)}\le 1-\min\bc{\fc{2\al \be m}{M}, 2m\al}.\]</span></li>
</ul></li>
<li></li>
</ul>
<h2 id="proofs">Proofs</h2>
<p>Gradient descent lemma: Let <span class="math inline">\(D=\nb f(x)\)</span>. Move to origin. Upper bound is <span class="math display">\[f(x) \le \fc{L}2 x^2 + Dx.\]</span> The minimum is at <span class="math inline">\(-\fc{D}{L}\)</span> and is <span class="math inline">\(\fc{-b^2}{4a} = -\fc{D^2}{2L}.\)</span></p>
<p>For strongly convex: Choose <span class="math inline">\(s\)</span> to maximize the minimum progress in terms of <span class="math inline">\(x\)</span>. <span class="math display">\[\fc{s-\rc{l}}{\rc{l}} = \fc{\rc L-s}{\rc L} \implies s = \fc{2}{L+l}.\]</span></p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Think of this as the harmonic average of how much to move to get to the minima of the upper and lower-bounding quadratics.<a href="#fnref1">↩</a></p></li>
</ol>
</section>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>[GRSY15] How Hard is Inference for Structured Prediction?</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/community/GRSY15.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/community/GRSY15.html</id>
    <published>2016-03-03T00:00:00Z</published>
    <updated>2016-03-03T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>[GRSY15] How Hard is Inference for Structured Prediction?</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-03-03 
          , Modified: 2016-03-03 
	</p>
      
       <p>Tags: <a href="/tags/paper.html">paper</a>, <a href="/tags/CBM.html">CBM</a></p> 
    </div>
    
  </div>
  <!--/div-->

  

  <div class="blog-main">
    <p>Model: In a <span class="math inline">\(n\times n\)</span> grid, observe <span class="math inline">\(p\)</span>-noisy edges <span class="math inline">\(Y_uY_v\)</span> and <span class="math inline">\(q\)</span>-noisy nodes <span class="math inline">\(Y_u\)</span>. Attempto to recover the original labeling. What is the maximum correlation you can achieve on average?</p>
<p>Answer: Error <span class="math inline">\(p^2n\)</span> up to a constant.</p>
<ul>
<li>Achievable: find the partition that maximizes the cut value <span class="math inline">\(\sum X_{uv}Y_uY_v\)</span>. Now negate all labelings if it would increase the node agreement.
<ul>
<li>Claim: this is polynomial time. How? This is max cut with negative weights. (https://en.wikipedia.org/wiki/Maximum_cut, http://cstheory.stackexchange.com/questions/2312/max-cut-with-negative-weight-edges, http://cstheory.stackexchange.com/questions/9323/hardness-of-max-cut-on-sparse-graphs)</li>
<li>They mention an LP relaxation, but don’t actually give the formula…</li>
</ul></li>
<li>Tight: consider the checkerboard graph.</li>
</ul>
<p>Applications: Image segmentation. (How would you have both node and edge measurements?)</p>
<p>More directions:</p>
<ul>
<li>Optimal constant?</li>
<li>If you can pay to get better observations, how would you spend a budget?</li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>LDCs</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/coding/ldc.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/coding/ldc.html</id>
    <published>2016-03-03T00:00:00Z</published>
    <updated>2016-03-03T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>LDCs</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-03-03 
          , Modified: 2016-03-03 
	</p>
      
       <p>Tags: <a href="/tags/LDC.html">LDC</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#talk-with-zeev">Talk with Zeev</a></li>
 <li><a href="#low-weight-ldcs-to-ldcs">Low-weight LDCs to LDCs</a></li>
 </ul> </div>

  <div class="blog-main">
    <h2 id="talk-with-zeev">Talk with Zeev</h2>
<p>Consider a partition of the complete bipartite graph into matchings. What is the worst partition, in the sense that you have to take the union of many (<span class="math inline">\(\Om(\ln n)\)</span>) matchings before you get an expander in the sense of the Expander Mixing Lemma?</p>
<p>Now consider if the bipartite graph represents a Cayley graph (<span class="math inline">\(x\)</span> on the left is connected to <span class="math inline">\(gx\)</span> on the right). “Abelian groups are the worst expanders.”</p>
<p>If you need <span class="math inline">\(\ge d\)</span> matchings, you get a LDC from <span class="math inline">\(d\)</span> to <span class="math inline">\(n\)</span>.</p>
<p>Consider tripartite hypergraphs, with <span class="math inline">\(n^3\)</span> matchings partitioned into <span class="math inline">\(n^2\)</span>. Is the worst partition take <span class="math inline">\((\ln n)^2\)</span>?</p>
<h2 id="low-weight-ldcs-to-ldcs">Low-weight LDCs to LDCs</h2>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Perron-Frobenius Theorem</title>
    <link href="http://holdenlee.github.io/notebook/posts/math/algebra/linear/perron-frobenius.html" />
    <id>http://holdenlee.github.io/notebook/posts/math/algebra/linear/perron-frobenius.html</id>
    <published>2016-03-03T00:00:00Z</published>
    <updated>2016-03-03T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Perron-Frobenius Theorem</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-03-03 
          , Modified: 2016-03-03 
	</p>
      
       <p>Tags: <a href="/tags/eigenvalue.html">eigenvalue</a>, <a href="/tags/theorem.html">theorem</a></p> 
    </div>
    
  </div>
  <!--/div-->

  

  <div class="blog-main">
    <h2 id="statement">Statement</h2>
<p>Let <span class="math inline">\(A\)</span> be a matrix with (strictly) positive entries. Then the eigenvalue with maximal absolute value is positive and simple. The corresponding eigenvector is (strictly) positive.</p>
<p><a href="https://en.wikipedia.org/wiki/Perron%E2%80%93Frobenius_theorem">Wikipedia</a></p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>[SD15] Minimax rates for memory-bounded sparse linear regression</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/machine_learning/community/SD15.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/machine_learning/community/SD15.html</id>
    <published>2016-02-29T00:00:00Z</published>
    <updated>2016-02-29T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>[SD15] Minimax rates for memory-bounded sparse linear regression</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-02-29 
          , Modified: 2016-02-29 
	</p>
      
       <p>Tags: <a href="/tags/none.html">none</a></p> 
    </div>
    
  </div>
  <!--/div-->

  

  <div class="blog-main">
    

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>Scraps</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/complexity/scraps.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/complexity/scraps.html</id>
    <published>2016-02-29T00:00:00Z</published>
    <updated>2016-02-29T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>Scraps</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-02-29 
          , Modified: 2016-02-29 
	</p>
      
       <p>Tags: <a href="/tags/scratch.html">scratch</a></p> 
    </div>
    
  </div>
  <!--/div-->

  

  <div class="blog-main">
    <p>Known that there is <span class="math inline">\(A\)</span>, <span class="math inline">\(BQP^A\nsubeq MA^A\)</span>, but not for <span class="math inline">\(AM\)</span>. AM, MA, NP?</p>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>
<entry>
    <title>[Rem16] The Hilbert Function, Algebraic Extractors, and Recursive Fourier Sampling</title>
    <link href="http://holdenlee.github.io/notebook/posts/tcs/complexity/Rem16.html" />
    <id>http://holdenlee.github.io/notebook/posts/tcs/complexity/Rem16.html</id>
    <published>2016-02-29T00:00:00Z</published>
    <updated>2016-02-29T00:00:00Z</updated>
    <summary type="html"><![CDATA[
<div class="container">
  <div id="content">
    <div class="page header">
      <h1>[Rem16] The Hilbert Function, Algebraic Extractors, and Recursive Fourier Sampling</h1>
    </div>
    <div class="info">
      
       
        <p>Posted: 2016-02-29 
          , Modified: 2016-02-29 
	</p>
      
       <p>Tags: <a href="/tags/none.html">none</a></p> 
    </div>
    
  </div>
  <!--/div-->

  <div class="toc"> <ul>
 <li><a href="#recursive-fourier-sampling">Recursive Fourier sampling</a></li>
 <li><a href="#vc-dimension">VC dimension</a></li>
 <li><a href="#algebraic-geometry">Algebraic geometry</a></li>
 <li><a href="#versatile-functions">Versatile functions</a></li>
 <li><a href="#rfs">RFS</a></li>
 <li><a href="#todo">Todo</a></li>
 </ul> </div>

  <div class="blog-main">
    <p>Summary: Define an algebraic measure of randomness (<span class="math inline">\(\de\)</span>-versatility for <span class="math inline">\(U\)</span>), such that a versatile function is an algebraic extractor. RFS is versatile, with applications to <span class="math inline">\(BQP^A\stackrel{?}{\subeq} ?^A\)</span>. #Extractors</p>
<p>Problem: Find extractors for algebraic sets of degree <span class="math inline">\(d\)</span> and density <span class="math inline">\(\ge \rh\)</span>, i.e., for sources uniform over sets of the form <span class="math inline">\(V(f_1,\ldots, f_t)\)</span> (common zeros), <span class="math inline">\(\deg(f_i)\le d\)</span>.</p>
<p>Previous results: [Dvi12] gives explicit extractors for</p>
<ul>
<li><span class="math inline">\(|\F|=\poly(d)\)</span>, <span class="math inline">\(\rh=2^{-\fc n2}\)</span>,</li>
<li><span class="math inline">\(|\F|=d^{\Om(n^2)}\)</span>, small density.</li>
<li>[CT13] degree 2, at most <span class="math inline">\((\ln \ln n)^{\rc{2e}}\)</span> polynomials; disperser for <span class="math inline">\(t\)</span> polys of degree <span class="math inline">\(\le (1-o(1))\fc{\ln\pf nt}{\ln^{0.9}n}\)</span>.</li>
</ul>
<p><strong>Theorem 1</strong>: Any <span class="math inline">\(\de\)</span>-versatile function is an extractor for algebraic sets. Parameters: <span class="math inline">\(\de\ge \fc n2-n^{\ga}\)</span>, <span class="math inline">\(d\le n^\al\)</span>, <span class="math inline">\(\rh\ge 2^{-n^{\be}}\)</span>, bias <span class="math inline">\(O\pf{n^\ga+d\ln \pf{\sqrt n}{\rh}}{\sqrt n}\)</span>. Proof exploits structure of sets of zeros.</p>
<h2 id="recursive-fourier-sampling">Recursive Fourier sampling</h2>
<p>Used to find <span class="math inline">\(A\)</span>, <span class="math inline">\(BQP^A\nsubeq \NP^A\)</span>.</p>
<p>Problem: Find larger class <span class="math inline">\(C\)</span> for which <span class="math inline">\(BQP^A\nsubeq C^A\)</span>.</p>
<p>Technique: connection between relativized separations from the polynomial hierarchy and lower bounds against constant depth circuits [FSS84],[Yao85]. “Here, the key idea is to reinterpret the 9 and 8 quantifiers of a PH machine as OR and AND gates.”</p>
<p>?: Don’t understand the part on poly approx.</p>
<p>Problem: What is the lowest degree polynomial <span class="math inline">\(/\F_2\)</span> representing <a href="RFS.html">recursive Fourier sampling</a>?</p>
<p><strong>Theorem 2</strong>: <span class="math inline">\(n=2^k-1\)</span>. No poly of degree <span class="math inline">\(&lt;\pf{n+1}2^h\)</span> can nontrivally one-sided agree (soundness) with <span class="math inline">\(RFS_{n,h}^{\Maj}\)</span>. (Similar statement for GIP.)</p>
<h2 id="vc-dimension">VC dimension</h2>
<p>Interpolation degree <span class="math inline">\(\text{reg}(C)\)</span> is min <span class="math inline">\(d\)</span> such that every <span class="math inline">\(f\)</span> is a multilinear poly of degree <span class="math inline">\(\le d\)</span>.</p>
<p>Problem: Characterize sets with interpolation degree <span class="math inline">\(r\)</span>.</p>
<p><strong>Theorem 4</strong>: <span class="math inline">\(\text{reg}(C)=r\)</span> iff <span class="math inline">\(r\)</span> is smallest so <span class="math inline">\(\rank \mathcal M(C, \binom{[n]}{\le r})=|C|\)</span>.</p>
<h2 id="algebraic-geometry">Algebraic geometry</h2>
<ul>
<li>Affine Hilbert function <span class="math inline">\(h^a(R,d) = \dim(R_{\le d})\)</span> where <span class="math inline">\(R_{\le d}=\F[\mx]_{\le d}/I(V)_{\le d}\)</span>.</li>
<li>Leading monomials of an ideal. Standard monomials are the complement. (Don’t know why they’re named like this. “Missing monomials” makes more sense.)
<ul>
<li>Hilbert function is a sum of sizes of SM’s: $h^a(V,d)=_{i=0}^d |SM(V,i)|.</li>
<li>Regularity is maximum degree of standard monomial of <span class="math inline">\(V\)</span>.</li>
</ul></li>
<li><span class="math inline">\(a(I)\)</span> is the min degree of <span class="math inline">\(g\in I\)</span> such that <span class="math inline">\(g\)</span> consists only of monomials from <span class="math inline">\(SM(V)\)</span>. (If says <span class="math inline">\(SM(\F^n)\)</span>, but this doesn’t make sense.)
<ul>
<li><span class="math inline">\(V\subeq \F^n\)</span> a nonempty zero-dimensional algebraic set. (What does zero-dim mean here?) Then <span class="math inline">\(a(\ol V)+\text{reg}(V)=n\)</span>.</li>
</ul></li>
<li>How to calculate Hilbert function? Inclusion matrix <span class="math inline">\(M(\mathcal F,\mathcal G)\)</span> has <span class="math inline">\(M_{F,G} = 1_{F\subeq G}\)</span>. Calculate Hilbert function by <span class="math inline">\(h^a(V,d) =\rank M\pa{V,\binom{[n]}{\le d}}\)</span>.</li>
</ul>
<h2 id="versatile-functions">Versatile functions</h2>
<ul>
<li>Versatile: <span class="math inline">\(\forall g, \exists \deg(u),\deg(v)\le \fc n2\)</span> and <span class="math inline">\(g=uf+v\)</span>.
<ul>
<li>Question: isn’t this always true for <span class="math inline">\(\deg g=\fc n2\)</span> by division? Yes, but there are other functions that are versatile too!</li>
<li>Observation: when <span class="math inline">\(f(x)=0, g=v\)</span>. When <span class="math inline">\(f(x)=1\)</span>, <span class="math inline">\(g=u+v\)</span>. Let <span class="math inline">\(U_i=\set{x}{f(x)=i}\)</span>. (Lemma 4) This shows that any poly can be collapsed to one of degree <span class="math inline">\(\le \fc n2\)</span> on <span class="math inline">\(U_0\)</span> and <span class="math inline">\(U_1\)</span>, i.e. <span class="math inline">\(\text{reg}(U_i)\le \fc n2\)</span>. Converse also holds. (How is regularity related to max degree of defining function?)</li>
</ul></li>
</ul>
<p>Example: the standard monomials (those missed by leading monomials) of Maj are those with weight <span class="math inline">\(&lt;\fc n2\)</span>. (Proof: any product of <span class="math inline">\(\ge \fc n2\)</span> variables vanishes on Maj.)</p>
<p>Generalize: <span class="math inline">\(\de\)</span>-versatile on <span class="math inline">\(U\)</span> if <span class="math inline">\(\de \le \text{reg}(U)-\text{reg}(U_i)\)</span>. (A versatile function is <span class="math inline">\(\fc n2\)</span>-versatile on <span class="math inline">\(\F_2^n\)</span>.)</p>
<p>Lemmas:</p>
<ul>
<li>6: A <span class="math inline">\(\de\)</span>-versatile function on <span class="math inline">\(U\)</span> cannot be represented on <span class="math inline">\(U\)</span> by degree <span class="math inline">\(&lt;\de\)</span>. (Note how we changed the degree and the set!)</li>
<li>7: If <span class="math inline">\(q\)</span> has degree <span class="math inline">\(&lt;\de\)</span> and <span class="math inline">\(q\)</span> vanishes on <span class="math inline">\(U_i\)</span>, then it vanishes on <span class="math inline">\(U_{1-i}\)</span>. (This gives failure of one-sided computation.) Necessary is that <span class="math inline">\(U\)</span> be critical algebraic, <span class="math inline">\(a(\ol V)=\deg(1_U)\)</span>. I don’t understand this condition.</li>
<li>8: The LM’s for <span class="math inline">\(U\cap G,U_i\cap G\)</span> for <span class="math inline">\(G\)</span> a union of hypersurfaces of degree <span class="math inline">\(&lt;d\)</span>, are the same up to degree <span class="math inline">\(\le \de -d\)</span>.</li>
<li>9: Bound the difference between 2 evaluations of the Hilbert function at around <span class="math inline">\(\text{reg}(V)\)</span>. Q: Why do we expect this to be small, and why do we care?</li>
</ul>
<h2 id="rfs">RFS</h2>
<h2 id="todo">Todo</h2>
<ul>
<li>Go through proof of Theorem 1.</li>
<li>Understand recursive Fourier sampling. Read another source for this.</li>
</ul>
<p>Questions</p>
<ul>
<li>How to construct a versatile set?</li>
</ul>

  </div>

    

    <!-- Extension : Sharing buttons @ www.sharethis.com -->
    <span class='st_facebook_large' displayText='Facebook'></span>
    <span class='st_twitter_large' displayText='Tweet'></span>
    <span class='st_googleplus_large' displayText='Google +'></span>
    <span class='st_reddit_large' displayText='Reddit'></span>
    <span class='st__large' displayText=''></span>

    <div id="disqus_thread"></div>
    


  
    <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
  </div>
  
</div>
]]></summary>
</entry>

</feed>
